{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./save_pretrained/cdd_pre_3/Bert_10470/pytorch_model.bin were not used when initializing BertBaseModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertBaseModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertBaseModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertBaseModel were not initialized from the model checkpoint at ./save_pretrained/cdd_pre_3/Bert_10470/pytorch_model.bin and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train:   5%|▍         | 6/125 [00:03<00:59,  2.00it/s, F1=0, train_acc=0.0857, train_loss=84, train_precision=0, train_recall=0]  /home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch: 1/30 Train:  19%|█▉        | 24/125 [00:11<00:46,  2.16it/s, F1=0, train_acc=0.702, train_loss=45.5, train_precision=0, train_recall=0]"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# from CC.trainer import NERTrainer\n",
    "\n",
    "# args = {\n",
    "#     'num_epochs': 30,\n",
    "#     'num_gpus': [0],\n",
    "#     'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "#     # 'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "#     'pretrained_file_name': './save_pretrained/cdd_pre_3/Bert_10470/pytorch_model.bin',\n",
    "#     'hidden_dim': 300,\n",
    "#     'max_seq_length': 150,\n",
    "#     'train_file': './data/CDD/0.5k/conll/train.txt',\n",
    "#     'eval_file': './data/CDD/conll/dev.txt',\n",
    "#     'test_file': './data/CDD/conll/test.txt',\n",
    "#     'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "#     'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "#     'loader_name': 'cn_loader',\n",
    "#     'output_eval':True,\n",
    "#     \"default_tag\":\"O\",\n",
    "#     'batch_size': 2,\n",
    "#     'eval_batch_size': 64,\n",
    "#     'do_shuffle': True,\n",
    "#     \"use_gpu\": True,\n",
    "#     \"debug\": True,\n",
    "#     'model_name': 'Bert',\n",
    "#     'classify':'lstm_crf',\n",
    "#     'task_name': 'cdd_bert_pro_0.5k_1'\n",
    "# }\n",
    "\n",
    "# # Trainer\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer():\n",
    "#     a = i\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_0.5k_2\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_0.5k_3\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_0.5k_4\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-5):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_0.5k_5\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'pretrained_file_name': './save_pretrained/cdd_pre_3/Bert_10470/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'train_file': './data/CDD/1k/conll/train.txt',\n",
    "    'eval_file': './data/CDD/conll/dev.txt',\n",
    "    'test_file': './data/CDD/conll/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'cdd_bert_pro_1k_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_1k_2\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_1k_3\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_1k_4\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-5):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_1k_5\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "# from CC.trainer import NERTrainer\n",
    "\n",
    "# args = {\n",
    "#     'num_epochs': 30,\n",
    "#     'num_gpus': [0],\n",
    "#     'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "#     # 'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "#     'pretrained_file_name': './save_pretrained/cdd_pre_3/Bert_10470/pytorch_model.bin',\n",
    "#     'hidden_dim': 300,\n",
    "#     'max_seq_length': 150,\n",
    "#     'train_file': './data/CDD/2k/conll/train.txt',\n",
    "#     'eval_file': './data/CDD/conll/dev.txt',\n",
    "#     'test_file': './data/CDD/conll/test.txt',\n",
    "#     'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "#     'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "#     'loader_name': 'cn_loader',\n",
    "#     'output_eval':True,\n",
    "#     \"default_tag\":\"O\",\n",
    "#     'batch_size': 8,\n",
    "#     'eval_batch_size': 64,\n",
    "#     'do_shuffle': True,\n",
    "#     \"use_gpu\": True,\n",
    "#     \"debug\": True,\n",
    "#     'model_name': 'Bert',\n",
    "#     'classify':'lstm_crf',\n",
    "#     'task_name': 'cdd_bert_pro_2k_1'\n",
    "# }\n",
    "\n",
    "# # Trainer\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_2k_2\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_2k_3\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_2k_4\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-5):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_bert_pro_2k_5\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/CDD/0.5k/json/train.json',\n",
    "    'eval_file': './data/CDD/dev.json',\n",
    "    'test_file': './data/CDD/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'cdd_v1_lstm_crf_0.5k_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_lstm_crf_0.5k_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_lstm_crf_0.5k_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_lstm_crf_0.5k_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-5):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_lstm_crf_0.5k_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/CDD/0.5k/json/train.json',\n",
    "    'eval_file': './data/CDD/dev.json',\n",
    "    'test_file': './data/CDD/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'cdd_LEBert_crf_0.5k_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_LEBert_crf_0.5k_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_LEBert_crf_0.5k_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_LEBert_crf_0.5k_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-5):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_LEBert_crf_0.5k_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9392d1f0914889243d058bb73f0d89e61311fd6d751bbc8fa50e38d7d4ff811"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('NER': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
