{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'train_file': './data/CDD/2k/conll/train.txt',\n",
    "    'eval_file': './data/CDD/conll/dev.txt',\n",
    "    'test_file': './data/CDD/conll/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'cdd_bert_lstm_crf_2k_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "args[\"task_name\"] = \"cdd_bert_lstm_crf_2k_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_bert_lstm_crf_2k_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_bert_lstm_crf_2k_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-5):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_bert_lstm_crf_2k_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# from CC.trainer import NERTrainer\n",
    "\n",
    "# args = {\n",
    "#     'num_epochs': 30,\n",
    "#     'num_gpus': [0],\n",
    "#     'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "#     # 'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "#     'pretrained_file_name': './save_pretrained/cdd_pre_3/Bert_10470/pytorch_model.bin',\n",
    "#     'hidden_dim': 300,\n",
    "#     'max_seq_length': 150,\n",
    "#     'max_scan_num': 1000000,\n",
    "#     'inter_max_scan_num': 20000,\n",
    "#     'train_file': './data/CDD/0.5k/json/train.json',\n",
    "#     'eval_file': './data/CDD/dev.json',\n",
    "#     'test_file': './data/CDD/test.json',\n",
    "#     'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "#     'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "#     'loader_name': 'le_loader_zl',\n",
    "#     'output_eval':True,\n",
    "#     \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "#     \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "#     \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "#     \"default_tag\":\"O\",\n",
    "#     'batch_size': 8,\n",
    "#     'eval_batch_size': 64,\n",
    "#     'do_shuffle': True,\n",
    "#     \"use_gpu\": True,\n",
    "#     \"debug\": True,\n",
    "#     'model_name': 'ZLEBert',\n",
    "#     'classify':'lstm_crf',\n",
    "#     'task_name': 'cdd_v1_pro_0.5k_1'\n",
    "# }\n",
    "\n",
    "# # Trainer\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_v1_pro_0.5k_2\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_v1_pro_0.5k_3\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_v1_pro_0.5k_4\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-5):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_v1_pro_0.5k_5\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# from CC.trainer import NERTrainer\n",
    "\n",
    "# args = {\n",
    "#     'num_epochs': 30,\n",
    "#     'num_gpus': [0],\n",
    "#     'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "#     # 'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "#     'pretrained_file_name': './save_pretrained/cdd_pre_3/Bert_10470/pytorch_model.bin',\n",
    "#     'hidden_dim': 300,\n",
    "#     'max_seq_length': 150,\n",
    "#     'max_scan_num': 1000000,\n",
    "#     'inter_max_scan_num': 20000,\n",
    "#     'train_file': './data/CDD/1k/json/train.json',\n",
    "#     'eval_file': './data/CDD/dev.json',\n",
    "#     'test_file': './data/CDD/test.json',\n",
    "#     'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "#     'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "#     'loader_name': 'le_loader_zl',\n",
    "#     'output_eval':True,\n",
    "#     \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "#     \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "#     \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "#     \"default_tag\":\"O\",\n",
    "#     'batch_size': 8,\n",
    "#     'eval_batch_size': 64,\n",
    "#     'do_shuffle': True,\n",
    "#     \"use_gpu\": True,\n",
    "#     \"debug\": True,\n",
    "#     'model_name': 'ZLEBert',\n",
    "#     'classify':'lstm_crf',\n",
    "#     'task_name': 'cdd_v1_pro_1k_1'\n",
    "# }\n",
    "\n",
    "# # Trainer\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_v1_pro_1k_2\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_v1_pro_1k_3\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_v1_pro_1k_4\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-5):\n",
    "#     a = i\n",
    "\n",
    "\n",
    "# args[\"task_name\"] = \"cdd_v1_pro_1k_5\"\n",
    "\n",
    "# trainer = NERTrainer(**args)\n",
    "\n",
    "# for i in trainer(lr2=1e-2):\n",
    "#     a = i\n",
    "\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/cdd_pre_3/Bert_10470/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/CDD/2k/json/train.json',\n",
    "    'eval_file': './data/CDD/dev.json',\n",
    "    'test_file': './data/CDD/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'cdd_v1_2k_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_2k_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_2k_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_2k_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-5):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_2k_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    # 'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'pretrained_file_name': './save_pretrained/ccks_pre_4/Bert_19215/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/CDD/2k/json/train.json',\n",
    "    'eval_file': './data/CDD/dev.json',\n",
    "    'test_file': './data/CDD/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'cdd_LEBert_crf_2k_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_LEBert_crf_2k_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_LEBert_crf_2k_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_LEBert_crf_2k_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-5):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_LEBert_crf_2k_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer import NERTrainer\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/cdd_pre_3/Bert_10470/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 100,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/CDD/train.json',\n",
    "    'eval_file': './data/CDD/dev.json',\n",
    "    'test_file': './data/CDD/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    # 'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'cdd_v1_seq_100_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_100_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_100_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_100_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_100_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "args['max_seq_length'] = 80\n",
    "args[\"task_name\"] = \"cdd_v1_seq_80_1\"\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_80_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_80_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_80_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_80_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "args['max_seq_length'] = 60\n",
    "args[\"task_name\"] = \"cdd_v1_seq_60_1\"\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_60_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_60_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_60_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_60_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args['max_seq_length'] = 40\n",
    "args[\"task_name\"] = \"cdd_v1_seq_40_1\"\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_40_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_40_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_40_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"cdd_v1_seq_40_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9392d1f0914889243d058bb73f0d89e61311fd6d751bbc8fa50e38d7d4ff811"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('NER': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
