{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v4_tx_1\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 306MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 244MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 344MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 370kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 97901.44L/s]\n",
      "build line mapper: 19L [00:00, 29084.59L/s]9 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 2637.58it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 98628.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1643: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:24<00:00, 606.17it/s]\n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:08<00:00, 607.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train:   8%|▊         | 18/235 [00:24<04:56,  1.37s/it, F1=9.64e-5, train_acc=0.359, train_loss=140, train_precision=6.01e-5, train_recall=0.000243]  /home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.38s/it, F1=0.349, train_acc=0.755, train_loss=37.9, train_precision=0.323, train_recall=0.386]        \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.598, eval_acc=0.833, eval_loss=15.1, eval_precision=0.629, eval_recall=0.572]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [05:29<00:00,  1.40s/it, F1=0.634, train_acc=0.838, train_loss=11.5, train_precision=0.634, train_recall=0.635]\n",
      "Eval Result: 100%|██████████| 79/79 [00:59<00:00,  1.32it/s, F1=0.627, eval_acc=0.832, eval_loss=9.9, eval_precision=0.675, eval_recall=0.589] \n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [05:31<00:00,  1.41s/it, F1=0.673, train_acc=0.852, train_loss=7.72, train_precision=0.675, train_recall=0.674]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.632, eval_acc=0.832, eval_loss=7.96, eval_precision=0.65, eval_recall=0.618] \n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [05:10<00:00,  1.32s/it, F1=0.697, train_acc=0.863, train_loss=6.32, train_precision=0.697, train_recall=0.698]\n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.45it/s, F1=0.638, eval_acc=0.834, eval_loss=7.34, eval_precision=0.642, eval_recall=0.638]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [05:26<00:00,  1.39s/it, F1=0.718, train_acc=0.874, train_loss=5.51, train_precision=0.717, train_recall=0.72] \n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.30it/s, F1=0.642, eval_acc=0.836, eval_loss=7.13, eval_precision=0.643, eval_recall=0.645]\n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [05:24<00:00,  1.38s/it, F1=0.738, train_acc=0.884, train_loss=4.88, train_precision=0.736, train_recall=0.74] \n",
      "Eval Result: 100%|██████████| 79/79 [00:59<00:00,  1.33it/s, F1=0.643, eval_acc=0.831, eval_loss=7.27, eval_precision=0.635, eval_recall=0.654]\n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.38s/it, F1=0.76, train_acc=0.896, train_loss=4.42, train_precision=0.757, train_recall=0.763] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.634, eval_acc=0.828, eval_loss=7.7, eval_precision=0.626, eval_recall=0.646] \n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [05:24<00:00,  1.38s/it, F1=0.776, train_acc=0.903, train_loss=4.13, train_precision=0.772, train_recall=0.781]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.632, eval_acc=0.821, eval_loss=8.1, eval_precision=0.609, eval_recall=0.659] \n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [05:31<00:00,  1.41s/it, F1=0.788, train_acc=0.909, train_loss=3.85, train_precision=0.785, train_recall=0.793]\n",
      "Eval Result: 100%|██████████| 79/79 [00:58<00:00,  1.35it/s, F1=0.629, eval_acc=0.818, eval_loss=7.93, eval_precision=0.612, eval_recall=0.65] \n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [05:28<00:00,  1.40s/it, F1=0.801, train_acc=0.914, train_loss=3.66, train_precision=0.798, train_recall=0.804]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.636, eval_acc=0.833, eval_loss=8.35, eval_precision=0.648, eval_recall=0.628]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [05:16<00:00,  1.35s/it, F1=0.814, train_acc=0.922, train_loss=3.35, train_precision=0.81, train_recall=0.82]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:59<00:00,  1.34it/s, F1=0.646, eval_acc=0.839, eval_loss=8.84, eval_precision=0.644, eval_recall=0.651]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [05:17<00:00,  1.35s/it, F1=0.83, train_acc=0.929, train_loss=3.12, train_precision=0.826, train_recall=0.835] \n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.47it/s, F1=0.632, eval_acc=0.83, eval_loss=8.82, eval_precision=0.627, eval_recall=0.639] \n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:55<00:00,  1.26s/it, F1=0.846, train_acc=0.936, train_loss=2.84, train_precision=0.841, train_recall=0.85] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.644, eval_acc=0.838, eval_loss=9.04, eval_precision=0.635, eval_recall=0.657]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [05:26<00:00,  1.39s/it, F1=0.854, train_acc=0.939, train_loss=2.77, train_precision=0.85, train_recall=0.858] \n",
      "Eval Result: 100%|██████████| 79/79 [00:59<00:00,  1.32it/s, F1=0.632, eval_acc=0.832, eval_loss=10.2, eval_precision=0.652, eval_recall=0.616]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [05:26<00:00,  1.39s/it, F1=0.865, train_acc=0.944, train_loss=2.6, train_precision=0.862, train_recall=0.869] \n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.23it/s, F1=0.627, eval_acc=0.831, eval_loss=10.2, eval_precision=0.612, eval_recall=0.645]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [05:05<00:00,  1.30s/it, F1=0.874, train_acc=0.948, train_loss=2.43, train_precision=0.871, train_recall=0.878]\n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.72it/s, F1=0.64, eval_acc=0.838, eval_loss=10.2, eval_precision=0.637, eval_recall=0.647] \n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [04:57<00:00,  1.27s/it, F1=0.887, train_acc=0.954, train_loss=2.21, train_precision=0.883, train_recall=0.891]\n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.31it/s, F1=0.635, eval_acc=0.837, eval_loss=10.7, eval_precision=0.652, eval_recall=0.622]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [05:15<00:00,  1.34s/it, F1=0.892, train_acc=0.956, train_loss=2.12, train_precision=0.889, train_recall=0.895]\n",
      "Eval Result: 100%|██████████| 79/79 [00:56<00:00,  1.39it/s, F1=0.633, eval_acc=0.834, eval_loss=10.7, eval_precision=0.637, eval_recall=0.631]\n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [05:09<00:00,  1.32s/it, F1=0.903, train_acc=0.961, train_loss=1.95, train_precision=0.899, train_recall=0.907]\n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.71it/s, F1=0.632, eval_acc=0.831, eval_loss=11.5, eval_precision=0.627, eval_recall=0.641]\n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:53<00:00,  1.25s/it, F1=0.911, train_acc=0.965, train_loss=1.81, train_precision=0.909, train_recall=0.914]\n",
      "Eval Result: 100%|██████████| 79/79 [00:56<00:00,  1.40it/s, F1=0.634, eval_acc=0.834, eval_loss=12, eval_precision=0.605, eval_recall=0.668]  \n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:29<00:00,  1.15s/it, F1=0.918, train_acc=0.968, train_loss=1.69, train_precision=0.916, train_recall=0.92] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.634, eval_acc=0.836, eval_loss=12.5, eval_precision=0.61, eval_recall=0.661] \n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.922, train_acc=0.969, train_loss=1.66, train_precision=0.919, train_recall=0.924]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.635, eval_acc=0.836, eval_loss=13, eval_precision=0.618, eval_recall=0.656]  \n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.925, train_acc=0.971, train_loss=1.59, train_precision=0.923, train_recall=0.927]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.632, eval_acc=0.836, eval_loss=13.3, eval_precision=0.625, eval_recall=0.643]\n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.928, train_acc=0.972, train_loss=1.52, train_precision=0.925, train_recall=0.93] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.632, eval_acc=0.835, eval_loss=13.5, eval_precision=0.629, eval_recall=0.638]\n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.931, train_acc=0.973, train_loss=1.49, train_precision=0.929, train_recall=0.934]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.636, eval_acc=0.836, eval_loss=13.3, eval_precision=0.635, eval_recall=0.64] \n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.938, train_acc=0.976, train_loss=1.36, train_precision=0.937, train_recall=0.94] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.632, eval_acc=0.837, eval_loss=14.2, eval_precision=0.611, eval_recall=0.657]\n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.945, train_acc=0.98, train_loss=1.2, train_precision=0.944, train_recall=0.947]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.633, eval_acc=0.836, eval_loss=14.7, eval_precision=0.612, eval_recall=0.659]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.948, train_acc=0.981, train_loss=1.15, train_precision=0.947, train_recall=0.95] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.634, eval_acc=0.838, eval_loss=15.2, eval_precision=0.615, eval_recall=0.655]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.95, train_acc=0.981, train_loss=1.11, train_precision=0.948, train_recall=0.952] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.635, eval_acc=0.834, eval_loss=14.3, eval_precision=0.615, eval_recall=0.66] \n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.956, train_acc=0.984, train_loss=0.992, train_precision=0.955, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.629, eval_acc=0.832, eval_loss=14.4, eval_precision=0.608, eval_recall=0.653]\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/chip/train_data.json',\n",
    "    'eval_file': './data/chip/val_data.json',\n",
    "    'test_file': './data/chip/val_data.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/chip/chip_tags_list.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    # 'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/tencent_medicine_vocab.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/fn_thu_chn.txt\",\n",
    "    # \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert_v4',\n",
    "    'task_name': 'chip_v4_tx_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v4_tx_2\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 304MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 353MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 355MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 322kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 46171.37L/s]\n",
      "build line mapper: 19L [00:00, 29063.38L/s]9 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 4398.24it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 169918.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:17<00:00, 868.80it/s] \n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:05<00:00, 871.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.293, train_acc=0.744, train_loss=43.1, train_precision=0.257, train_recall=0.348]       \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.533, eval_acc=0.819, eval_loss=17.8, eval_precision=0.491, eval_recall=0.587]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.624, train_acc=0.839, train_loss=12.8, train_precision=0.619, train_recall=0.631]\n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.80it/s, F1=0.623, eval_acc=0.834, eval_loss=10.4, eval_precision=0.614, eval_recall=0.634]\n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.675, train_acc=0.855, train_loss=8.25, train_precision=0.677, train_recall=0.674]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.622, eval_acc=0.822, eval_loss=8.59, eval_precision=0.613, eval_recall=0.634]\n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.701, train_acc=0.866, train_loss=6.53, train_precision=0.701, train_recall=0.701]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.62, eval_acc=0.81, eval_loss=8.15, eval_precision=0.607, eval_recall=0.637]  \n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.72, train_acc=0.875, train_loss=5.7, train_precision=0.72, train_recall=0.721]   \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.597, eval_acc=0.785, eval_loss=8.4, eval_precision=0.586, eval_recall=0.612] \n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.738, train_acc=0.885, train_loss=5.09, train_precision=0.737, train_recall=0.741]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.615, eval_acc=0.807, eval_loss=7.75, eval_precision=0.61, eval_recall=0.622] \n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.758, train_acc=0.895, train_loss=4.58, train_precision=0.755, train_recall=0.761]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.628, eval_acc=0.822, eval_loss=7.62, eval_precision=0.624, eval_recall=0.635]\n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.777, train_acc=0.905, train_loss=4.2, train_precision=0.774, train_recall=0.78]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.641, eval_acc=0.838, eval_loss=7.59, eval_precision=0.643, eval_recall=0.641]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.787, train_acc=0.908, train_loss=4, train_precision=0.784, train_recall=0.791]   \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.629, eval_acc=0.826, eval_loss=8.05, eval_precision=0.638, eval_recall=0.623]\n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.802, train_acc=0.916, train_loss=3.72, train_precision=0.799, train_recall=0.806]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.628, eval_acc=0.826, eval_loss=8.17, eval_precision=0.619, eval_recall=0.64] \n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.818, train_acc=0.924, train_loss=3.4, train_precision=0.814, train_recall=0.822] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.615, eval_acc=0.814, eval_loss=9.12, eval_precision=0.606, eval_recall=0.627]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.837, train_acc=0.935, train_loss=3.07, train_precision=0.833, train_recall=0.841]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.623, eval_acc=0.825, eval_loss=9.37, eval_precision=0.607, eval_recall=0.641]\n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.85, train_acc=0.94, train_loss=2.86, train_precision=0.845, train_recall=0.854]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.615, eval_acc=0.813, eval_loss=9.95, eval_precision=0.601, eval_recall=0.632]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.856, train_acc=0.943, train_loss=2.77, train_precision=0.853, train_recall=0.86] \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.78it/s, F1=0.625, eval_acc=0.83, eval_loss=9.36, eval_precision=0.62, eval_recall=0.633]  \n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [04:20<00:00,  1.11s/it, F1=0.87, train_acc=0.948, train_loss=2.57, train_precision=0.866, train_recall=0.874] \n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.74it/s, F1=0.627, eval_acc=0.831, eval_loss=9.78, eval_precision=0.621, eval_recall=0.635]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [04:21<00:00,  1.11s/it, F1=0.876, train_acc=0.951, train_loss=2.44, train_precision=0.873, train_recall=0.879]\n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.75it/s, F1=0.636, eval_acc=0.838, eval_loss=10.8, eval_precision=0.631, eval_recall=0.644]\n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.88, train_acc=0.951, train_loss=2.43, train_precision=0.878, train_recall=0.883] \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.77it/s, F1=0.635, eval_acc=0.835, eval_loss=10.7, eval_precision=0.633, eval_recall=0.64] \n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [04:42<00:00,  1.20s/it, F1=0.89, train_acc=0.956, train_loss=2.22, train_precision=0.888, train_recall=0.893] \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.58it/s, F1=0.624, eval_acc=0.829, eval_loss=10.9, eval_precision=0.622, eval_recall=0.63] \n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [04:42<00:00,  1.20s/it, F1=0.907, train_acc=0.965, train_loss=1.93, train_precision=0.904, train_recall=0.909]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.57it/s, F1=0.627, eval_acc=0.83, eval_loss=10.9, eval_precision=0.625, eval_recall=0.631] \n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:42<00:00,  1.20s/it, F1=0.913, train_acc=0.968, train_loss=1.81, train_precision=0.91, train_recall=0.916] \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.55it/s, F1=0.623, eval_acc=0.826, eval_loss=11.3, eval_precision=0.631, eval_recall=0.617]\n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:44<00:00,  1.21s/it, F1=0.917, train_acc=0.97, train_loss=1.74, train_precision=0.915, train_recall=0.92]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.56it/s, F1=0.621, eval_acc=0.829, eval_loss=11.7, eval_precision=0.647, eval_recall=0.601]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:50<00:00,  1.24s/it, F1=0.924, train_acc=0.972, train_loss=1.63, train_precision=0.921, train_recall=0.926]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, F1=0.617, eval_acc=0.827, eval_loss=12.4, eval_precision=0.648, eval_recall=0.592]\n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:53<00:00,  1.25s/it, F1=0.93, train_acc=0.974, train_loss=1.55, train_precision=0.929, train_recall=0.932] \n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, F1=0.618, eval_acc=0.827, eval_loss=12.6, eval_precision=0.638, eval_recall=0.603]\n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:52<00:00,  1.24s/it, F1=0.931, train_acc=0.974, train_loss=1.51, train_precision=0.929, train_recall=0.933]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.51it/s, F1=0.623, eval_acc=0.829, eval_loss=13, eval_precision=0.641, eval_recall=0.608]  \n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:53<00:00,  1.25s/it, F1=0.934, train_acc=0.975, train_loss=1.48, train_precision=0.932, train_recall=0.936]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.47it/s, F1=0.619, eval_acc=0.829, eval_loss=12.8, eval_precision=0.644, eval_recall=0.599]\n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [04:54<00:00,  1.25s/it, F1=0.936, train_acc=0.976, train_loss=1.47, train_precision=0.934, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.47it/s, F1=0.604, eval_acc=0.815, eval_loss=13, eval_precision=0.629, eval_recall=0.585]  \n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [04:53<00:00,  1.25s/it, F1=0.939, train_acc=0.977, train_loss=1.42, train_precision=0.937, train_recall=0.941]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, F1=0.628, eval_acc=0.831, eval_loss=13.7, eval_precision=0.643, eval_recall=0.616]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [04:54<00:00,  1.26s/it, F1=0.944, train_acc=0.98, train_loss=1.27, train_precision=0.943, train_recall=0.946] \n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, F1=0.629, eval_acc=0.832, eval_loss=13.5, eval_precision=0.631, eval_recall=0.63] \n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [04:55<00:00,  1.26s/it, F1=0.949, train_acc=0.981, train_loss=1.23, train_precision=0.947, train_recall=0.95] \n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.46it/s, F1=0.625, eval_acc=0.833, eval_loss=14.5, eval_precision=0.641, eval_recall=0.613]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [04:52<00:00,  1.25s/it, F1=0.95, train_acc=0.981, train_loss=1.21, train_precision=0.948, train_recall=0.951] \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.52it/s, F1=0.636, eval_acc=0.835, eval_loss=15.1, eval_precision=0.643, eval_recall=0.633]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_v4_tx_2'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v4_tx_3\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 329MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 347MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 347MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 168kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 31300.78L/s]\n",
      "build line mapper: 19L [00:00, 70336.96L/s]9 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 1486.56it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 74200.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:27<00:00, 536.03it/s]\n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:09<00:00, 505.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [04:53<00:00,  1.25s/it, F1=0.341, train_acc=0.747, train_loss=40.7, train_precision=0.306, train_recall=0.392]       \n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.46it/s, F1=0.595, eval_acc=0.834, eval_loss=16.6, eval_precision=0.569, eval_recall=0.626]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [04:51<00:00,  1.24s/it, F1=0.636, train_acc=0.84, train_loss=12.1, train_precision=0.633, train_recall=0.642] \n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.47it/s, F1=0.638, eval_acc=0.837, eval_loss=10.3, eval_precision=0.639, eval_recall=0.64] \n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [04:52<00:00,  1.24s/it, F1=0.676, train_acc=0.853, train_loss=7.96, train_precision=0.677, train_recall=0.675]\n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.46it/s, F1=0.642, eval_acc=0.838, eval_loss=8.52, eval_precision=0.634, eval_recall=0.652]\n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [04:54<00:00,  1.25s/it, F1=0.698, train_acc=0.863, train_loss=6.38, train_precision=0.699, train_recall=0.697]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, F1=0.642, eval_acc=0.838, eval_loss=7.92, eval_precision=0.626, eval_recall=0.662]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [04:54<00:00,  1.25s/it, F1=0.716, train_acc=0.873, train_loss=5.57, train_precision=0.717, train_recall=0.716]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, F1=0.642, eval_acc=0.838, eval_loss=7.75, eval_precision=0.63, eval_recall=0.657] \n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [04:55<00:00,  1.26s/it, F1=0.732, train_acc=0.88, train_loss=5.1, train_precision=0.732, train_recall=0.733]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.47it/s, F1=0.628, eval_acc=0.832, eval_loss=7.9, eval_precision=0.619, eval_recall=0.64]  \n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [04:53<00:00,  1.25s/it, F1=0.748, train_acc=0.887, train_loss=4.75, train_precision=0.747, train_recall=0.75] \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, F1=0.64, eval_acc=0.837, eval_loss=8.13, eval_precision=0.622, eval_recall=0.662] \n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [04:56<00:00,  1.26s/it, F1=0.755, train_acc=0.893, train_loss=4.53, train_precision=0.755, train_recall=0.758]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, F1=0.635, eval_acc=0.832, eval_loss=8.16, eval_precision=0.605, eval_recall=0.67] \n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [04:55<00:00,  1.26s/it, F1=0.78, train_acc=0.905, train_loss=4.06, train_precision=0.777, train_recall=0.784] \n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, F1=0.634, eval_acc=0.83, eval_loss=7.74, eval_precision=0.611, eval_recall=0.66]  \n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [04:52<00:00,  1.25s/it, F1=0.798, train_acc=0.915, train_loss=3.66, train_precision=0.795, train_recall=0.802]\n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.45it/s, F1=0.636, eval_acc=0.835, eval_loss=7.95, eval_precision=0.621, eval_recall=0.655]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:24<00:00,  1.13s/it, F1=0.814, train_acc=0.922, train_loss=3.44, train_precision=0.811, train_recall=0.818]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.636, eval_acc=0.834, eval_loss=8.09, eval_precision=0.633, eval_recall=0.641]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.828, train_acc=0.928, train_loss=3.15, train_precision=0.824, train_recall=0.833]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.619, eval_acc=0.826, eval_loss=8.45, eval_precision=0.63, eval_recall=0.611] \n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.842, train_acc=0.935, train_loss=2.96, train_precision=0.838, train_recall=0.847]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.594, eval_acc=0.803, eval_loss=8.98, eval_precision=0.62, eval_recall=0.572] \n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.85, train_acc=0.938, train_loss=2.85, train_precision=0.846, train_recall=0.855] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.597, eval_acc=0.799, eval_loss=9.39, eval_precision=0.598, eval_recall=0.599]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.857, train_acc=0.94, train_loss=2.77, train_precision=0.854, train_recall=0.861] \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.634, eval_acc=0.834, eval_loss=9.47, eval_precision=0.631, eval_recall=0.641]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.866, train_acc=0.945, train_loss=2.59, train_precision=0.863, train_recall=0.869]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.637, eval_acc=0.835, eval_loss=10.8, eval_precision=0.619, eval_recall=0.659]\n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.881, train_acc=0.952, train_loss=2.32, train_precision=0.877, train_recall=0.885]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.636, eval_acc=0.837, eval_loss=10.4, eval_precision=0.621, eval_recall=0.656]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.894, train_acc=0.959, train_loss=2.08, train_precision=0.89, train_recall=0.898] \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.632, eval_acc=0.833, eval_loss=11.2, eval_precision=0.608, eval_recall=0.662]\n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.9, train_acc=0.961, train_loss=2.03, train_precision=0.898, train_recall=0.903]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.64, eval_acc=0.839, eval_loss=12.2, eval_precision=0.612, eval_recall=0.672] \n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.903, train_acc=0.962, train_loss=1.96, train_precision=0.901, train_recall=0.906]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.634, eval_acc=0.838, eval_loss=13.6, eval_precision=0.62, eval_recall=0.651] \n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.905, train_acc=0.962, train_loss=1.94, train_precision=0.904, train_recall=0.908]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.632, eval_acc=0.837, eval_loss=14.2, eval_precision=0.63, eval_recall=0.636] \n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.91, train_acc=0.964, train_loss=1.88, train_precision=0.908, train_recall=0.911] \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.623, eval_acc=0.828, eval_loss=13.7, eval_precision=0.654, eval_recall=0.598]\n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.916, train_acc=0.966, train_loss=1.75, train_precision=0.913, train_recall=0.918]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.626, eval_acc=0.833, eval_loss=12.3, eval_precision=0.652, eval_recall=0.605]\n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.925, train_acc=0.971, train_loss=1.55, train_precision=0.922, train_recall=0.928]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.632, eval_acc=0.834, eval_loss=12.4, eval_precision=0.624, eval_recall=0.642]\n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.934, train_acc=0.975, train_loss=1.39, train_precision=0.932, train_recall=0.936]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.628, eval_acc=0.833, eval_loss=13.2, eval_precision=0.613, eval_recall=0.646]\n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.94, train_acc=0.978, train_loss=1.28, train_precision=0.939, train_recall=0.941] \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.63, eval_acc=0.835, eval_loss=14, eval_precision=0.607, eval_recall=0.658]   \n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.945, train_acc=0.98, train_loss=1.22, train_precision=0.943, train_recall=0.946] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.625, eval_acc=0.828, eval_loss=13.7, eval_precision=0.608, eval_recall=0.646]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.949, train_acc=0.981, train_loss=1.16, train_precision=0.948, train_recall=0.95] \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.619, eval_acc=0.826, eval_loss=16.1, eval_precision=0.594, eval_recall=0.649]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.952, train_acc=0.983, train_loss=1.08, train_precision=0.951, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.631, eval_acc=0.831, eval_loss=15.2, eval_precision=0.611, eval_recall=0.654]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.95, train_acc=0.982, train_loss=1.1, train_precision=0.949, train_recall=0.951]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.632, eval_acc=0.83, eval_loss=15.1, eval_precision=0.612, eval_recall=0.655] \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_v4_tx_3'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v4_tx_4\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 332MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 355MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 348MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 280kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 33483.94L/s]\n",
      "build line mapper: 19L [00:00, 33767.70L/s]9 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 5088.22it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 56438.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:17<00:00, 857.47it/s] \n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:05<00:00, 849.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.278, train_acc=0.738, train_loss=44.5, train_precision=0.242, train_recall=0.333]       \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.547, eval_acc=0.831, eval_loss=18.7, eval_precision=0.502, eval_recall=0.603]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.615, train_acc=0.839, train_loss=12.8, train_precision=0.604, train_recall=0.628]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.635, eval_acc=0.84, eval_loss=10.7, eval_precision=0.622, eval_recall=0.65]  \n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [04:12<00:00,  1.07s/it, F1=0.671, train_acc=0.851, train_loss=8.29, train_precision=0.672, train_recall=0.672]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.64, eval_acc=0.839, eval_loss=9.1, eval_precision=0.631, eval_recall=0.652]  \n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.695, train_acc=0.862, train_loss=6.61, train_precision=0.695, train_recall=0.696]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.645, eval_acc=0.84, eval_loss=7.64, eval_precision=0.622, eval_recall=0.673] \n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.711, train_acc=0.869, train_loss=5.8, train_precision=0.711, train_recall=0.712] \n",
      "Eval Result: 100%|██████████| 79/79 [00:49<00:00,  1.59it/s, F1=0.648, eval_acc=0.843, eval_loss=7.35, eval_precision=0.637, eval_recall=0.661]\n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [04:50<00:00,  1.24s/it, F1=0.731, train_acc=0.88, train_loss=5.15, train_precision=0.729, train_recall=0.733] \n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, F1=0.644, eval_acc=0.842, eval_loss=7.85, eval_precision=0.642, eval_recall=0.648]\n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [04:52<00:00,  1.24s/it, F1=0.748, train_acc=0.889, train_loss=4.68, train_precision=0.746, train_recall=0.751]\n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.67it/s, F1=0.641, eval_acc=0.839, eval_loss=7.95, eval_precision=0.636, eval_recall=0.649]\n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [04:30<00:00,  1.15s/it, F1=0.759, train_acc=0.895, train_loss=4.41, train_precision=0.756, train_recall=0.763]\n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.67it/s, F1=0.632, eval_acc=0.832, eval_loss=8.17, eval_precision=0.613, eval_recall=0.654]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [04:34<00:00,  1.17s/it, F1=0.776, train_acc=0.904, train_loss=4.04, train_precision=0.773, train_recall=0.779]\n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.52it/s, F1=0.633, eval_acc=0.834, eval_loss=8.07, eval_precision=0.621, eval_recall=0.647]\n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [04:29<00:00,  1.15s/it, F1=0.791, train_acc=0.911, train_loss=3.8, train_precision=0.787, train_recall=0.795] \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.76it/s, F1=0.631, eval_acc=0.835, eval_loss=8.49, eval_precision=0.637, eval_recall=0.627]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.808, train_acc=0.92, train_loss=3.46, train_precision=0.804, train_recall=0.813] \n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.73it/s, F1=0.621, eval_acc=0.827, eval_loss=9.55, eval_precision=0.665, eval_recall=0.586]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.819, train_acc=0.924, train_loss=3.32, train_precision=0.815, train_recall=0.824]\n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.75it/s, F1=0.625, eval_acc=0.83, eval_loss=8.54, eval_precision=0.637, eval_recall=0.616] \n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:22<00:00,  1.12s/it, F1=0.832, train_acc=0.929, train_loss=3.11, train_precision=0.829, train_recall=0.836]\n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.76it/s, F1=0.631, eval_acc=0.834, eval_loss=9.47, eval_precision=0.631, eval_recall=0.634]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [04:21<00:00,  1.11s/it, F1=0.843, train_acc=0.936, train_loss=2.88, train_precision=0.839, train_recall=0.848]\n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.74it/s, F1=0.634, eval_acc=0.835, eval_loss=10.1, eval_precision=0.636, eval_recall=0.634]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [04:21<00:00,  1.11s/it, F1=0.852, train_acc=0.939, train_loss=2.78, train_precision=0.848, train_recall=0.856]\n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.76it/s, F1=0.625, eval_acc=0.829, eval_loss=9.68, eval_precision=0.656, eval_recall=0.599]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [04:22<00:00,  1.12s/it, F1=0.866, train_acc=0.946, train_loss=2.54, train_precision=0.862, train_recall=0.87] \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.77it/s, F1=0.606, eval_acc=0.813, eval_loss=10.6, eval_precision=0.616, eval_recall=0.6]  \n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [04:22<00:00,  1.11s/it, F1=0.873, train_acc=0.949, train_loss=2.43, train_precision=0.871, train_recall=0.876]\n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.76it/s, F1=0.625, eval_acc=0.822, eval_loss=9.81, eval_precision=0.611, eval_recall=0.642]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [04:21<00:00,  1.11s/it, F1=0.88, train_acc=0.951, train_loss=2.32, train_precision=0.877, train_recall=0.883] \n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.75it/s, F1=0.637, eval_acc=0.838, eval_loss=10.7, eval_precision=0.629, eval_recall=0.648]\n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [04:22<00:00,  1.12s/it, F1=0.892, train_acc=0.957, train_loss=2.1, train_precision=0.89, train_recall=0.895]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.77it/s, F1=0.631, eval_acc=0.835, eval_loss=11.9, eval_precision=0.638, eval_recall=0.627]\n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:21<00:00,  1.11s/it, F1=0.902, train_acc=0.962, train_loss=1.91, train_precision=0.9, train_recall=0.906]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.77it/s, F1=0.618, eval_acc=0.827, eval_loss=12.8, eval_precision=0.67, eval_recall=0.577] \n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.91, train_acc=0.965, train_loss=1.81, train_precision=0.907, train_recall=0.914] \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.77it/s, F1=0.612, eval_acc=0.825, eval_loss=11.5, eval_precision=0.654, eval_recall=0.578]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:21<00:00,  1.11s/it, F1=0.914, train_acc=0.968, train_loss=1.71, train_precision=0.912, train_recall=0.917]\n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.77it/s, F1=0.624, eval_acc=0.832, eval_loss=12.2, eval_precision=0.64, eval_recall=0.611] \n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:22<00:00,  1.12s/it, F1=0.921, train_acc=0.97, train_loss=1.6, train_precision=0.918, train_recall=0.924]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.76it/s, F1=0.629, eval_acc=0.832, eval_loss=12.3, eval_precision=0.617, eval_recall=0.644]\n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:29<00:00,  1.15s/it, F1=0.926, train_acc=0.972, train_loss=1.51, train_precision=0.924, train_recall=0.928]\n",
      "Eval Result: 100%|██████████| 79/79 [00:58<00:00,  1.34it/s, F1=0.634, eval_acc=0.834, eval_loss=12.5, eval_precision=0.614, eval_recall=0.657]\n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:37<00:00,  1.18s/it, F1=0.93, train_acc=0.974, train_loss=1.44, train_precision=0.929, train_recall=0.932] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.632, eval_acc=0.837, eval_loss=13.7, eval_precision=0.612, eval_recall=0.655]\n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.937, train_acc=0.977, train_loss=1.35, train_precision=0.935, train_recall=0.939]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.63, eval_acc=0.836, eval_loss=14.2, eval_precision=0.625, eval_recall=0.639] \n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.938, train_acc=0.977, train_loss=1.31, train_precision=0.937, train_recall=0.941]\n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.36it/s, F1=0.629, eval_acc=0.834, eval_loss=13, eval_precision=0.626, eval_recall=0.635]  \n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [05:35<00:00,  1.43s/it, F1=0.944, train_acc=0.979, train_loss=1.21, train_precision=0.942, train_recall=0.946]\n",
      "Eval Result: 100%|██████████| 79/79 [01:07<00:00,  1.17it/s, F1=0.626, eval_acc=0.831, eval_loss=12.9, eval_precision=0.639, eval_recall=0.616]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [05:24<00:00,  1.38s/it, F1=0.946, train_acc=0.98, train_loss=1.17, train_precision=0.945, train_recall=0.948] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.624, eval_acc=0.827, eval_loss=13.7, eval_precision=0.632, eval_recall=0.618]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.947, train_acc=0.98, train_loss=1.2, train_precision=0.945, train_recall=0.949]  \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.27it/s, F1=0.602, eval_acc=0.813, eval_loss=14, eval_precision=0.636, eval_recall=0.574]  \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_v4_tx_4'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v4_tx_5\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 221MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 234MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 250MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 180kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 102038.13L/s]\n",
      "build line mapper: 19L [00:00, 79453.42L/s]9 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 2719.58it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 112718.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:37<00:00, 401.34it/s]\n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:13<00:00, 377.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [05:20<00:00,  1.37s/it, F1=0.345, train_acc=0.744, train_loss=41.8, train_precision=0.311, train_recall=0.393]       \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.572, eval_acc=0.827, eval_loss=16.7, eval_precision=0.601, eval_recall=0.549]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [05:16<00:00,  1.35s/it, F1=0.633, train_acc=0.841, train_loss=12.1, train_precision=0.629, train_recall=0.639]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.612, eval_acc=0.823, eval_loss=10.4, eval_precision=0.646, eval_recall=0.586]\n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [05:15<00:00,  1.34s/it, F1=0.671, train_acc=0.853, train_loss=7.92, train_precision=0.671, train_recall=0.673]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.636, eval_acc=0.833, eval_loss=8.38, eval_precision=0.651, eval_recall=0.626]\n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [05:15<00:00,  1.34s/it, F1=0.696, train_acc=0.864, train_loss=6.4, train_precision=0.695, train_recall=0.698] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.624, eval_acc=0.826, eval_loss=7.88, eval_precision=0.629, eval_recall=0.623]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [05:10<00:00,  1.32s/it, F1=0.712, train_acc=0.871, train_loss=5.66, train_precision=0.711, train_recall=0.714]\n",
      "Eval Result: 100%|██████████| 79/79 [00:58<00:00,  1.36it/s, F1=0.621, eval_acc=0.819, eval_loss=7.81, eval_precision=0.634, eval_recall=0.612]\n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [04:59<00:00,  1.28s/it, F1=0.732, train_acc=0.88, train_loss=5.12, train_precision=0.729, train_recall=0.736] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.629, eval_acc=0.823, eval_loss=7.59, eval_precision=0.631, eval_recall=0.63] \n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [05:13<00:00,  1.34s/it, F1=0.749, train_acc=0.887, train_loss=4.69, train_precision=0.747, train_recall=0.753]\n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, F1=0.595, eval_acc=0.784, eval_loss=8.15, eval_precision=0.587, eval_recall=0.607]\n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [05:13<00:00,  1.33s/it, F1=0.767, train_acc=0.899, train_loss=4.2, train_precision=0.763, train_recall=0.772] \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.624, eval_acc=0.816, eval_loss=7.59, eval_precision=0.616, eval_recall=0.635]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [05:08<00:00,  1.31s/it, F1=0.79, train_acc=0.911, train_loss=3.78, train_precision=0.785, train_recall=0.795] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.629, eval_acc=0.825, eval_loss=8.07, eval_precision=0.62, eval_recall=0.642] \n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [05:07<00:00,  1.31s/it, F1=0.802, train_acc=0.916, train_loss=3.61, train_precision=0.798, train_recall=0.808]\n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.70it/s, F1=0.64, eval_acc=0.833, eval_loss=8.15, eval_precision=0.629, eval_recall=0.656] \n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:44<00:00,  1.21s/it, F1=0.805, train_acc=0.915, train_loss=3.59, train_precision=0.803, train_recall=0.809]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.637, eval_acc=0.835, eval_loss=8.88, eval_precision=0.64, eval_recall=0.636] \n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [05:15<00:00,  1.34s/it, F1=0.813, train_acc=0.918, train_loss=3.49, train_precision=0.81, train_recall=0.817] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.635, eval_acc=0.831, eval_loss=9.67, eval_precision=0.642, eval_recall=0.631]\n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [05:20<00:00,  1.36s/it, F1=0.835, train_acc=0.931, train_loss=3, train_precision=0.832, train_recall=0.84]    \n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.30it/s, F1=0.644, eval_acc=0.838, eval_loss=8.75, eval_precision=0.634, eval_recall=0.657]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [05:27<00:00,  1.40s/it, F1=0.856, train_acc=0.942, train_loss=2.6, train_precision=0.852, train_recall=0.861] \n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.46it/s, F1=0.64, eval_acc=0.837, eval_loss=8.78, eval_precision=0.626, eval_recall=0.658] \n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.874, train_acc=0.95, train_loss=2.35, train_precision=0.87, train_recall=0.879]  \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.641, eval_acc=0.838, eval_loss=9.85, eval_precision=0.621, eval_recall=0.665]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [05:15<00:00,  1.34s/it, F1=0.883, train_acc=0.954, train_loss=2.2, train_precision=0.88, train_recall=0.887]  \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.636, eval_acc=0.832, eval_loss=9.73, eval_precision=0.615, eval_recall=0.66] \n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [05:15<00:00,  1.34s/it, F1=0.891, train_acc=0.957, train_loss=2.13, train_precision=0.887, train_recall=0.895]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.639, eval_acc=0.836, eval_loss=10.5, eval_precision=0.617, eval_recall=0.665]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [05:17<00:00,  1.35s/it, F1=0.897, train_acc=0.96, train_loss=2, train_precision=0.895, train_recall=0.901]    \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.636, eval_acc=0.834, eval_loss=11, eval_precision=0.613, eval_recall=0.663]  \n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.904, train_acc=0.962, train_loss=1.95, train_precision=0.901, train_recall=0.907]\n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.41it/s, F1=0.629, eval_acc=0.828, eval_loss=11.6, eval_precision=0.603, eval_recall=0.661]\n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [05:24<00:00,  1.38s/it, F1=0.904, train_acc=0.962, train_loss=1.95, train_precision=0.902, train_recall=0.907]\n",
      "Eval Result: 100%|██████████| 79/79 [00:56<00:00,  1.40it/s, F1=0.626, eval_acc=0.823, eval_loss=11.5, eval_precision=0.597, eval_recall=0.659]\n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.905, train_acc=0.963, train_loss=1.92, train_precision=0.903, train_recall=0.907]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.623, eval_acc=0.829, eval_loss=12.6, eval_precision=0.601, eval_recall=0.649]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [05:14<00:00,  1.34s/it, F1=0.907, train_acc=0.962, train_loss=1.93, train_precision=0.904, train_recall=0.909]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.631, eval_acc=0.833, eval_loss=12.3, eval_precision=0.621, eval_recall=0.643]\n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [05:01<00:00,  1.28s/it, F1=0.912, train_acc=0.963, train_loss=1.83, train_precision=0.91, train_recall=0.914] \n",
      "Eval Result: 100%|██████████| 79/79 [00:56<00:00,  1.40it/s, F1=0.629, eval_acc=0.831, eval_loss=12.6, eval_precision=0.62, eval_recall=0.641] \n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [05:01<00:00,  1.28s/it, F1=0.922, train_acc=0.969, train_loss=1.6, train_precision=0.92, train_recall=0.924]  \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.632, eval_acc=0.833, eval_loss=11.9, eval_precision=0.617, eval_recall=0.65] \n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [05:12<00:00,  1.33s/it, F1=0.93, train_acc=0.973, train_loss=1.4, train_precision=0.929, train_recall=0.933]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.57it/s, F1=0.631, eval_acc=0.834, eval_loss=12.6, eval_precision=0.62, eval_recall=0.646] \n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [05:14<00:00,  1.34s/it, F1=0.935, train_acc=0.976, train_loss=1.31, train_precision=0.934, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.627, eval_acc=0.832, eval_loss=12.8, eval_precision=0.641, eval_recall=0.616]\n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [05:10<00:00,  1.32s/it, F1=0.943, train_acc=0.978, train_loss=1.22, train_precision=0.941, train_recall=0.945]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.627, eval_acc=0.83, eval_loss=12.7, eval_precision=0.644, eval_recall=0.614] \n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [05:01<00:00,  1.28s/it, F1=0.948, train_acc=0.98, train_loss=1.13, train_precision=0.946, train_recall=0.949] \n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.43it/s, F1=0.627, eval_acc=0.827, eval_loss=13.6, eval_precision=0.641, eval_recall=0.618]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [05:06<00:00,  1.31s/it, F1=0.951, train_acc=0.981, train_loss=1.08, train_precision=0.949, train_recall=0.952]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, F1=0.61, eval_acc=0.818, eval_loss=13.7, eval_precision=0.624, eval_recall=0.6]   \n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [05:07<00:00,  1.31s/it, F1=0.953, train_acc=0.983, train_loss=1.03, train_precision=0.952, train_recall=0.955]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.632, eval_acc=0.83, eval_loss=13.8, eval_precision=0.628, eval_recall=0.639] \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_v4_tx_5'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v4_16_1\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 85.9MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 155MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 69.5MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 36.9kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 9000.65L/s]\n",
      "build line mapper: 4L [00:00, 28244.47L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 985.91it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 25420.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:09<00:00, 561.17it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:01<00:00, 573.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [03:28<00:00,  1.67it/s, F1=0.162, train_acc=0.908, train_loss=24.4, train_precision=0.147, train_recall=0.205]        \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.65it/s, F1=0.547, eval_acc=0.939, eval_loss=9.75, eval_precision=0.63, eval_recall=0.487] \n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [03:25<00:00,  1.70it/s, F1=0.61, train_acc=0.951, train_loss=5.33, train_precision=0.639, train_recall=0.603] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.27it/s, F1=0.595, eval_acc=0.939, eval_loss=7.48, eval_precision=0.659, eval_recall=0.547]\n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [03:11<00:00,  1.82it/s, F1=0.673, train_acc=0.959, train_loss=3.11, train_precision=0.705, train_recall=0.657]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.612, eval_acc=0.941, eval_loss=6.78, eval_precision=0.684, eval_recall=0.558]\n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [03:32<00:00,  1.65it/s, F1=0.721, train_acc=0.965, train_loss=2.37, train_precision=0.747, train_recall=0.712]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.595, eval_acc=0.939, eval_loss=7.07, eval_precision=0.701, eval_recall=0.52] \n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.751, train_acc=0.97, train_loss=1.94, train_precision=0.767, train_recall=0.747] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.61, eval_acc=0.94, eval_loss=6.54, eval_precision=0.684, eval_recall=0.553]  \n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.761, train_acc=0.97, train_loss=1.85, train_precision=0.777, train_recall=0.761] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.20it/s, F1=0.57, eval_acc=0.936, eval_loss=8.31, eval_precision=0.727, eval_recall=0.47]  \n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:32<00:00,  1.64it/s, F1=0.779, train_acc=0.972, train_loss=1.69, train_precision=0.799, train_recall=0.774]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.612, eval_acc=0.938, eval_loss=6.09, eval_precision=0.641, eval_recall=0.589]\n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [03:27<00:00,  1.68it/s, F1=0.817, train_acc=0.978, train_loss=1.42, train_precision=0.826, train_recall=0.818]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.576, eval_acc=0.914, eval_loss=8.88, eval_precision=0.528, eval_recall=0.635]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:25<00:00,  1.70it/s, F1=0.829, train_acc=0.979, train_loss=1.31, train_precision=0.843, train_recall=0.826]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.61, eval_acc=0.935, eval_loss=8.72, eval_precision=0.61, eval_recall=0.612]  \n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [03:30<00:00,  1.66it/s, F1=0.847, train_acc=0.982, train_loss=1.19, train_precision=0.857, train_recall=0.845]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.606, eval_acc=0.936, eval_loss=8.23, eval_precision=0.626, eval_recall=0.59] \n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [03:30<00:00,  1.65it/s, F1=0.859, train_acc=0.984, train_loss=1.06, train_precision=0.867, train_recall=0.859]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s, F1=0.598, eval_acc=0.937, eval_loss=8.46, eval_precision=0.674, eval_recall=0.54] \n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [03:17<00:00,  1.77it/s, F1=0.877, train_acc=0.985, train_loss=0.998, train_precision=0.881, train_recall=0.878]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.32it/s, F1=0.576, eval_acc=0.934, eval_loss=11.5, eval_precision=0.72, eval_recall=0.483] \n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [03:18<00:00,  1.76it/s, F1=0.872, train_acc=0.985, train_loss=0.995, train_precision=0.879, train_recall=0.873]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, F1=0.573, eval_acc=0.935, eval_loss=10.8, eval_precision=0.7, eval_recall=0.488]  \n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [03:30<00:00,  1.66it/s, F1=0.899, train_acc=0.988, train_loss=0.8, train_precision=0.898, train_recall=0.903]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.604, eval_acc=0.938, eval_loss=9.38, eval_precision=0.699, eval_recall=0.534]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [03:26<00:00,  1.69it/s, F1=0.901, train_acc=0.989, train_loss=0.757, train_precision=0.905, train_recall=0.9]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.605, eval_acc=0.94, eval_loss=8.72, eval_precision=0.69, eval_recall=0.542]  \n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:30<00:00,  1.66it/s, F1=0.911, train_acc=0.99, train_loss=0.708, train_precision=0.912, train_recall=0.913] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.598, eval_acc=0.939, eval_loss=8.2, eval_precision=0.685, eval_recall=0.533] \n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [03:32<00:00,  1.64it/s, F1=0.916, train_acc=0.991, train_loss=0.668, train_precision=0.918, train_recall=0.918]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, F1=0.592, eval_acc=0.938, eval_loss=7.92, eval_precision=0.686, eval_recall=0.524]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [03:34<00:00,  1.63it/s, F1=0.923, train_acc=0.991, train_loss=0.616, train_precision=0.925, train_recall=0.924]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.596, eval_acc=0.937, eval_loss=9, eval_precision=0.715, eval_recall=0.513]   \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:27<00:00,  1.68it/s, F1=0.924, train_acc=0.991, train_loss=0.628, train_precision=0.926, train_recall=0.924]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.615, eval_acc=0.942, eval_loss=8.67, eval_precision=0.724, eval_recall=0.537]\n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:33<00:00,  1.63it/s, F1=0.929, train_acc=0.992, train_loss=0.563, train_precision=0.931, train_recall=0.931]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.595, eval_acc=0.938, eval_loss=9.49, eval_precision=0.693, eval_recall=0.525]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [03:18<00:00,  1.76it/s, F1=0.94, train_acc=0.993, train_loss=0.488, train_precision=0.941, train_recall=0.941] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.28it/s, F1=0.62, eval_acc=0.941, eval_loss=9.11, eval_precision=0.696, eval_recall=0.562]\n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [02:43<00:00,  2.13it/s, F1=0.936, train_acc=0.992, train_loss=0.561, train_precision=0.939, train_recall=0.936]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s, F1=0.606, eval_acc=0.938, eval_loss=9.96, eval_precision=0.685, eval_recall=0.546]\n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.944, train_acc=0.994, train_loss=0.482, train_precision=0.948, train_recall=0.942]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.608, eval_acc=0.941, eval_loss=11.5, eval_precision=0.69, eval_recall=0.545] \n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:12<00:00,  1.81it/s, F1=0.945, train_acc=0.994, train_loss=0.466, train_precision=0.948, train_recall=0.944]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.26it/s, F1=0.615, eval_acc=0.942, eval_loss=10.2, eval_precision=0.703, eval_recall=0.55] \n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [02:49<00:00,  2.06it/s, F1=0.944, train_acc=0.994, train_loss=0.468, train_precision=0.947, train_recall=0.942]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.599, eval_acc=0.939, eval_loss=10.4, eval_precision=0.699, eval_recall=0.526]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.95, train_acc=0.995, train_loss=0.378, train_precision=0.952, train_recall=0.949] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.604, eval_acc=0.941, eval_loss=12.4, eval_precision=0.714, eval_recall=0.526]\n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [03:28<00:00,  1.67it/s, F1=0.952, train_acc=0.995, train_loss=0.432, train_precision=0.953, train_recall=0.952]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.607, eval_acc=0.94, eval_loss=11.9, eval_precision=0.682, eval_recall=0.549]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.55it/s, F1=0.959, train_acc=0.996, train_loss=0.325, train_precision=0.961, train_recall=0.959]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, F1=0.596, eval_acc=0.937, eval_loss=13.3, eval_precision=0.649, eval_recall=0.554]\n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [03:28<00:00,  1.68it/s, F1=0.957, train_acc=0.995, train_loss=0.36, train_precision=0.958, train_recall=0.957] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.606, eval_acc=0.939, eval_loss=13.2, eval_precision=0.707, eval_recall=0.533]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.60it/s, F1=0.962, train_acc=0.996, train_loss=0.33, train_precision=0.963, train_recall=0.962] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.608, eval_acc=0.941, eval_loss=14.4, eval_precision=0.697, eval_recall=0.542]\n"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/CDD/train.json',\n",
    "    'eval_file': './data/CDD/dev.json',\n",
    "    'test_file': './data/CDD/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    # 'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/tencent_medicine_vocab.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    # \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert_v4',\n",
    "    'task_name': 'cdd_v4_16_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v4_16_2\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 331MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 327MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 331MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 112kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 7584.64L/s]\n",
      "build line mapper: 4L [00:00, 10831.00L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 611.01it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 11086.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:19<00:00, 287.56it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:03<00:00, 301.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.304, train_acc=0.927, train_loss=14.4, train_precision=0.316, train_recall=0.321]        \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s, F1=0.551, eval_acc=0.931, eval_loss=7.2, eval_precision=0.562, eval_recall=0.542] \n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [03:29<00:00,  1.67it/s, F1=0.638, train_acc=0.953, train_loss=4.08, train_precision=0.69, train_recall=0.61]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.574, eval_acc=0.922, eval_loss=6.38, eval_precision=0.577, eval_recall=0.574]\n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [03:41<00:00,  1.58it/s, F1=0.688, train_acc=0.959, train_loss=2.81, train_precision=0.729, train_recall=0.665]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.552, eval_acc=0.904, eval_loss=6.43, eval_precision=0.533, eval_recall=0.576]\n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [03:36<00:00,  1.61it/s, F1=0.73, train_acc=0.964, train_loss=2.28, train_precision=0.763, train_recall=0.714] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.577, eval_acc=0.921, eval_loss=6, eval_precision=0.575, eval_recall=0.583]   \n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.75, train_acc=0.969, train_loss=2.03, train_precision=0.777, train_recall=0.738] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.58, eval_acc=0.923, eval_loss=6.25, eval_precision=0.588, eval_recall=0.575] \n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.55it/s, F1=0.772, train_acc=0.971, train_loss=1.84, train_precision=0.793, train_recall=0.762]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.57, eval_acc=0.925, eval_loss=6.59, eval_precision=0.609, eval_recall=0.539] \n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.799, train_acc=0.975, train_loss=1.6, train_precision=0.81, train_recall=0.797]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.601, eval_acc=0.939, eval_loss=7.67, eval_precision=0.71, eval_recall=0.524] \n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [03:34<00:00,  1.62it/s, F1=0.819, train_acc=0.977, train_loss=1.45, train_precision=0.833, train_recall=0.815]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.574, eval_acc=0.938, eval_loss=7.97, eval_precision=0.764, eval_recall=0.462]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.827, train_acc=0.978, train_loss=1.4, train_precision=0.843, train_recall=0.823] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.601, eval_acc=0.939, eval_loss=7.86, eval_precision=0.723, eval_recall=0.518]\n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [03:29<00:00,  1.67it/s, F1=0.854, train_acc=0.983, train_loss=1.2, train_precision=0.858, train_recall=0.854] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.582, eval_acc=0.939, eval_loss=6.31, eval_precision=0.701, eval_recall=0.5]  \n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.56it/s, F1=0.871, train_acc=0.985, train_loss=1.06, train_precision=0.876, train_recall=0.87] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.15it/s, F1=0.59, eval_acc=0.937, eval_loss=7.72, eval_precision=0.682, eval_recall=0.523] \n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [03:14<00:00,  1.80it/s, F1=0.884, train_acc=0.986, train_loss=1, train_precision=0.887, train_recall=0.885]    \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.28it/s, F1=0.595, eval_acc=0.935, eval_loss=6.74, eval_precision=0.636, eval_recall=0.56] \n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [02:56<00:00,  1.98it/s, F1=0.892, train_acc=0.988, train_loss=0.933, train_precision=0.895, train_recall=0.892]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.604, eval_acc=0.938, eval_loss=7.83, eval_precision=0.651, eval_recall=0.567]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [02:53<00:00,  2.02it/s, F1=0.891, train_acc=0.987, train_loss=0.909, train_precision=0.894, train_recall=0.891]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.61, eval_acc=0.941, eval_loss=8.55, eval_precision=0.704, eval_recall=0.54]  \n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.895, train_acc=0.988, train_loss=0.882, train_precision=0.898, train_recall=0.896]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.595, eval_acc=0.94, eval_loss=9.27, eval_precision=0.698, eval_recall=0.521] \n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.54it/s, F1=0.903, train_acc=0.989, train_loss=0.805, train_precision=0.905, train_recall=0.903]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.593, eval_acc=0.94, eval_loss=9.58, eval_precision=0.711, eval_recall=0.511] \n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.917, train_acc=0.991, train_loss=0.702, train_precision=0.92, train_recall=0.918] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.587, eval_acc=0.939, eval_loss=10.3, eval_precision=0.701, eval_recall=0.507]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [03:47<00:00,  1.53it/s, F1=0.919, train_acc=0.991, train_loss=0.705, train_precision=0.922, train_recall=0.918]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.589, eval_acc=0.94, eval_loss=9.62, eval_precision=0.732, eval_recall=0.494] \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.55it/s, F1=0.926, train_acc=0.992, train_loss=0.645, train_precision=0.929, train_recall=0.926]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.588, eval_acc=0.938, eval_loss=10.6, eval_precision=0.735, eval_recall=0.493]\n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:29<00:00,  1.67it/s, F1=0.934, train_acc=0.992, train_loss=0.581, train_precision=0.935, train_recall=0.935]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.595, eval_acc=0.939, eval_loss=9.48, eval_precision=0.719, eval_recall=0.509]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.56it/s, F1=0.93, train_acc=0.991, train_loss=0.611, train_precision=0.934, train_recall=0.928] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.6, eval_acc=0.941, eval_loss=9.1, eval_precision=0.703, eval_recall=0.526]   \n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.56it/s, F1=0.938, train_acc=0.993, train_loss=0.514, train_precision=0.94, train_recall=0.938] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.588, eval_acc=0.94, eval_loss=10.4, eval_precision=0.689, eval_recall=0.514] \n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [03:26<00:00,  1.69it/s, F1=0.939, train_acc=0.993, train_loss=0.505, train_precision=0.942, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.606, eval_acc=0.941, eval_loss=9.94, eval_precision=0.702, eval_recall=0.536]\n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.938, train_acc=0.993, train_loss=0.521, train_precision=0.939, train_recall=0.939]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.20it/s, F1=0.611, eval_acc=0.941, eval_loss=9.76, eval_precision=0.671, eval_recall=0.565]\n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.943, train_acc=0.994, train_loss=0.451, train_precision=0.945, train_recall=0.943]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.614, eval_acc=0.942, eval_loss=10.9, eval_precision=0.691, eval_recall=0.554]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.95, train_acc=0.995, train_loss=0.42, train_precision=0.953, train_recall=0.949]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.605, eval_acc=0.938, eval_loss=10.2, eval_precision=0.656, eval_recall=0.565]\n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.55it/s, F1=0.951, train_acc=0.994, train_loss=0.434, train_precision=0.953, train_recall=0.951]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.598, eval_acc=0.94, eval_loss=11.3, eval_precision=0.677, eval_recall=0.539] \n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.952, train_acc=0.995, train_loss=0.419, train_precision=0.954, train_recall=0.951]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.596, eval_acc=0.94, eval_loss=9.75, eval_precision=0.7, eval_recall=0.522]   \n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [03:29<00:00,  1.66it/s, F1=0.955, train_acc=0.995, train_loss=0.372, train_precision=0.957, train_recall=0.954]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.593, eval_acc=0.939, eval_loss=9.75, eval_precision=0.681, eval_recall=0.528]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [03:41<00:00,  1.57it/s, F1=0.95, train_acc=0.995, train_loss=0.425, train_precision=0.954, train_recall=0.949] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.593, eval_acc=0.938, eval_loss=11.8, eval_precision=0.67, eval_recall=0.534] \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_v4_16_2'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v4_16_3\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 314MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 306MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 317MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 42.8kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 6465.21L/s]\n",
      "build line mapper: 4L [00:00, 19996.68L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 862.80it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 23301.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:19<00:00, 289.50it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:02<00:00, 328.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [03:25<00:00,  1.69it/s, F1=0.341, train_acc=0.9, train_loss=17.1, train_precision=0.415, train_recall=0.311]         \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.562, eval_acc=0.938, eval_loss=6.11, eval_precision=0.691, eval_recall=0.477]\n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [03:41<00:00,  1.58it/s, F1=0.585, train_acc=0.947, train_loss=3.83, train_precision=0.665, train_recall=0.567]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.57, eval_acc=0.937, eval_loss=6.19, eval_precision=0.725, eval_recall=0.473] \n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [03:41<00:00,  1.57it/s, F1=0.657, train_acc=0.954, train_loss=2.84, train_precision=0.705, train_recall=0.644]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.602, eval_acc=0.935, eval_loss=5.21, eval_precision=0.62, eval_recall=0.589] \n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [03:25<00:00,  1.69it/s, F1=0.705, train_acc=0.96, train_loss=2.34, train_precision=0.738, train_recall=0.698] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.612, eval_acc=0.943, eval_loss=5.56, eval_precision=0.685, eval_recall=0.556]\n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.55it/s, F1=0.737, train_acc=0.965, train_loss=2.02, train_precision=0.764, train_recall=0.732]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.605, eval_acc=0.934, eval_loss=6.26, eval_precision=0.622, eval_recall=0.591]\n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.763, train_acc=0.969, train_loss=1.79, train_precision=0.785, train_recall=0.76] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.584, eval_acc=0.929, eval_loss=6.15, eval_precision=0.609, eval_recall=0.563]\n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:29<00:00,  1.67it/s, F1=0.799, train_acc=0.974, train_loss=1.53, train_precision=0.813, train_recall=0.798]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.612, eval_acc=0.939, eval_loss=6.64, eval_precision=0.679, eval_recall=0.56] \n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.826, train_acc=0.978, train_loss=1.27, train_precision=0.831, train_recall=0.83] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.605, eval_acc=0.939, eval_loss=7.15, eval_precision=0.655, eval_recall=0.566]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.846, train_acc=0.981, train_loss=1.16, train_precision=0.849, train_recall=0.851]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.605, eval_acc=0.937, eval_loss=6.8, eval_precision=0.629, eval_recall=0.585] \n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [03:25<00:00,  1.70it/s, F1=0.852, train_acc=0.982, train_loss=1.14, train_precision=0.856, train_recall=0.858]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.602, eval_acc=0.94, eval_loss=7.6, eval_precision=0.648, eval_recall=0.565]  \n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.843, train_acc=0.979, train_loss=1.34, train_precision=0.854, train_recall=0.846]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s, F1=0.582, eval_acc=0.939, eval_loss=9, eval_precision=0.698, eval_recall=0.502]   \n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [03:41<00:00,  1.58it/s, F1=0.857, train_acc=0.981, train_loss=1.18, train_precision=0.863, train_recall=0.861]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.589, eval_acc=0.939, eval_loss=8.3, eval_precision=0.715, eval_recall=0.504] \n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [03:16<00:00,  1.77it/s, F1=0.892, train_acc=0.987, train_loss=0.781, train_precision=0.895, train_recall=0.894]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.30it/s, F1=0.607, eval_acc=0.939, eval_loss=9.02, eval_precision=0.691, eval_recall=0.544]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [02:46<00:00,  2.10it/s, F1=0.911, train_acc=0.989, train_loss=0.676, train_precision=0.91, train_recall=0.914] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.599, eval_acc=0.937, eval_loss=7.82, eval_precision=0.651, eval_recall=0.557]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.22it/s, F1=0.919, train_acc=0.99, train_loss=0.61, train_precision=0.92, train_recall=0.921]   \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s, F1=0.601, eval_acc=0.937, eval_loss=7.86, eval_precision=0.643, eval_recall=0.568]\n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:08<00:00,  1.85it/s, F1=0.928, train_acc=0.991, train_loss=0.563, train_precision=0.928, train_recall=0.93] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.52it/s, F1=0.602, eval_acc=0.938, eval_loss=8.69, eval_precision=0.656, eval_recall=0.559]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [02:39<00:00,  2.18it/s, F1=0.933, train_acc=0.992, train_loss=0.513, train_precision=0.933, train_recall=0.935]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s, F1=0.611, eval_acc=0.939, eval_loss=9.57, eval_precision=0.663, eval_recall=0.57] \n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.22it/s, F1=0.935, train_acc=0.992, train_loss=0.525, train_precision=0.934, train_recall=0.939]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s, F1=0.599, eval_acc=0.937, eval_loss=10.2, eval_precision=0.648, eval_recall=0.56] \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:26<00:00,  1.69it/s, F1=0.937, train_acc=0.992, train_loss=0.536, train_precision=0.938, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.38it/s, F1=0.61, eval_acc=0.938, eval_loss=8.51, eval_precision=0.643, eval_recall=0.583] \n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:16<00:00,  1.77it/s, F1=0.931, train_acc=0.992, train_loss=0.584, train_precision=0.932, train_recall=0.933]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, F1=0.602, eval_acc=0.94, eval_loss=11.2, eval_precision=0.666, eval_recall=0.553] \n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [03:26<00:00,  1.69it/s, F1=0.934, train_acc=0.992, train_loss=0.599, train_precision=0.932, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s, F1=0.596, eval_acc=0.938, eval_loss=10.3, eval_precision=0.654, eval_recall=0.55] \n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.936, train_acc=0.993, train_loss=0.535, train_precision=0.935, train_recall=0.939]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.603, eval_acc=0.94, eval_loss=12.8, eval_precision=0.678, eval_recall=0.546] \n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [03:34<00:00,  1.63it/s, F1=0.937, train_acc=0.993, train_loss=0.51, train_precision=0.939, train_recall=0.939] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.596, eval_acc=0.94, eval_loss=10.5, eval_precision=0.705, eval_recall=0.519] \n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.94, train_acc=0.993, train_loss=0.508, train_precision=0.94, train_recall=0.942]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.59it/s, F1=0.597, eval_acc=0.941, eval_loss=12, eval_precision=0.702, eval_recall=0.522]  \n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [03:26<00:00,  1.69it/s, F1=0.95, train_acc=0.994, train_loss=0.413, train_precision=0.95, train_recall=0.951]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s, F1=0.598, eval_acc=0.942, eval_loss=11.4, eval_precision=0.701, eval_recall=0.524]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:33<00:00,  1.63it/s, F1=0.946, train_acc=0.994, train_loss=0.445, train_precision=0.947, train_recall=0.947]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.596, eval_acc=0.941, eval_loss=12.6, eval_precision=0.713, eval_recall=0.515]\n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [03:32<00:00,  1.65it/s, F1=0.952, train_acc=0.994, train_loss=0.394, train_precision=0.953, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.591, eval_acc=0.939, eval_loss=14.5, eval_precision=0.726, eval_recall=0.502]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [03:09<00:00,  1.84it/s, F1=0.956, train_acc=0.995, train_loss=0.377, train_precision=0.957, train_recall=0.956]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.592, eval_acc=0.941, eval_loss=13.8, eval_precision=0.707, eval_recall=0.512]\n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [03:29<00:00,  1.66it/s, F1=0.955, train_acc=0.995, train_loss=0.347, train_precision=0.955, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, F1=0.598, eval_acc=0.941, eval_loss=12.8, eval_precision=0.708, eval_recall=0.521]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [03:22<00:00,  1.73it/s, F1=0.958, train_acc=0.995, train_loss=0.37, train_precision=0.958, train_recall=0.959] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.6, eval_acc=0.941, eval_loss=12.6, eval_precision=0.707, eval_recall=0.525]  \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_v4_16_3'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v4_16_4\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 229MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 229MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 244MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 72.6kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 8180.02L/s]\n",
      "build line mapper: 4L [00:00, 6161.30L/s]/4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 961.72it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 25015.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:12<00:00, 433.59it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:01<00:00, 598.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [03:24<00:00,  1.71it/s, F1=0.134, train_acc=0.915, train_loss=19.7, train_precision=0.119, train_recall=0.162]        \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.402, eval_acc=0.933, eval_loss=10.9, eval_precision=0.407, eval_recall=0.4]  \n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [03:21<00:00,  1.73it/s, F1=0.542, train_acc=0.949, train_loss=5.2, train_precision=0.558, train_recall=0.549] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.527, eval_acc=0.93, eval_loss=7.66, eval_precision=0.751, eval_recall=0.409] \n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [03:20<00:00,  1.74it/s, F1=0.68, train_acc=0.96, train_loss=3.01, train_precision=0.709, train_recall=0.669]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.538, eval_acc=0.93, eval_loss=6.94, eval_precision=0.783, eval_recall=0.412] \n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [03:18<00:00,  1.76it/s, F1=0.72, train_acc=0.964, train_loss=2.33, train_precision=0.747, train_recall=0.709] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.27it/s, F1=0.561, eval_acc=0.934, eval_loss=8.16, eval_precision=0.774, eval_recall=0.442]\n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [03:01<00:00,  1.93it/s, F1=0.755, train_acc=0.969, train_loss=1.93, train_precision=0.773, train_recall=0.749]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.539, eval_acc=0.929, eval_loss=10.1, eval_precision=0.757, eval_recall=0.421]\n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.22it/s, F1=0.787, train_acc=0.973, train_loss=1.71, train_precision=0.801, train_recall=0.783]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.511, eval_acc=0.925, eval_loss=10.5, eval_precision=0.802, eval_recall=0.376]\n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.798, train_acc=0.974, train_loss=1.62, train_precision=0.813, train_recall=0.797]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.28it/s, F1=0.561, eval_acc=0.934, eval_loss=9.51, eval_precision=0.768, eval_recall=0.444]\n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.815, train_acc=0.977, train_loss=1.4, train_precision=0.83, train_recall=0.813]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s, F1=0.576, eval_acc=0.936, eval_loss=8.58, eval_precision=0.698, eval_recall=0.494]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:36<00:00,  1.61it/s, F1=0.844, train_acc=0.982, train_loss=1.21, train_precision=0.85, train_recall=0.845] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s, F1=0.587, eval_acc=0.937, eval_loss=8.51, eval_precision=0.68, eval_recall=0.519] \n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [03:29<00:00,  1.67it/s, F1=0.855, train_acc=0.983, train_loss=1.15, train_precision=0.867, train_recall=0.852]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s, F1=0.585, eval_acc=0.938, eval_loss=9.26, eval_precision=0.714, eval_recall=0.497]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.60it/s, F1=0.882, train_acc=0.986, train_loss=0.948, train_precision=0.887, train_recall=0.881]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.605, eval_acc=0.94, eval_loss=8.86, eval_precision=0.69, eval_recall=0.541]  \n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.881, train_acc=0.986, train_loss=0.946, train_precision=0.883, train_recall=0.883]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.606, eval_acc=0.941, eval_loss=9.73, eval_precision=0.719, eval_recall=0.527]\n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [03:23<00:00,  1.71it/s, F1=0.894, train_acc=0.987, train_loss=0.861, train_precision=0.899, train_recall=0.894]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s, F1=0.587, eval_acc=0.931, eval_loss=7.76, eval_precision=0.645, eval_recall=0.541]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.61it/s, F1=0.903, train_acc=0.988, train_loss=0.83, train_precision=0.906, train_recall=0.904] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.572, eval_acc=0.928, eval_loss=8.14, eval_precision=0.634, eval_recall=0.523]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.905, train_acc=0.989, train_loss=0.803, train_precision=0.91, train_recall=0.903] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.586, eval_acc=0.933, eval_loss=8.61, eval_precision=0.657, eval_recall=0.531]\n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:24<00:00,  1.71it/s, F1=0.91, train_acc=0.99, train_loss=0.707, train_precision=0.916, train_recall=0.908]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.587, eval_acc=0.934, eval_loss=8.64, eval_precision=0.653, eval_recall=0.535]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.92, train_acc=0.991, train_loss=0.62, train_precision=0.925, train_recall=0.918]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.586, eval_acc=0.93, eval_loss=8.49, eval_precision=0.645, eval_recall=0.539] \n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.928, train_acc=0.992, train_loss=0.591, train_precision=0.93, train_recall=0.929] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.576, eval_acc=0.934, eval_loss=8.55, eval_precision=0.657, eval_recall=0.514]\n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:25<00:00,  1.70it/s, F1=0.932, train_acc=0.992, train_loss=0.552, train_precision=0.934, train_recall=0.931]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s, F1=0.601, eval_acc=0.939, eval_loss=9.14, eval_precision=0.678, eval_recall=0.541]\n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.932, train_acc=0.992, train_loss=0.564, train_precision=0.936, train_recall=0.931]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.585, eval_acc=0.941, eval_loss=9.1, eval_precision=0.721, eval_recall=0.494] \n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.60it/s, F1=0.934, train_acc=0.992, train_loss=0.562, train_precision=0.937, train_recall=0.934]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.586, eval_acc=0.94, eval_loss=9.09, eval_precision=0.696, eval_recall=0.508] \n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.939, train_acc=0.993, train_loss=0.503, train_precision=0.942, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.587, eval_acc=0.939, eval_loss=10.5, eval_precision=0.72, eval_recall=0.498] \n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [03:27<00:00,  1.68it/s, F1=0.947, train_acc=0.994, train_loss=0.448, train_precision=0.95, train_recall=0.946] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.587, eval_acc=0.94, eval_loss=11.6, eval_precision=0.704, eval_recall=0.506] \n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.949, train_acc=0.995, train_loss=0.43, train_precision=0.95, train_recall=0.949]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.592, eval_acc=0.94, eval_loss=9.99, eval_precision=0.724, eval_recall=0.503] \n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.952, train_acc=0.994, train_loss=0.412, train_precision=0.952, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.597, eval_acc=0.937, eval_loss=8.97, eval_precision=0.691, eval_recall=0.529]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:24<00:00,  1.71it/s, F1=0.953, train_acc=0.995, train_loss=0.367, train_precision=0.955, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.592, eval_acc=0.939, eval_loss=10, eval_precision=0.694, eval_recall=0.519]  \n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [02:53<00:00,  2.01it/s, F1=0.957, train_acc=0.995, train_loss=0.349, train_precision=0.96, train_recall=0.955] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.584, eval_acc=0.938, eval_loss=12.2, eval_precision=0.691, eval_recall=0.509]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.963, train_acc=0.996, train_loss=0.33, train_precision=0.964, train_recall=0.962] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.59, eval_acc=0.939, eval_loss=11.8, eval_precision=0.685, eval_recall=0.521] \n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.962, train_acc=0.996, train_loss=0.32, train_precision=0.964, train_recall=0.961] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s, F1=0.582, eval_acc=0.933, eval_loss=10.3, eval_precision=0.682, eval_recall=0.51] \n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.963, train_acc=0.996, train_loss=0.316, train_precision=0.965, train_recall=0.963]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.591, eval_acc=0.939, eval_loss=11.4, eval_precision=0.687, eval_recall=0.522]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_v4_16_4'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v4_16_5\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 335MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 329MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 362MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 54.4kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 9597.95L/s]\n",
      "build line mapper: 4L [00:00, 31714.96L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 1166.62it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 36366.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:09<00:00, 577.22it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:01<00:00, 599.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel_v4: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel_v4 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel_v4 were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.attn_W', 'bert.embeddings.position_ids', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_word_weight.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.282, train_acc=0.912, train_loss=14.7, train_precision=0.308, train_recall=0.29]        \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.484, eval_acc=0.93, eval_loss=7.2, eval_precision=0.671, eval_recall=0.381]  \n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.613, train_acc=0.951, train_loss=4.01, train_precision=0.673, train_recall=0.592]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.527, eval_acc=0.927, eval_loss=6.11, eval_precision=0.76, eval_recall=0.407] \n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.687, train_acc=0.959, train_loss=2.67, train_precision=0.717, train_recall=0.672]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s, F1=0.568, eval_acc=0.933, eval_loss=5.6, eval_precision=0.728, eval_recall=0.468] \n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.724, train_acc=0.965, train_loss=2.18, train_precision=0.748, train_recall=0.713]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.586, eval_acc=0.937, eval_loss=5.85, eval_precision=0.72, eval_recall=0.496] \n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.761, train_acc=0.97, train_loss=1.83, train_precision=0.777, train_recall=0.755] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.585, eval_acc=0.937, eval_loss=6.72, eval_precision=0.743, eval_recall=0.484]\n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.794, train_acc=0.975, train_loss=1.62, train_precision=0.809, train_recall=0.79] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.61, eval_acc=0.941, eval_loss=6.12, eval_precision=0.699, eval_recall=0.544] \n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.808, train_acc=0.976, train_loss=1.5, train_precision=0.819, train_recall=0.806] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.594, eval_acc=0.939, eval_loss=6.65, eval_precision=0.705, eval_recall=0.516]\n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.22it/s, F1=0.833, train_acc=0.98, train_loss=1.32, train_precision=0.84, train_recall=0.834]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.564, eval_acc=0.933, eval_loss=8.76, eval_precision=0.764, eval_recall=0.449]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.85, train_acc=0.982, train_loss=1.19, train_precision=0.856, train_recall=0.85]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.603, eval_acc=0.939, eval_loss=7.02, eval_precision=0.682, eval_recall=0.544]\n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.863, train_acc=0.983, train_loss=1.1, train_precision=0.867, train_recall=0.865] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.599, eval_acc=0.939, eval_loss=7.86, eval_precision=0.696, eval_recall=0.529]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.877, train_acc=0.985, train_loss=1.02, train_precision=0.881, train_recall=0.879]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.574, eval_acc=0.936, eval_loss=9.29, eval_precision=0.746, eval_recall=0.47] \n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.887, train_acc=0.986, train_loss=0.939, train_precision=0.892, train_recall=0.887]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.596, eval_acc=0.94, eval_loss=8.16, eval_precision=0.74, eval_recall=0.501] \n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.903, train_acc=0.988, train_loss=0.808, train_precision=0.907, train_recall=0.902]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.582, eval_acc=0.938, eval_loss=9.63, eval_precision=0.684, eval_recall=0.509]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.905, train_acc=0.989, train_loss=0.803, train_precision=0.909, train_recall=0.907]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.596, eval_acc=0.939, eval_loss=8.69, eval_precision=0.706, eval_recall=0.518]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.22it/s, F1=0.917, train_acc=0.99, train_loss=0.723, train_precision=0.922, train_recall=0.917] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.592, eval_acc=0.937, eval_loss=8.57, eval_precision=0.668, eval_recall=0.535]\n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.927, train_acc=0.991, train_loss=0.65, train_precision=0.93, train_recall=0.926]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.596, eval_acc=0.938, eval_loss=9.84, eval_precision=0.724, eval_recall=0.509]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.933, train_acc=0.992, train_loss=0.603, train_precision=0.936, train_recall=0.932]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.601, eval_acc=0.94, eval_loss=9.29, eval_precision=0.693, eval_recall=0.534] \n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.929, train_acc=0.992, train_loss=0.597, train_precision=0.929, train_recall=0.931]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.575, eval_acc=0.936, eval_loss=10.3, eval_precision=0.701, eval_recall=0.491]\n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.937, train_acc=0.993, train_loss=0.55, train_precision=0.937, train_recall=0.939] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.593, eval_acc=0.94, eval_loss=10.5, eval_precision=0.684, eval_recall=0.527] \n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.939, train_acc=0.993, train_loss=0.553, train_precision=0.941, train_recall=0.939]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.593, eval_acc=0.94, eval_loss=12.2, eval_precision=0.694, eval_recall=0.52]  \n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.941, train_acc=0.993, train_loss=0.521, train_precision=0.943, train_recall=0.942]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.572, eval_acc=0.937, eval_loss=11.1, eval_precision=0.679, eval_recall=0.497]\n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.939, train_acc=0.992, train_loss=0.608, train_precision=0.942, train_recall=0.937]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.596, eval_acc=0.939, eval_loss=9.81, eval_precision=0.682, eval_recall=0.532]\n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.94, train_acc=0.993, train_loss=0.522, train_precision=0.942, train_recall=0.939] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.593, eval_acc=0.938, eval_loss=12.6, eval_precision=0.657, eval_recall=0.544]\n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.945, train_acc=0.994, train_loss=0.475, train_precision=0.947, train_recall=0.944]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.601, eval_acc=0.937, eval_loss=10.2, eval_precision=0.647, eval_recall=0.564]\n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.944, train_acc=0.994, train_loss=0.491, train_precision=0.944, train_recall=0.946]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.591, eval_acc=0.931, eval_loss=9.8, eval_precision=0.631, eval_recall=0.558] \n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.948, train_acc=0.994, train_loss=0.444, train_precision=0.95, train_recall=0.949] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.594, eval_acc=0.935, eval_loss=11.8, eval_precision=0.636, eval_recall=0.56] \n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.948, train_acc=0.994, train_loss=0.448, train_precision=0.951, train_recall=0.948]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.6, eval_acc=0.937, eval_loss=10.9, eval_precision=0.645, eval_recall=0.564]  \n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.949, train_acc=0.994, train_loss=0.428, train_precision=0.951, train_recall=0.949]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.595, eval_acc=0.936, eval_loss=9.25, eval_precision=0.657, eval_recall=0.547]\n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.957, train_acc=0.995, train_loss=0.363, train_precision=0.958, train_recall=0.958]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.594, eval_acc=0.936, eval_loss=11.2, eval_precision=0.674, eval_recall=0.534]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.23it/s, F1=0.954, train_acc=0.995, train_loss=0.402, train_precision=0.957, train_recall=0.954]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.58, eval_acc=0.935, eval_loss=9.93, eval_precision=0.635, eval_recall=0.537] \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_v4_16_5'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9392d1f0914889243d058bb73f0d89e61311fd6d751bbc8fa50e38d7d4ff811"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('NER': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
