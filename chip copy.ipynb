{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v1_tx_1\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 314MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 311MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 345MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 422kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 47805.50L/s]\n",
      "build line mapper: 19L [00:00, 143073.21L/s] [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 5312.08it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 159702.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1643: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n",
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:28<00:00, 523.38it/s]\n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:12<00:00, 387.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train:   5%|▌         | 12/235 [00:17<05:19,  1.43s/it, F1=0.000376, train_acc=0.287, train_loss=135, train_precision=0.000204, train_recall=0.00249]/home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [05:30<00:00,  1.41s/it, F1=0.357, train_acc=0.763, train_loss=36.8, train_precision=0.328, train_recall=0.396]       \n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.38it/s, F1=0.597, eval_acc=0.837, eval_loss=15.6, eval_precision=0.593, eval_recall=0.604]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [05:33<00:00,  1.42s/it, F1=0.64, train_acc=0.843, train_loss=11.6, train_precision=0.642, train_recall=0.641] \n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.67it/s, F1=0.634, eval_acc=0.836, eval_loss=9.68, eval_precision=0.634, eval_recall=0.636]\n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [05:31<00:00,  1.41s/it, F1=0.684, train_acc=0.858, train_loss=7.58, train_precision=0.686, train_recall=0.683]\n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.66it/s, F1=0.644, eval_acc=0.839, eval_loss=8.14, eval_precision=0.654, eval_recall=0.638]\n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [05:33<00:00,  1.42s/it, F1=0.711, train_acc=0.87, train_loss=6.13, train_precision=0.712, train_recall=0.711] \n",
      "Eval Result: 100%|██████████| 79/79 [00:48<00:00,  1.64it/s, F1=0.641, eval_acc=0.838, eval_loss=7.77, eval_precision=0.647, eval_recall=0.638]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [05:30<00:00,  1.41s/it, F1=0.734, train_acc=0.883, train_loss=5.29, train_precision=0.733, train_recall=0.735]\n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.69it/s, F1=0.64, eval_acc=0.838, eval_loss=7.77, eval_precision=0.648, eval_recall=0.635] \n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [05:00<00:00,  1.28s/it, F1=0.751, train_acc=0.891, train_loss=4.77, train_precision=0.75, train_recall=0.754] \n",
      "Eval Result: 100%|██████████| 79/79 [01:05<00:00,  1.21it/s, F1=0.645, eval_acc=0.841, eval_loss=7.91, eval_precision=0.65, eval_recall=0.644] \n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [05:17<00:00,  1.35s/it, F1=0.77, train_acc=0.901, train_loss=4.33, train_precision=0.767, train_recall=0.775] \n",
      "Eval Result: 100%|██████████| 79/79 [00:58<00:00,  1.35it/s, F1=0.634, eval_acc=0.831, eval_loss=7.86, eval_precision=0.647, eval_recall=0.624]\n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [05:18<00:00,  1.36s/it, F1=0.789, train_acc=0.908, train_loss=4.06, train_precision=0.787, train_recall=0.791]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, F1=0.632, eval_acc=0.828, eval_loss=7.81, eval_precision=0.641, eval_recall=0.626]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [05:18<00:00,  1.36s/it, F1=0.81, train_acc=0.921, train_loss=3.6, train_precision=0.807, train_recall=0.814]  \n",
      "Eval Result: 100%|██████████| 79/79 [01:04<00:00,  1.23it/s, F1=0.627, eval_acc=0.822, eval_loss=8.07, eval_precision=0.639, eval_recall=0.617]\n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [05:16<00:00,  1.35s/it, F1=0.832, train_acc=0.932, train_loss=3.21, train_precision=0.828, train_recall=0.836]\n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.31it/s, F1=0.635, eval_acc=0.832, eval_loss=8.66, eval_precision=0.622, eval_recall=0.652]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:54<00:00,  1.25s/it, F1=0.845, train_acc=0.938, train_loss=3.04, train_precision=0.842, train_recall=0.849]\n",
      "Eval Result: 100%|██████████| 79/79 [01:06<00:00,  1.19it/s, F1=0.641, eval_acc=0.834, eval_loss=8.63, eval_precision=0.624, eval_recall=0.662]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [05:27<00:00,  1.39s/it, F1=0.851, train_acc=0.94, train_loss=2.92, train_precision=0.848, train_recall=0.855] \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.642, eval_acc=0.839, eval_loss=9.22, eval_precision=0.637, eval_recall=0.649]\n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [05:36<00:00,  1.43s/it, F1=0.863, train_acc=0.945, train_loss=2.73, train_precision=0.86, train_recall=0.868] \n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.65it/s, F1=0.628, eval_acc=0.829, eval_loss=10.7, eval_precision=0.64, eval_recall=0.619] \n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [05:33<00:00,  1.42s/it, F1=0.873, train_acc=0.949, train_loss=2.6, train_precision=0.869, train_recall=0.877] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.626, eval_acc=0.831, eval_loss=9.84, eval_precision=0.616, eval_recall=0.639]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [05:20<00:00,  1.36s/it, F1=0.878, train_acc=0.95, train_loss=2.52, train_precision=0.875, train_recall=0.881] \n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.24it/s, F1=0.635, eval_acc=0.836, eval_loss=10.3, eval_precision=0.616, eval_recall=0.658]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [05:20<00:00,  1.36s/it, F1=0.891, train_acc=0.957, train_loss=2.25, train_precision=0.888, train_recall=0.895]\n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.24it/s, F1=0.635, eval_acc=0.838, eval_loss=10.9, eval_precision=0.62, eval_recall=0.654] \n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.39s/it, F1=0.901, train_acc=0.962, train_loss=2.06, train_precision=0.897, train_recall=0.905]\n",
      "Eval Result: 100%|██████████| 79/79 [01:06<00:00,  1.19it/s, F1=0.635, eval_acc=0.836, eval_loss=10.9, eval_precision=0.624, eval_recall=0.648]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [05:38<00:00,  1.44s/it, F1=0.914, train_acc=0.968, train_loss=1.83, train_precision=0.911, train_recall=0.917]\n",
      "Eval Result: 100%|██████████| 79/79 [01:05<00:00,  1.20it/s, F1=0.637, eval_acc=0.836, eval_loss=11, eval_precision=0.64, eval_recall=0.636]   \n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [05:31<00:00,  1.41s/it, F1=0.924, train_acc=0.972, train_loss=1.67, train_precision=0.921, train_recall=0.927]\n",
      "Eval Result: 100%|██████████| 79/79 [01:08<00:00,  1.15it/s, F1=0.632, eval_acc=0.833, eval_loss=11.6, eval_precision=0.63, eval_recall=0.637] \n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [05:47<00:00,  1.48s/it, F1=0.931, train_acc=0.974, train_loss=1.59, train_precision=0.929, train_recall=0.933]\n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, F1=0.627, eval_acc=0.831, eval_loss=12.9, eval_precision=0.629, eval_recall=0.628]\n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [05:47<00:00,  1.48s/it, F1=0.935, train_acc=0.976, train_loss=1.51, train_precision=0.933, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, F1=0.634, eval_acc=0.836, eval_loss=12.2, eval_precision=0.621, eval_recall=0.651]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [05:46<00:00,  1.48s/it, F1=0.937, train_acc=0.976, train_loss=1.51, train_precision=0.936, train_recall=0.94] \n",
      "Eval Result: 100%|██████████| 79/79 [00:59<00:00,  1.32it/s, F1=0.625, eval_acc=0.827, eval_loss=12.4, eval_precision=0.601, eval_recall=0.654]\n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [05:11<00:00,  1.33s/it, F1=0.935, train_acc=0.975, train_loss=1.56, train_precision=0.934, train_recall=0.937]\n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.24it/s, F1=0.633, eval_acc=0.831, eval_loss=12.3, eval_precision=0.611, eval_recall=0.658]\n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.39s/it, F1=0.938, train_acc=0.976, train_loss=1.47, train_precision=0.936, train_recall=0.939]\n",
      "Eval Result: 100%|██████████| 79/79 [01:06<00:00,  1.18it/s, F1=0.633, eval_acc=0.836, eval_loss=12.6, eval_precision=0.635, eval_recall=0.633]\n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [05:32<00:00,  1.42s/it, F1=0.943, train_acc=0.979, train_loss=1.39, train_precision=0.941, train_recall=0.945]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, F1=0.626, eval_acc=0.831, eval_loss=13, eval_precision=0.63, eval_recall=0.626]   \n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [05:36<00:00,  1.43s/it, F1=0.95, train_acc=0.982, train_loss=1.25, train_precision=0.948, train_recall=0.952] \n",
      "Eval Result: 100%|██████████| 79/79 [01:07<00:00,  1.18it/s, F1=0.63, eval_acc=0.831, eval_loss=13.1, eval_precision=0.624, eval_recall=0.638] \n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [05:33<00:00,  1.42s/it, F1=0.951, train_acc=0.981, train_loss=1.21, train_precision=0.95, train_recall=0.953] \n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.42it/s, F1=0.615, eval_acc=0.822, eval_loss=13.3, eval_precision=0.625, eval_recall=0.607]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [05:09<00:00,  1.32s/it, F1=0.955, train_acc=0.984, train_loss=1.13, train_precision=0.953, train_recall=0.956]\n",
      "Eval Result: 100%|██████████| 79/79 [01:08<00:00,  1.16it/s, F1=0.613, eval_acc=0.819, eval_loss=14.1, eval_precision=0.62, eval_recall=0.608] \n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.958, train_acc=0.984, train_loss=1.06, train_precision=0.957, train_recall=0.96] \n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.30it/s, F1=0.615, eval_acc=0.821, eval_loss=13.9, eval_precision=0.618, eval_recall=0.614]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.39s/it, F1=0.962, train_acc=0.986, train_loss=0.979, train_precision=0.96, train_recall=0.963] \n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, F1=0.624, eval_acc=0.826, eval_loss=14.6, eval_precision=0.625, eval_recall=0.624]\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/chip/train_data.json',\n",
    "    'eval_file': './data/chip/val_data.json',\n",
    "    'test_file': './data/chip/val_data.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/chip/chip_tags_list.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    # 'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/tencent_medicine_vocab.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/fn_thu_chn.txt\",\n",
    "    # \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'task_name': 'chip_v1_tx_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v1_tx_2\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 205MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 326MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 290MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 143kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 95668.40L/s]\n",
      "build line mapper: 19L [00:00, 91916.70L/s]9 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 2229.89it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 86339.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:36<00:00, 407.57it/s]\n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:10<00:00, 496.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [04:59<00:00,  1.27s/it, F1=0.318, train_acc=0.754, train_loss=36.5, train_precision=0.285, train_recall=0.364]        \n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.67it/s, F1=0.566, eval_acc=0.834, eval_loss=15.2, eval_precision=0.537, eval_recall=0.602]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [05:28<00:00,  1.40s/it, F1=0.629, train_acc=0.84, train_loss=11.6, train_precision=0.627, train_recall=0.634] \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, F1=0.636, eval_acc=0.838, eval_loss=9.8, eval_precision=0.636, eval_recall=0.638] \n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [05:24<00:00,  1.38s/it, F1=0.682, train_acc=0.856, train_loss=7.65, train_precision=0.684, train_recall=0.682]\n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, F1=0.644, eval_acc=0.839, eval_loss=8.35, eval_precision=0.65, eval_recall=0.641] \n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.706, train_acc=0.867, train_loss=6.19, train_precision=0.706, train_recall=0.707]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.55it/s, F1=0.641, eval_acc=0.832, eval_loss=7.64, eval_precision=0.639, eval_recall=0.646]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.38s/it, F1=0.729, train_acc=0.879, train_loss=5.34, train_precision=0.728, train_recall=0.731]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.57it/s, F1=0.636, eval_acc=0.832, eval_loss=7.49, eval_precision=0.634, eval_recall=0.64] \n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [05:22<00:00,  1.37s/it, F1=0.75, train_acc=0.888, train_loss=4.79, train_precision=0.748, train_recall=0.752] \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.78it/s, F1=0.627, eval_acc=0.826, eval_loss=7.51, eval_precision=0.62, eval_recall=0.637] \n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [05:05<00:00,  1.30s/it, F1=0.769, train_acc=0.899, train_loss=4.34, train_precision=0.766, train_recall=0.773]\n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.43it/s, F1=0.633, eval_acc=0.833, eval_loss=7.88, eval_precision=0.646, eval_recall=0.623]\n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [05:22<00:00,  1.37s/it, F1=0.784, train_acc=0.907, train_loss=4.02, train_precision=0.781, train_recall=0.788]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.58it/s, F1=0.64, eval_acc=0.835, eval_loss=8.17, eval_precision=0.64, eval_recall=0.642]  \n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.38s/it, F1=0.8, train_acc=0.915, train_loss=3.77, train_precision=0.797, train_recall=0.804]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.57it/s, F1=0.635, eval_acc=0.83, eval_loss=8.01, eval_precision=0.628, eval_recall=0.645] \n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.39s/it, F1=0.813, train_acc=0.918, train_loss=3.59, train_precision=0.81, train_recall=0.817] \n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.44it/s, F1=0.636, eval_acc=0.831, eval_loss=8.09, eval_precision=0.639, eval_recall=0.635]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [05:18<00:00,  1.36s/it, F1=0.829, train_acc=0.927, train_loss=3.29, train_precision=0.825, train_recall=0.834]\n",
      "Eval Result: 100%|██████████| 79/79 [01:04<00:00,  1.22it/s, F1=0.628, eval_acc=0.823, eval_loss=8.54, eval_precision=0.635, eval_recall=0.624]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [04:56<00:00,  1.26s/it, F1=0.842, train_acc=0.932, train_loss=3.01, train_precision=0.838, train_recall=0.847]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.63, eval_acc=0.832, eval_loss=8.84, eval_precision=0.633, eval_recall=0.63]  \n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.859, train_acc=0.943, train_loss=2.7, train_precision=0.855, train_recall=0.863] \n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.49it/s, F1=0.636, eval_acc=0.837, eval_loss=8.78, eval_precision=0.64, eval_recall=0.634] \n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [04:44<00:00,  1.21s/it, F1=0.872, train_acc=0.949, train_loss=2.54, train_precision=0.867, train_recall=0.877]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, F1=0.634, eval_acc=0.833, eval_loss=9.08, eval_precision=0.645, eval_recall=0.626]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [05:29<00:00,  1.40s/it, F1=0.88, train_acc=0.953, train_loss=2.34, train_precision=0.877, train_recall=0.885] \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.56it/s, F1=0.615, eval_acc=0.822, eval_loss=9.54, eval_precision=0.642, eval_recall=0.593]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [05:30<00:00,  1.41s/it, F1=0.888, train_acc=0.957, train_loss=2.23, train_precision=0.884, train_recall=0.893]\n",
      "Eval Result: 100%|██████████| 79/79 [00:49<00:00,  1.60it/s, F1=0.621, eval_acc=0.825, eval_loss=9.69, eval_precision=0.637, eval_recall=0.608]\n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [05:32<00:00,  1.41s/it, F1=0.896, train_acc=0.96, train_loss=2.1, train_precision=0.893, train_recall=0.9]    \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, F1=0.626, eval_acc=0.828, eval_loss=9.77, eval_precision=0.643, eval_recall=0.613]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [05:28<00:00,  1.40s/it, F1=0.906, train_acc=0.963, train_loss=1.96, train_precision=0.903, train_recall=0.909]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.47it/s, F1=0.618, eval_acc=0.82, eval_loss=10.6, eval_precision=0.614, eval_recall=0.624] \n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [05:32<00:00,  1.42s/it, F1=0.914, train_acc=0.967, train_loss=1.82, train_precision=0.912, train_recall=0.917]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.51it/s, F1=0.614, eval_acc=0.815, eval_loss=10.8, eval_precision=0.604, eval_recall=0.627]\n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [05:31<00:00,  1.41s/it, F1=0.918, train_acc=0.968, train_loss=1.75, train_precision=0.916, train_recall=0.921]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, F1=0.63, eval_acc=0.829, eval_loss=11.3, eval_precision=0.616, eval_recall=0.646] \n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [05:28<00:00,  1.40s/it, F1=0.923, train_acc=0.97, train_loss=1.66, train_precision=0.921, train_recall=0.925] \n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.42it/s, F1=0.637, eval_acc=0.835, eval_loss=11.7, eval_precision=0.624, eval_recall=0.652]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [05:26<00:00,  1.39s/it, F1=0.928, train_acc=0.973, train_loss=1.59, train_precision=0.926, train_recall=0.93] \n",
      "Eval Result: 100%|██████████| 79/79 [00:58<00:00,  1.34it/s, F1=0.625, eval_acc=0.831, eval_loss=12.6, eval_precision=0.635, eval_recall=0.618]\n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [05:24<00:00,  1.38s/it, F1=0.931, train_acc=0.973, train_loss=1.54, train_precision=0.929, train_recall=0.933]\n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.37it/s, F1=0.621, eval_acc=0.825, eval_loss=12.9, eval_precision=0.637, eval_recall=0.609]\n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [05:22<00:00,  1.37s/it, F1=0.932, train_acc=0.972, train_loss=1.55, train_precision=0.93, train_recall=0.934] \n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, F1=0.62, eval_acc=0.826, eval_loss=12.4, eval_precision=0.633, eval_recall=0.609] \n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:47<00:00,  1.22s/it, F1=0.936, train_acc=0.975, train_loss=1.46, train_precision=0.934, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.615, eval_acc=0.821, eval_loss=12.8, eval_precision=0.623, eval_recall=0.61] \n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [05:12<00:00,  1.33s/it, F1=0.939, train_acc=0.977, train_loss=1.34, train_precision=0.937, train_recall=0.941]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.62, eval_acc=0.827, eval_loss=12.2, eval_precision=0.622, eval_recall=0.62]  \n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [05:35<00:00,  1.43s/it, F1=0.947, train_acc=0.981, train_loss=1.2, train_precision=0.946, train_recall=0.949] \n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.70it/s, F1=0.629, eval_acc=0.832, eval_loss=13.3, eval_precision=0.619, eval_recall=0.641]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [05:38<00:00,  1.44s/it, F1=0.952, train_acc=0.982, train_loss=1.13, train_precision=0.95, train_recall=0.953] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.628, eval_acc=0.83, eval_loss=14.4, eval_precision=0.607, eval_recall=0.653] \n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.38s/it, F1=0.954, train_acc=0.984, train_loss=1.07, train_precision=0.953, train_recall=0.956]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.624, eval_acc=0.828, eval_loss=14.7, eval_precision=0.601, eval_recall=0.652]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [05:34<00:00,  1.42s/it, F1=0.956, train_acc=0.984, train_loss=1.05, train_precision=0.955, train_recall=0.958]\n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.25it/s, F1=0.63, eval_acc=0.831, eval_loss=14.8, eval_precision=0.602, eval_recall=0.664] \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_v1_tx_2'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v1_tx_3\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 215MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 276MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 281MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 196kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 94758.35L/s]\n",
      "build line mapper: 19L [00:00, 64371.39L/s]9 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 2644.84it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 98628.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:36<00:00, 415.40it/s]\n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:11<00:00, 422.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.299, train_acc=0.742, train_loss=44, train_precision=0.256, train_recall=0.368]         \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.555, eval_acc=0.834, eval_loss=18.2, eval_precision=0.518, eval_recall=0.601]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [05:30<00:00,  1.41s/it, F1=0.631, train_acc=0.842, train_loss=12.8, train_precision=0.621, train_recall=0.644]\n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.65it/s, F1=0.619, eval_acc=0.826, eval_loss=10.7, eval_precision=0.635, eval_recall=0.608]\n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [05:33<00:00,  1.42s/it, F1=0.683, train_acc=0.858, train_loss=7.98, train_precision=0.682, train_recall=0.685]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.628, eval_acc=0.823, eval_loss=8.58, eval_precision=0.644, eval_recall=0.616]\n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [05:18<00:00,  1.36s/it, F1=0.707, train_acc=0.869, train_loss=6.32, train_precision=0.706, train_recall=0.708]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.627, eval_acc=0.823, eval_loss=8.19, eval_precision=0.638, eval_recall=0.618]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [05:30<00:00,  1.41s/it, F1=0.725, train_acc=0.877, train_loss=5.5, train_precision=0.723, train_recall=0.727] \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.638, eval_acc=0.83, eval_loss=8.05, eval_precision=0.657, eval_recall=0.624] \n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.744, train_acc=0.888, train_loss=4.88, train_precision=0.741, train_recall=0.747]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.642, eval_acc=0.838, eval_loss=8.01, eval_precision=0.655, eval_recall=0.632]\n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [05:31<00:00,  1.41s/it, F1=0.76, train_acc=0.897, train_loss=4.46, train_precision=0.757, train_recall=0.763] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.634, eval_acc=0.831, eval_loss=8.08, eval_precision=0.635, eval_recall=0.635]\n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [05:20<00:00,  1.36s/it, F1=0.774, train_acc=0.902, train_loss=4.18, train_precision=0.771, train_recall=0.777]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.638, eval_acc=0.837, eval_loss=8.63, eval_precision=0.641, eval_recall=0.637]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.789, train_acc=0.91, train_loss=3.85, train_precision=0.787, train_recall=0.792] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.636, eval_acc=0.833, eval_loss=9.14, eval_precision=0.651, eval_recall=0.624]\n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [05:29<00:00,  1.40s/it, F1=0.812, train_acc=0.921, train_loss=3.42, train_precision=0.808, train_recall=0.816]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.621, eval_acc=0.816, eval_loss=9.46, eval_precision=0.689, eval_recall=0.569]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.822, train_acc=0.927, train_loss=3.25, train_precision=0.818, train_recall=0.827]\n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.25it/s, F1=0.625, eval_acc=0.825, eval_loss=8.94, eval_precision=0.668, eval_recall=0.592]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [05:30<00:00,  1.41s/it, F1=0.837, train_acc=0.933, train_loss=3, train_precision=0.833, train_recall=0.842]   \n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.30it/s, F1=0.641, eval_acc=0.835, eval_loss=9.5, eval_precision=0.647, eval_recall=0.638] \n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:59<00:00,  1.28s/it, F1=0.849, train_acc=0.937, train_loss=2.79, train_precision=0.846, train_recall=0.853]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.642, eval_acc=0.836, eval_loss=10.7, eval_precision=0.632, eval_recall=0.654]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [04:16<00:00,  1.09s/it, F1=0.86, train_acc=0.942, train_loss=2.64, train_precision=0.856, train_recall=0.864] \n",
      "Eval Result: 100%|██████████| 79/79 [00:49<00:00,  1.58it/s, F1=0.639, eval_acc=0.837, eval_loss=9.91, eval_precision=0.63, eval_recall=0.65]  \n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [04:33<00:00,  1.16s/it, F1=0.866, train_acc=0.944, train_loss=2.53, train_precision=0.862, train_recall=0.871]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.63, eval_acc=0.828, eval_loss=10.7, eval_precision=0.636, eval_recall=0.627] \n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [04:41<00:00,  1.20s/it, F1=0.88, train_acc=0.951, train_loss=2.3, train_precision=0.876, train_recall=0.884]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.39it/s, F1=0.631, eval_acc=0.831, eval_loss=10.3, eval_precision=0.627, eval_recall=0.638]\n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [05:05<00:00,  1.30s/it, F1=0.891, train_acc=0.956, train_loss=2.09, train_precision=0.889, train_recall=0.894]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.629, eval_acc=0.829, eval_loss=10.7, eval_precision=0.62, eval_recall=0.64]  \n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.898, train_acc=0.959, train_loss=1.98, train_precision=0.896, train_recall=0.901]\n",
      "Eval Result: 100%|██████████| 79/79 [01:04<00:00,  1.23it/s, F1=0.625, eval_acc=0.832, eval_loss=12.7, eval_precision=0.619, eval_recall=0.633]\n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [05:18<00:00,  1.36s/it, F1=0.905, train_acc=0.961, train_loss=1.91, train_precision=0.903, train_recall=0.907]\n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.31it/s, F1=0.63, eval_acc=0.832, eval_loss=12.4, eval_precision=0.626, eval_recall=0.637] \n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.909, train_acc=0.962, train_loss=1.87, train_precision=0.907, train_recall=0.912]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.58it/s, F1=0.618, eval_acc=0.823, eval_loss=12.4, eval_precision=0.623, eval_recall=0.616]\n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [05:22<00:00,  1.37s/it, F1=0.912, train_acc=0.964, train_loss=1.77, train_precision=0.911, train_recall=0.914]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.56it/s, F1=0.618, eval_acc=0.825, eval_loss=13.5, eval_precision=0.626, eval_recall=0.613]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [05:09<00:00,  1.32s/it, F1=0.921, train_acc=0.969, train_loss=1.59, train_precision=0.919, train_recall=0.924]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.612, eval_acc=0.82, eval_loss=12.9, eval_precision=0.617, eval_recall=0.61]  \n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [05:10<00:00,  1.32s/it, F1=0.933, train_acc=0.974, train_loss=1.35, train_precision=0.932, train_recall=0.935]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.46it/s, F1=0.63, eval_acc=0.83, eval_loss=13.1, eval_precision=0.623, eval_recall=0.639]  \n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [05:13<00:00,  1.34s/it, F1=0.942, train_acc=0.979, train_loss=1.18, train_precision=0.94, train_recall=0.944] \n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, F1=0.631, eval_acc=0.831, eval_loss=13.8, eval_precision=0.619, eval_recall=0.646]\n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [05:08<00:00,  1.31s/it, F1=0.947, train_acc=0.982, train_loss=1.07, train_precision=0.946, train_recall=0.949]\n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.37it/s, F1=0.628, eval_acc=0.829, eval_loss=14, eval_precision=0.613, eval_recall=0.645]  \n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [04:34<00:00,  1.17s/it, F1=0.953, train_acc=0.983, train_loss=0.993, train_precision=0.951, train_recall=0.955]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.633, eval_acc=0.834, eval_loss=14.4, eval_precision=0.624, eval_recall=0.645]\n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [05:20<00:00,  1.36s/it, F1=0.954, train_acc=0.983, train_loss=0.974, train_precision=0.953, train_recall=0.955]\n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.31it/s, F1=0.624, eval_acc=0.829, eval_loss=14.9, eval_precision=0.615, eval_recall=0.637]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.39s/it, F1=0.961, train_acc=0.986, train_loss=0.872, train_precision=0.959, train_recall=0.962]\n",
      "Eval Result: 100%|██████████| 79/79 [00:48<00:00,  1.62it/s, F1=0.62, eval_acc=0.828, eval_loss=15.7, eval_precision=0.617, eval_recall=0.626] \n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [05:26<00:00,  1.39s/it, F1=0.963, train_acc=0.987, train_loss=0.838, train_precision=0.962, train_recall=0.964]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.634, eval_acc=0.836, eval_loss=15.9, eval_precision=0.624, eval_recall=0.648]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [05:22<00:00,  1.37s/it, F1=0.962, train_acc=0.986, train_loss=0.839, train_precision=0.962, train_recall=0.963]\n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, F1=0.623, eval_acc=0.83, eval_loss=16.7, eval_precision=0.618, eval_recall=0.631] \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_v1_tx_3'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v1_tx_4\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 307MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 252MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 338MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 218kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 68463.73L/s]\n",
      "build line mapper: 19L [00:00, 79771.55L/s]9 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 2648.89it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 90972.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:33<00:00, 453.32it/s]\n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:11<00:00, 433.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [05:24<00:00,  1.38s/it, F1=0.383, train_acc=0.754, train_loss=35.1, train_precision=0.37, train_recall=0.399]        \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.565, eval_acc=0.818, eval_loss=14.4, eval_precision=0.575, eval_recall=0.559]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [05:16<00:00,  1.35s/it, F1=0.643, train_acc=0.839, train_loss=10.9, train_precision=0.645, train_recall=0.641]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.612, eval_acc=0.816, eval_loss=9.51, eval_precision=0.623, eval_recall=0.607]\n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [05:32<00:00,  1.42s/it, F1=0.685, train_acc=0.857, train_loss=7.38, train_precision=0.687, train_recall=0.685]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.612, eval_acc=0.808, eval_loss=8.29, eval_precision=0.628, eval_recall=0.601]\n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [05:18<00:00,  1.35s/it, F1=0.711, train_acc=0.87, train_loss=6.04, train_precision=0.711, train_recall=0.712] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.606, eval_acc=0.776, eval_loss=8.31, eval_precision=0.597, eval_recall=0.619]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [05:28<00:00,  1.40s/it, F1=0.729, train_acc=0.879, train_loss=5.32, train_precision=0.728, train_recall=0.73] \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.62, eval_acc=0.802, eval_loss=7.9, eval_precision=0.604, eval_recall=0.639]  \n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [05:17<00:00,  1.35s/it, F1=0.752, train_acc=0.89, train_loss=4.76, train_precision=0.75, train_recall=0.754]  \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.639, eval_acc=0.837, eval_loss=7.99, eval_precision=0.648, eval_recall=0.634]\n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [05:27<00:00,  1.40s/it, F1=0.772, train_acc=0.9, train_loss=4.31, train_precision=0.769, train_recall=0.775]  \n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.27it/s, F1=0.631, eval_acc=0.833, eval_loss=8.65, eval_precision=0.644, eval_recall=0.622]\n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [05:17<00:00,  1.35s/it, F1=0.791, train_acc=0.911, train_loss=3.91, train_precision=0.788, train_recall=0.795]\n",
      "Eval Result: 100%|██████████| 79/79 [00:58<00:00,  1.35it/s, F1=0.638, eval_acc=0.835, eval_loss=8.14, eval_precision=0.633, eval_recall=0.645]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.812, train_acc=0.922, train_loss=3.51, train_precision=0.809, train_recall=0.817]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.624, eval_acc=0.818, eval_loss=8.13, eval_precision=0.61, eval_recall=0.642] \n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.827, train_acc=0.927, train_loss=3.31, train_precision=0.824, train_recall=0.832]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.626, eval_acc=0.823, eval_loss=8.76, eval_precision=0.609, eval_recall=0.646]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.843, train_acc=0.935, train_loss=3.03, train_precision=0.839, train_recall=0.847]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.631, eval_acc=0.833, eval_loss=8.99, eval_precision=0.614, eval_recall=0.651]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.852, train_acc=0.939, train_loss=2.93, train_precision=0.849, train_recall=0.855]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.621, eval_acc=0.823, eval_loss=9.77, eval_precision=0.604, eval_recall=0.641]\n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.857, train_acc=0.939, train_loss=2.9, train_precision=0.854, train_recall=0.861] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.628, eval_acc=0.829, eval_loss=9.75, eval_precision=0.625, eval_recall=0.633]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.871, train_acc=0.946, train_loss=2.62, train_precision=0.868, train_recall=0.874]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.636, eval_acc=0.835, eval_loss=9.48, eval_precision=0.643, eval_recall=0.632]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.881, train_acc=0.953, train_loss=2.39, train_precision=0.878, train_recall=0.885]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.64, eval_acc=0.839, eval_loss=10.1, eval_precision=0.634, eval_recall=0.647] \n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.892, train_acc=0.957, train_loss=2.25, train_precision=0.889, train_recall=0.895]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.629, eval_acc=0.835, eval_loss=11.3, eval_precision=0.638, eval_recall=0.624]\n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.896, train_acc=0.958, train_loss=2.19, train_precision=0.893, train_recall=0.9]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.622, eval_acc=0.829, eval_loss=11.9, eval_precision=0.659, eval_recall=0.591]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.905, train_acc=0.961, train_loss=2.03, train_precision=0.902, train_recall=0.907]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.627, eval_acc=0.835, eval_loss=12.3, eval_precision=0.645, eval_recall=0.613]\n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.913, train_acc=0.966, train_loss=1.87, train_precision=0.91, train_recall=0.916] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.64, eval_acc=0.84, eval_loss=12.1, eval_precision=0.642, eval_recall=0.641]  \n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.923, train_acc=0.971, train_loss=1.69, train_precision=0.921, train_recall=0.925]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.637, eval_acc=0.838, eval_loss=12.6, eval_precision=0.623, eval_recall=0.654]\n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.929, train_acc=0.973, train_loss=1.58, train_precision=0.927, train_recall=0.931]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.637, eval_acc=0.839, eval_loss=13.4, eval_precision=0.622, eval_recall=0.654]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.935, train_acc=0.975, train_loss=1.48, train_precision=0.934, train_recall=0.936]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.632, eval_acc=0.837, eval_loss=14.1, eval_precision=0.606, eval_recall=0.662]\n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.94, train_acc=0.978, train_loss=1.4, train_precision=0.938, train_recall=0.942]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.637, eval_acc=0.836, eval_loss=13.1, eval_precision=0.611, eval_recall=0.667]\n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.945, train_acc=0.98, train_loss=1.31, train_precision=0.944, train_recall=0.947] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.632, eval_acc=0.835, eval_loss=13.5, eval_precision=0.608, eval_recall=0.66] \n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.95, train_acc=0.982, train_loss=1.22, train_precision=0.948, train_recall=0.952] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.633, eval_acc=0.832, eval_loss=13.7, eval_precision=0.606, eval_recall=0.664]\n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.954, train_acc=0.983, train_loss=1.14, train_precision=0.953, train_recall=0.955]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.639, eval_acc=0.838, eval_loss=14.1, eval_precision=0.611, eval_recall=0.671]\n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [04:14<00:00,  1.08s/it, F1=0.956, train_acc=0.985, train_loss=1.09, train_precision=0.955, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.638, eval_acc=0.838, eval_loss=14.6, eval_precision=0.611, eval_recall=0.669]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.958, train_acc=0.985, train_loss=1.09, train_precision=0.957, train_recall=0.959]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.634, eval_acc=0.837, eval_loss=14.5, eval_precision=0.616, eval_recall=0.655]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.956, train_acc=0.984, train_loss=1.12, train_precision=0.956, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.625, eval_acc=0.835, eval_loss=15.4, eval_precision=0.599, eval_recall=0.655]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.958, train_acc=0.985, train_loss=1.06, train_precision=0.957, train_recall=0.96] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.638, eval_acc=0.839, eval_loss=15.5, eval_precision=0.615, eval_recall=0.665]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_v1_tx_4'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_v1_tx_5\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 332MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 356MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 355MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 346kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 55035.76L/s]\n",
      "build line mapper: 19L [00:00, 173242.99L/s] [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 5480.86it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 214225.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_word_vocab\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:16<00:00, 886.62it/s] \n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:05<00:00, 878.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [04:12<00:00,  1.07s/it, F1=0.333, train_acc=0.754, train_loss=40.1, train_precision=0.298, train_recall=0.39]       \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.544, eval_acc=0.813, eval_loss=18.4, eval_precision=0.503, eval_recall=0.596]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.637, train_acc=0.842, train_loss=12.2, train_precision=0.635, train_recall=0.641]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.621, eval_acc=0.826, eval_loss=10.8, eval_precision=0.602, eval_recall=0.643]\n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.684, train_acc=0.858, train_loss=7.83, train_precision=0.687, train_recall=0.681]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.64, eval_acc=0.835, eval_loss=8.5, eval_precision=0.633, eval_recall=0.648]  \n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.708, train_acc=0.869, train_loss=6.26, train_precision=0.709, train_recall=0.708]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.644, eval_acc=0.838, eval_loss=8.07, eval_precision=0.648, eval_recall=0.643]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.732, train_acc=0.881, train_loss=5.37, train_precision=0.732, train_recall=0.734]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.642, eval_acc=0.838, eval_loss=8.44, eval_precision=0.646, eval_recall=0.641]\n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [04:12<00:00,  1.08s/it, F1=0.749, train_acc=0.891, train_loss=4.83, train_precision=0.747, train_recall=0.752]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.648, eval_acc=0.84, eval_loss=8.85, eval_precision=0.639, eval_recall=0.66]  \n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.765, train_acc=0.899, train_loss=4.45, train_precision=0.763, train_recall=0.769]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.645, eval_acc=0.84, eval_loss=8.54, eval_precision=0.633, eval_recall=0.66]  \n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.786, train_acc=0.908, train_loss=4.08, train_precision=0.784, train_recall=0.789]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.634, eval_acc=0.835, eval_loss=8.43, eval_precision=0.626, eval_recall=0.644]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.803, train_acc=0.915, train_loss=3.79, train_precision=0.8, train_recall=0.807]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.644, eval_acc=0.841, eval_loss=8.65, eval_precision=0.638, eval_recall=0.653]\n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.811, train_acc=0.918, train_loss=3.6, train_precision=0.808, train_recall=0.814] \n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.82it/s, F1=0.639, eval_acc=0.836, eval_loss=8.52, eval_precision=0.631, eval_recall=0.649]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:47<00:00,  1.22s/it, F1=0.837, train_acc=0.932, train_loss=3.11, train_precision=0.834, train_recall=0.841]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, F1=0.632, eval_acc=0.832, eval_loss=8.62, eval_precision=0.619, eval_recall=0.649]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [05:02<00:00,  1.29s/it, F1=0.855, train_acc=0.941, train_loss=2.8, train_precision=0.851, train_recall=0.859] \n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.46it/s, F1=0.64, eval_acc=0.838, eval_loss=9.34, eval_precision=0.632, eval_recall=0.651] \n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [05:02<00:00,  1.29s/it, F1=0.871, train_acc=0.949, train_loss=2.54, train_precision=0.867, train_recall=0.876]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.47it/s, F1=0.633, eval_acc=0.836, eval_loss=9.98, eval_precision=0.626, eval_recall=0.643]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [05:03<00:00,  1.29s/it, F1=0.878, train_acc=0.951, train_loss=2.45, train_precision=0.874, train_recall=0.882]\n",
      "Eval Result: 100%|██████████| 79/79 [00:56<00:00,  1.40it/s, F1=0.638, eval_acc=0.836, eval_loss=10.8, eval_precision=0.619, eval_recall=0.66] \n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [05:09<00:00,  1.32s/it, F1=0.884, train_acc=0.954, train_loss=2.39, train_precision=0.881, train_recall=0.888]\n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.43it/s, F1=0.638, eval_acc=0.836, eval_loss=11.1, eval_precision=0.637, eval_recall=0.641]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [05:06<00:00,  1.30s/it, F1=0.889, train_acc=0.955, train_loss=2.3, train_precision=0.886, train_recall=0.893] \n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.43it/s, F1=0.63, eval_acc=0.829, eval_loss=10.5, eval_precision=0.63, eval_recall=0.632]  \n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [05:05<00:00,  1.30s/it, F1=0.899, train_acc=0.96, train_loss=2.12, train_precision=0.896, train_recall=0.904] \n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.42it/s, F1=0.629, eval_acc=0.829, eval_loss=10.8, eval_precision=0.618, eval_recall=0.642]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [04:47<00:00,  1.22s/it, F1=0.909, train_acc=0.965, train_loss=1.89, train_precision=0.906, train_recall=0.912]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.629, eval_acc=0.834, eval_loss=11.2, eval_precision=0.632, eval_recall=0.628]\n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [04:24<00:00,  1.12s/it, F1=0.919, train_acc=0.969, train_loss=1.76, train_precision=0.917, train_recall=0.922]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.631, eval_acc=0.834, eval_loss=11.7, eval_precision=0.631, eval_recall=0.634]\n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:12<00:00,  1.08s/it, F1=0.926, train_acc=0.972, train_loss=1.6, train_precision=0.924, train_recall=0.929] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.634, eval_acc=0.836, eval_loss=13.3, eval_precision=0.632, eval_recall=0.638]\n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.931, train_acc=0.974, train_loss=1.55, train_precision=0.93, train_recall=0.933] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.623, eval_acc=0.831, eval_loss=14.6, eval_precision=0.644, eval_recall=0.608]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.933, train_acc=0.974, train_loss=1.52, train_precision=0.931, train_recall=0.935]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.636, eval_acc=0.84, eval_loss=13.3, eval_precision=0.633, eval_recall=0.643] \n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:16<00:00,  1.09s/it, F1=0.938, train_acc=0.977, train_loss=1.43, train_precision=0.937, train_recall=0.939]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.637, eval_acc=0.838, eval_loss=12.9, eval_precision=0.62, eval_recall=0.658] \n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.942, train_acc=0.979, train_loss=1.33, train_precision=0.941, train_recall=0.943]\n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.84it/s, F1=0.63, eval_acc=0.831, eval_loss=13, eval_precision=0.609, eval_recall=0.655]   \n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:16<00:00,  1.09s/it, F1=0.947, train_acc=0.98, train_loss=1.24, train_precision=0.945, train_recall=0.948] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.617, eval_acc=0.819, eval_loss=13, eval_precision=0.593, eval_recall=0.645]  \n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.949, train_acc=0.981, train_loss=1.2, train_precision=0.948, train_recall=0.95]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.635, eval_acc=0.835, eval_loss=13.7, eval_precision=0.607, eval_recall=0.668]\n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [04:12<00:00,  1.07s/it, F1=0.953, train_acc=0.983, train_loss=1.13, train_precision=0.952, train_recall=0.955]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.57it/s, F1=0.628, eval_acc=0.828, eval_loss=13.9, eval_precision=0.605, eval_recall=0.654]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.956, train_acc=0.984, train_loss=1.06, train_precision=0.955, train_recall=0.956]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.628, eval_acc=0.829, eval_loss=13.9, eval_precision=0.616, eval_recall=0.643]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [04:12<00:00,  1.08s/it, F1=0.96, train_acc=0.986, train_loss=0.981, train_precision=0.96, train_recall=0.961]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.83it/s, F1=0.631, eval_acc=0.831, eval_loss=14.8, eval_precision=0.624, eval_recall=0.641]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [04:16<00:00,  1.09s/it, F1=0.963, train_acc=0.987, train_loss=0.932, train_precision=0.962, train_recall=0.963]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.627, eval_acc=0.833, eval_loss=14.9, eval_precision=0.621, eval_recall=0.635]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_v1_tx_5'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v1_16_1\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 323MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 339MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 360MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 54.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 10401.25L/s]\n",
      "build line mapper: 4L [00:00, 8008.22L/s]/4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 1189.03it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 47304.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:08<00:00, 619.55it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:01<00:00, 627.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [02:43<00:00,  2.14it/s, F1=0.404, train_acc=0.926, train_loss=8.52, train_precision=0.503, train_recall=0.372]       \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.572, eval_acc=0.938, eval_loss=4.93, eval_precision=0.653, eval_recall=0.511]\n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.649, train_acc=0.953, train_loss=3.09, train_precision=0.699, train_recall=0.626]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.62, eval_acc=0.941, eval_loss=4.68, eval_precision=0.664, eval_recall=0.585] \n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.717, train_acc=0.962, train_loss=2.29, train_precision=0.748, train_recall=0.704]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.622, eval_acc=0.94, eval_loss=4.86, eval_precision=0.649, eval_recall=0.599] \n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.758, train_acc=0.968, train_loss=1.93, train_precision=0.784, train_recall=0.75] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.618, eval_acc=0.943, eval_loss=5.35, eval_precision=0.684, eval_recall=0.567]\n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.789, train_acc=0.972, train_loss=1.68, train_precision=0.808, train_recall=0.784]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.604, eval_acc=0.936, eval_loss=5.55, eval_precision=0.641, eval_recall=0.573]\n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.827, train_acc=0.977, train_loss=1.41, train_precision=0.837, train_recall=0.825]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.606, eval_acc=0.939, eval_loss=6.97, eval_precision=0.647, eval_recall=0.572]\n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.851, train_acc=0.981, train_loss=1.22, train_precision=0.86, train_recall=0.851] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.589, eval_acc=0.94, eval_loss=7.97, eval_precision=0.699, eval_recall=0.51]  \n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.872, train_acc=0.984, train_loss=1.07, train_precision=0.878, train_recall=0.871]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.592, eval_acc=0.934, eval_loss=7.54, eval_precision=0.667, eval_recall=0.535]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.884, train_acc=0.986, train_loss=1, train_precision=0.89, train_recall=0.884]     \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.591, eval_acc=0.933, eval_loss=7.7, eval_precision=0.662, eval_recall=0.537] \n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.891, train_acc=0.986, train_loss=0.972, train_precision=0.896, train_recall=0.892]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.595, eval_acc=0.937, eval_loss=8.35, eval_precision=0.677, eval_recall=0.533]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.901, train_acc=0.988, train_loss=0.908, train_precision=0.905, train_recall=0.902]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.592, eval_acc=0.938, eval_loss=7.38, eval_precision=0.703, eval_recall=0.513]\n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.17it/s, F1=0.909, train_acc=0.988, train_loss=0.817, train_precision=0.912, train_recall=0.91] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.589, eval_acc=0.938, eval_loss=9.36, eval_precision=0.743, eval_recall=0.489]\n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.17it/s, F1=0.916, train_acc=0.99, train_loss=0.752, train_precision=0.917, train_recall=0.918] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.59, eval_acc=0.936, eval_loss=9.33, eval_precision=0.694, eval_recall=0.516] \n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.93, train_acc=0.992, train_loss=0.657, train_precision=0.932, train_recall=0.931] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.589, eval_acc=0.939, eval_loss=9.39, eval_precision=0.696, eval_recall=0.513]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.932, train_acc=0.992, train_loss=0.606, train_precision=0.936, train_recall=0.931]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.569, eval_acc=0.934, eval_loss=9.59, eval_precision=0.73, eval_recall=0.468] \n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.939, train_acc=0.993, train_loss=0.559, train_precision=0.94, train_recall=0.94]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.567, eval_acc=0.936, eval_loss=11.4, eval_precision=0.713, eval_recall=0.473]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.942, train_acc=0.993, train_loss=0.558, train_precision=0.943, train_recall=0.943]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.585, eval_acc=0.936, eval_loss=8.76, eval_precision=0.679, eval_recall=0.517]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.943, train_acc=0.993, train_loss=0.529, train_precision=0.944, train_recall=0.943]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.574, eval_acc=0.939, eval_loss=9.46, eval_precision=0.709, eval_recall=0.484]\n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.949, train_acc=0.994, train_loss=0.475, train_precision=0.95, train_recall=0.95]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.58, eval_acc=0.939, eval_loss=10.1, eval_precision=0.73, eval_recall=0.483]  \n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.949, train_acc=0.994, train_loss=0.467, train_precision=0.952, train_recall=0.949]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.573, eval_acc=0.938, eval_loss=11.3, eval_precision=0.734, eval_recall=0.473]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.956, train_acc=0.995, train_loss=0.392, train_precision=0.957, train_recall=0.955]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.557, eval_acc=0.935, eval_loss=11.1, eval_precision=0.76, eval_recall=0.441] \n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.955, train_acc=0.995, train_loss=0.388, train_precision=0.958, train_recall=0.954]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.572, eval_acc=0.937, eval_loss=10.6, eval_precision=0.75, eval_recall=0.464] \n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.955, train_acc=0.995, train_loss=0.384, train_precision=0.957, train_recall=0.954]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.583, eval_acc=0.939, eval_loss=9.16, eval_precision=0.717, eval_recall=0.494]\n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.958, train_acc=0.995, train_loss=0.386, train_precision=0.958, train_recall=0.958]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.595, eval_acc=0.941, eval_loss=11.6, eval_precision=0.708, eval_recall=0.516]\n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.955, train_acc=0.995, train_loss=0.39, train_precision=0.956, train_recall=0.956] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.567, eval_acc=0.934, eval_loss=10.7, eval_precision=0.728, eval_recall=0.466]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.961, train_acc=0.995, train_loss=0.338, train_precision=0.962, train_recall=0.961]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.584, eval_acc=0.939, eval_loss=10.5, eval_precision=0.724, eval_recall=0.492]\n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.963, train_acc=0.996, train_loss=0.32, train_precision=0.964, train_recall=0.963] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.578, eval_acc=0.938, eval_loss=12, eval_precision=0.733, eval_recall=0.479]  \n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.957, train_acc=0.995, train_loss=0.349, train_precision=0.958, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.571, eval_acc=0.935, eval_loss=13.1, eval_precision=0.747, eval_recall=0.464]\n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [03:00<00:00,  1.94it/s, F1=0.963, train_acc=0.996, train_loss=0.297, train_precision=0.964, train_recall=0.964]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.42it/s, F1=0.564, eval_acc=0.933, eval_loss=12.2, eval_precision=0.725, eval_recall=0.464]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [03:13<00:00,  1.81it/s, F1=0.96, train_acc=0.996, train_loss=0.333, train_precision=0.963, train_recall=0.959] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.32it/s, F1=0.591, eval_acc=0.94, eval_loss=10.8, eval_precision=0.711, eval_recall=0.508] \n"
     ]
    }
   ],
   "source": [
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/CDD/train.json',\n",
    "    'eval_file': './data/CDD/dev.json',\n",
    "    'test_file': './data/CDD/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    # 'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/tencent_medicine_vocab.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    # \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'task_name': 'cdd_v1_16_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v1_16_2\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 249MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 282MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 304MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 46.6kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 22104.37L/s]\n",
      "build line mapper: 4L [00:00, 18335.76L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 679.87it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 20971.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:16<00:00, 339.87it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:01<00:00, 569.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [03:18<00:00,  1.76it/s, F1=0.275, train_acc=0.904, train_loss=18.2, train_precision=0.291, train_recall=0.285]       \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.29it/s, F1=0.514, eval_acc=0.933, eval_loss=7.67, eval_precision=0.715, eval_recall=0.404]\n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [03:20<00:00,  1.74it/s, F1=0.623, train_acc=0.952, train_loss=3.94, train_precision=0.672, train_recall=0.603]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.37it/s, F1=0.556, eval_acc=0.937, eval_loss=6.76, eval_precision=0.715, eval_recall=0.458]\n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [03:20<00:00,  1.74it/s, F1=0.672, train_acc=0.957, train_loss=2.78, train_precision=0.707, train_recall=0.661]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.34it/s, F1=0.581, eval_acc=0.938, eval_loss=6.17, eval_precision=0.745, eval_recall=0.479]\n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [03:21<00:00,  1.74it/s, F1=0.719, train_acc=0.964, train_loss=2.2, train_precision=0.743, train_recall=0.713] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.32it/s, F1=0.597, eval_acc=0.939, eval_loss=5.6, eval_precision=0.706, eval_recall=0.52]  \n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [03:20<00:00,  1.74it/s, F1=0.759, train_acc=0.969, train_loss=1.8, train_precision=0.775, train_recall=0.756] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.36it/s, F1=0.589, eval_acc=0.938, eval_loss=6.15, eval_precision=0.703, eval_recall=0.509]\n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.55it/s, F1=0.796, train_acc=0.975, train_loss=1.51, train_precision=0.807, train_recall=0.795]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s, F1=0.558, eval_acc=0.935, eval_loss=7.19, eval_precision=0.752, eval_recall=0.446]\n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:52<00:00,  1.50it/s, F1=0.809, train_acc=0.976, train_loss=1.48, train_precision=0.818, train_recall=0.81] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.584, eval_acc=0.936, eval_loss=6.08, eval_precision=0.685, eval_recall=0.512]\n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.816, train_acc=0.976, train_loss=1.54, train_precision=0.828, train_recall=0.819]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.555, eval_acc=0.937, eval_loss=7.01, eval_precision=0.75, eval_recall=0.444] \n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.55it/s, F1=0.817, train_acc=0.976, train_loss=1.49, train_precision=0.832, train_recall=0.819]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.587, eval_acc=0.94, eval_loss=7.32, eval_precision=0.712, eval_recall=0.503] \n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.56it/s, F1=0.863, train_acc=0.984, train_loss=1.05, train_precision=0.866, train_recall=0.868]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.15it/s, F1=0.613, eval_acc=0.943, eval_loss=7.49, eval_precision=0.724, eval_recall=0.533]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [03:24<00:00,  1.71it/s, F1=0.893, train_acc=0.988, train_loss=0.82, train_precision=0.893, train_recall=0.897] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.28it/s, F1=0.608, eval_acc=0.942, eval_loss=8.25, eval_precision=0.688, eval_recall=0.548]\n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [03:33<00:00,  1.64it/s, F1=0.902, train_acc=0.989, train_loss=0.721, train_precision=0.905, train_recall=0.903]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.30it/s, F1=0.609, eval_acc=0.942, eval_loss=7.67, eval_precision=0.695, eval_recall=0.545]\n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [03:33<00:00,  1.64it/s, F1=0.91, train_acc=0.99, train_loss=0.673, train_precision=0.911, train_recall=0.912]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.30it/s, F1=0.589, eval_acc=0.94, eval_loss=9.14, eval_precision=0.729, eval_recall=0.497] \n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.922, train_acc=0.991, train_loss=0.601, train_precision=0.924, train_recall=0.924]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.29it/s, F1=0.592, eval_acc=0.94, eval_loss=8.65, eval_precision=0.709, eval_recall=0.512] \n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [03:29<00:00,  1.67it/s, F1=0.927, train_acc=0.992, train_loss=0.584, train_precision=0.928, train_recall=0.928]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.28it/s, F1=0.561, eval_acc=0.934, eval_loss=11.7, eval_precision=0.725, eval_recall=0.46] \n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:28<00:00,  1.67it/s, F1=0.926, train_acc=0.991, train_loss=0.602, train_precision=0.927, train_recall=0.928]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.35it/s, F1=0.577, eval_acc=0.937, eval_loss=11.1, eval_precision=0.725, eval_recall=0.482]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [03:16<00:00,  1.77it/s, F1=0.93, train_acc=0.992, train_loss=0.598, train_precision=0.93, train_recall=0.933]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.50it/s, F1=0.598, eval_acc=0.942, eval_loss=12.5, eval_precision=0.719, eval_recall=0.514]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [02:56<00:00,  1.98it/s, F1=0.927, train_acc=0.991, train_loss=0.633, train_precision=0.931, train_recall=0.927]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.6, eval_acc=0.941, eval_loss=12.1, eval_precision=0.678, eval_recall=0.54]   \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.926, train_acc=0.992, train_loss=0.63, train_precision=0.93, train_recall=0.924]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.597, eval_acc=0.94, eval_loss=8.22, eval_precision=0.668, eval_recall=0.543] \n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.934, train_acc=0.992, train_loss=0.574, train_precision=0.938, train_recall=0.934]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.604, eval_acc=0.939, eval_loss=9.47, eval_precision=0.653, eval_recall=0.564]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.17it/s, F1=0.934, train_acc=0.993, train_loss=0.514, train_precision=0.938, train_recall=0.933]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.6, eval_acc=0.939, eval_loss=9.4, eval_precision=0.679, eval_recall=0.541]   \n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.17it/s, F1=0.951, train_acc=0.994, train_loss=0.441, train_precision=0.951, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.607, eval_acc=0.941, eval_loss=9.81, eval_precision=0.702, eval_recall=0.537]\n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.17it/s, F1=0.958, train_acc=0.995, train_loss=0.353, train_precision=0.957, train_recall=0.96] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.603, eval_acc=0.94, eval_loss=11.5, eval_precision=0.696, eval_recall=0.536] \n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.17it/s, F1=0.958, train_acc=0.996, train_loss=0.346, train_precision=0.96, train_recall=0.958] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.607, eval_acc=0.941, eval_loss=10.5, eval_precision=0.674, eval_recall=0.554]\n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.955, train_acc=0.995, train_loss=0.373, train_precision=0.957, train_recall=0.955]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.597, eval_acc=0.942, eval_loss=12, eval_precision=0.711, eval_recall=0.517]  \n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.958, train_acc=0.995, train_loss=0.33, train_precision=0.96, train_recall=0.957]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s, F1=0.591, eval_acc=0.94, eval_loss=12.4, eval_precision=0.719, eval_recall=0.505] \n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.957, train_acc=0.996, train_loss=0.347, train_precision=0.958, train_recall=0.958]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.591, eval_acc=0.94, eval_loss=13.1, eval_precision=0.736, eval_recall=0.497]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.963, train_acc=0.996, train_loss=0.307, train_precision=0.963, train_recall=0.963]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.604, eval_acc=0.942, eval_loss=11.2, eval_precision=0.708, eval_recall=0.529]\n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.961, train_acc=0.995, train_loss=0.362, train_precision=0.963, train_recall=0.961]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.597, eval_acc=0.941, eval_loss=11.8, eval_precision=0.709, eval_recall=0.519]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.96, train_acc=0.995, train_loss=0.35, train_precision=0.962, train_recall=0.96]   \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.598, eval_acc=0.942, eval_loss=11, eval_precision=0.746, eval_recall=0.501]  \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_v1_16_2'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v1_16_3\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 352MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 332MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 365MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 53.6kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 11634.69L/s]\n",
      "build line mapper: 4L [00:00, 35544.95L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 1218.39it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 45756.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:09<00:00, 576.06it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:01<00:00, 597.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.396, train_acc=0.933, train_loss=7.81, train_precision=0.513, train_recall=0.364]     \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.517, eval_acc=0.927, eval_loss=5.99, eval_precision=0.742, eval_recall=0.399]\n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.653, train_acc=0.954, train_loss=3.2, train_precision=0.722, train_recall=0.621] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.502, eval_acc=0.922, eval_loss=6.6, eval_precision=0.825, eval_recall=0.364] \n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.735, train_acc=0.965, train_loss=2.33, train_precision=0.773, train_recall=0.714]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.569, eval_acc=0.935, eval_loss=6.43, eval_precision=0.755, eval_recall=0.458]\n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.784, train_acc=0.972, train_loss=1.89, train_precision=0.809, train_recall=0.771]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.588, eval_acc=0.939, eval_loss=6.39, eval_precision=0.713, eval_recall=0.503]\n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.816, train_acc=0.978, train_loss=1.62, train_precision=0.835, train_recall=0.805]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.588, eval_acc=0.936, eval_loss=7.46, eval_precision=0.723, eval_recall=0.498]\n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.845, train_acc=0.981, train_loss=1.44, train_precision=0.859, train_recall=0.839]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.584, eval_acc=0.935, eval_loss=6.65, eval_precision=0.669, eval_recall=0.522]\n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.848, train_acc=0.981, train_loss=1.39, train_precision=0.866, train_recall=0.843]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.599, eval_acc=0.931, eval_loss=6.84, eval_precision=0.631, eval_recall=0.574]\n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.17it/s, F1=0.871, train_acc=0.984, train_loss=1.19, train_precision=0.882, train_recall=0.867]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.587, eval_acc=0.931, eval_loss=7.31, eval_precision=0.619, eval_recall=0.562]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.894, train_acc=0.988, train_loss=1, train_precision=0.899, train_recall=0.894]    \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.65it/s, F1=0.574, eval_acc=0.928, eval_loss=7.05, eval_precision=0.603, eval_recall=0.55] \n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.908, train_acc=0.99, train_loss=0.898, train_precision=0.914, train_recall=0.906] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.588, eval_acc=0.933, eval_loss=7.38, eval_precision=0.626, eval_recall=0.557]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.912, train_acc=0.99, train_loss=0.826, train_precision=0.915, train_recall=0.912] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.584, eval_acc=0.934, eval_loss=7.09, eval_precision=0.647, eval_recall=0.534]\n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [02:43<00:00,  2.14it/s, F1=0.924, train_acc=0.991, train_loss=0.777, train_precision=0.926, train_recall=0.924]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.587, eval_acc=0.936, eval_loss=7.07, eval_precision=0.691, eval_recall=0.513]\n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.922, train_acc=0.991, train_loss=0.749, train_precision=0.926, train_recall=0.92] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.568, eval_acc=0.937, eval_loss=8.48, eval_precision=0.727, eval_recall=0.468]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.928, train_acc=0.992, train_loss=0.694, train_precision=0.93, train_recall=0.927] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.573, eval_acc=0.935, eval_loss=8.57, eval_precision=0.727, eval_recall=0.476]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.937, train_acc=0.992, train_loss=0.643, train_precision=0.941, train_recall=0.936]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.65it/s, F1=0.563, eval_acc=0.936, eval_loss=9.37, eval_precision=0.713, eval_recall=0.466]\n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.94, train_acc=0.993, train_loss=0.621, train_precision=0.942, train_recall=0.941] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.582, eval_acc=0.936, eval_loss=8.3, eval_precision=0.699, eval_recall=0.501] \n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [02:43<00:00,  2.13it/s, F1=0.942, train_acc=0.993, train_loss=0.553, train_precision=0.945, train_recall=0.942]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.20it/s, F1=0.588, eval_acc=0.939, eval_loss=9.54, eval_precision=0.722, eval_recall=0.498]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [03:49<00:00,  1.52it/s, F1=0.943, train_acc=0.993, train_loss=0.543, train_precision=0.944, train_recall=0.943]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.29it/s, F1=0.578, eval_acc=0.934, eval_loss=11, eval_precision=0.74, eval_recall=0.476]   \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:47<00:00,  1.54it/s, F1=0.941, train_acc=0.993, train_loss=0.555, train_precision=0.944, train_recall=0.941]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.568, eval_acc=0.935, eval_loss=8.45, eval_precision=0.703, eval_recall=0.478]\n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:46<00:00,  1.54it/s, F1=0.954, train_acc=0.994, train_loss=0.486, train_precision=0.955, train_recall=0.954]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.20it/s, F1=0.582, eval_acc=0.936, eval_loss=10.8, eval_precision=0.713, eval_recall=0.494]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [03:49<00:00,  1.52it/s, F1=0.956, train_acc=0.995, train_loss=0.42, train_precision=0.957, train_recall=0.956] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s, F1=0.582, eval_acc=0.936, eval_loss=9.94, eval_precision=0.717, eval_recall=0.491]\n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [03:49<00:00,  1.52it/s, F1=0.958, train_acc=0.996, train_loss=0.406, train_precision=0.96, train_recall=0.957] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s, F1=0.591, eval_acc=0.939, eval_loss=11, eval_precision=0.716, eval_recall=0.506] \n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [03:50<00:00,  1.51it/s, F1=0.957, train_acc=0.995, train_loss=0.423, train_precision=0.958, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s, F1=0.57, eval_acc=0.937, eval_loss=11.3, eval_precision=0.712, eval_recall=0.477] \n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:47<00:00,  1.54it/s, F1=0.958, train_acc=0.995, train_loss=0.409, train_precision=0.96, train_recall=0.958] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s, F1=0.581, eval_acc=0.935, eval_loss=9.38, eval_precision=0.696, eval_recall=0.501]\n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.959, train_acc=0.996, train_loss=0.359, train_precision=0.96, train_recall=0.959] \n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.44it/s, F1=0.589, eval_acc=0.937, eval_loss=10.6, eval_precision=0.719, eval_recall=0.502]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:11<00:00,  1.82it/s, F1=0.964, train_acc=0.996, train_loss=0.329, train_precision=0.966, train_recall=0.964]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.67it/s, F1=0.595, eval_acc=0.941, eval_loss=11, eval_precision=0.708, eval_recall=0.516]  \n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.962, train_acc=0.995, train_loss=0.342, train_precision=0.963, train_recall=0.963]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.568, eval_acc=0.934, eval_loss=13.3, eval_precision=0.775, eval_recall=0.451]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [02:39<00:00,  2.19it/s, F1=0.961, train_acc=0.995, train_loss=0.353, train_precision=0.964, train_recall=0.958]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.65it/s, F1=0.589, eval_acc=0.938, eval_loss=12.1, eval_precision=0.709, eval_recall=0.507]\n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [02:47<00:00,  2.09it/s, F1=0.963, train_acc=0.996, train_loss=0.35, train_precision=0.964, train_recall=0.963] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.65it/s, F1=0.605, eval_acc=0.941, eval_loss=9.54, eval_precision=0.708, eval_recall=0.531]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [02:39<00:00,  2.18it/s, F1=0.972, train_acc=0.997, train_loss=0.265, train_precision=0.973, train_recall=0.972]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.41it/s, F1=0.606, eval_acc=0.942, eval_loss=11.3, eval_precision=0.712, eval_recall=0.529]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_v1_16_3'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v1_16_4\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 323MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 338MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 361MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 62.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 12446.01L/s]\n",
      "build line mapper: 4L [00:00, 35098.78L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 1201.63it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 44620.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:09<00:00, 585.23it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:01<00:00, 619.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.432, train_acc=0.938, train_loss=8.4, train_precision=0.496, train_recall=0.407]      \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.566, eval_acc=0.928, eval_loss=5.64, eval_precision=0.575, eval_recall=0.561]\n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [02:43<00:00,  2.14it/s, F1=0.664, train_acc=0.957, train_loss=3.23, train_precision=0.726, train_recall=0.633]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.583, eval_acc=0.934, eval_loss=5.22, eval_precision=0.618, eval_recall=0.555]\n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [02:43<00:00,  2.14it/s, F1=0.722, train_acc=0.965, train_loss=2.42, train_precision=0.764, train_recall=0.699]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.40it/s, F1=0.594, eval_acc=0.936, eval_loss=5.45, eval_precision=0.646, eval_recall=0.553]\n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [02:44<00:00,  2.12it/s, F1=0.759, train_acc=0.969, train_loss=2.1, train_precision=0.788, train_recall=0.746] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.62it/s, F1=0.594, eval_acc=0.937, eval_loss=5.1, eval_precision=0.637, eval_recall=0.559] \n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [02:47<00:00,  2.08it/s, F1=0.794, train_acc=0.973, train_loss=1.81, train_precision=0.812, train_recall=0.786]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.574, eval_acc=0.934, eval_loss=5.6, eval_precision=0.633, eval_recall=0.528] \n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [02:39<00:00,  2.19it/s, F1=0.816, train_acc=0.977, train_loss=1.58, train_precision=0.828, train_recall=0.812]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.588, eval_acc=0.94, eval_loss=6.53, eval_precision=0.705, eval_recall=0.508] \n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [02:39<00:00,  2.19it/s, F1=0.843, train_acc=0.981, train_loss=1.4, train_precision=0.851, train_recall=0.841] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.576, eval_acc=0.937, eval_loss=6.84, eval_precision=0.704, eval_recall=0.49] \n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [02:38<00:00,  2.20it/s, F1=0.86, train_acc=0.983, train_loss=1.29, train_precision=0.868, train_recall=0.859] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.573, eval_acc=0.936, eval_loss=7.23, eval_precision=0.699, eval_recall=0.488]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [02:42<00:00,  2.14it/s, F1=0.865, train_acc=0.984, train_loss=1.23, train_precision=0.873, train_recall=0.863]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.65it/s, F1=0.579, eval_acc=0.937, eval_loss=7.71, eval_precision=0.649, eval_recall=0.525]\n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [02:45<00:00,  2.11it/s, F1=0.881, train_acc=0.986, train_loss=1.05, train_precision=0.888, train_recall=0.879]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.596, eval_acc=0.935, eval_loss=6.62, eval_precision=0.647, eval_recall=0.554]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [02:42<00:00,  2.15it/s, F1=0.894, train_acc=0.988, train_loss=0.935, train_precision=0.898, train_recall=0.893]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.591, eval_acc=0.936, eval_loss=6.98, eval_precision=0.649, eval_recall=0.546]\n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [02:48<00:00,  2.08it/s, F1=0.903, train_acc=0.989, train_loss=0.867, train_precision=0.908, train_recall=0.902]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.593, eval_acc=0.937, eval_loss=7.19, eval_precision=0.649, eval_recall=0.548]\n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [02:38<00:00,  2.20it/s, F1=0.908, train_acc=0.989, train_loss=0.831, train_precision=0.914, train_recall=0.906]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.599, eval_acc=0.938, eval_loss=8.73, eval_precision=0.689, eval_recall=0.533]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [02:44<00:00,  2.13it/s, F1=0.914, train_acc=0.99, train_loss=0.767, train_precision=0.917, train_recall=0.915] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.578, eval_acc=0.936, eval_loss=9.44, eval_precision=0.734, eval_recall=0.478]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [02:42<00:00,  2.15it/s, F1=0.922, train_acc=0.991, train_loss=0.707, train_precision=0.925, train_recall=0.922]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.41it/s, F1=0.582, eval_acc=0.937, eval_loss=9.43, eval_precision=0.721, eval_recall=0.49] \n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [02:43<00:00,  2.13it/s, F1=0.927, train_acc=0.992, train_loss=0.679, train_precision=0.93, train_recall=0.927] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.65it/s, F1=0.577, eval_acc=0.938, eval_loss=9.92, eval_precision=0.701, eval_recall=0.493]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.927, train_acc=0.992, train_loss=0.676, train_precision=0.93, train_recall=0.927] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.597, eval_acc=0.939, eval_loss=8.33, eval_precision=0.692, eval_recall=0.528]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [02:39<00:00,  2.18it/s, F1=0.937, train_acc=0.993, train_loss=0.55, train_precision=0.939, train_recall=0.938] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.594, eval_acc=0.938, eval_loss=9.64, eval_precision=0.683, eval_recall=0.527]\n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.18it/s, F1=0.935, train_acc=0.993, train_loss=0.6, train_precision=0.938, train_recall=0.934]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.41it/s, F1=0.591, eval_acc=0.938, eval_loss=8.59, eval_precision=0.679, eval_recall=0.526]\n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [02:48<00:00,  2.07it/s, F1=0.939, train_acc=0.993, train_loss=0.55, train_precision=0.943, train_recall=0.938] \n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.41it/s, F1=0.597, eval_acc=0.936, eval_loss=9.68, eval_precision=0.646, eval_recall=0.558]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [02:45<00:00,  2.11it/s, F1=0.949, train_acc=0.994, train_loss=0.472, train_precision=0.952, train_recall=0.948]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.593, eval_acc=0.937, eval_loss=11, eval_precision=0.644, eval_recall=0.552]  \n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.947, train_acc=0.994, train_loss=0.508, train_precision=0.95, train_recall=0.946] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.587, eval_acc=0.935, eval_loss=10.1, eval_precision=0.631, eval_recall=0.552]\n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [03:49<00:00,  1.52it/s, F1=0.951, train_acc=0.995, train_loss=0.48, train_precision=0.953, train_recall=0.951] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.25it/s, F1=0.602, eval_acc=0.936, eval_loss=10.1, eval_precision=0.662, eval_recall=0.554]\n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:52<00:00,  1.50it/s, F1=0.95, train_acc=0.994, train_loss=0.46, train_precision=0.952, train_recall=0.948]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s, F1=0.6, eval_acc=0.937, eval_loss=9.1, eval_precision=0.646, eval_recall=0.562]   \n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [03:49<00:00,  1.52it/s, F1=0.954, train_acc=0.995, train_loss=0.393, train_precision=0.955, train_recall=0.954]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.19it/s, F1=0.595, eval_acc=0.938, eval_loss=9.63, eval_precision=0.669, eval_recall=0.539]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.96, train_acc=0.995, train_loss=0.356, train_precision=0.962, train_recall=0.958] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.32it/s, F1=0.591, eval_acc=0.937, eval_loss=10.5, eval_precision=0.658, eval_recall=0.54] \n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [03:11<00:00,  1.82it/s, F1=0.965, train_acc=0.996, train_loss=0.343, train_precision=0.966, train_recall=0.964]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.589, eval_acc=0.937, eval_loss=10.7, eval_precision=0.658, eval_recall=0.536]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [02:38<00:00,  2.21it/s, F1=0.955, train_acc=0.995, train_loss=0.437, train_precision=0.957, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.595, eval_acc=0.935, eval_loss=10.6, eval_precision=0.638, eval_recall=0.56] \n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [03:25<00:00,  1.70it/s, F1=0.962, train_acc=0.996, train_loss=0.354, train_precision=0.965, train_recall=0.961]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.25it/s, F1=0.596, eval_acc=0.936, eval_loss=10.3, eval_precision=0.664, eval_recall=0.544]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.55it/s, F1=0.963, train_acc=0.996, train_loss=0.336, train_precision=0.965, train_recall=0.962]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s, F1=0.593, eval_acc=0.938, eval_loss=10.4, eval_precision=0.664, eval_recall=0.538]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_v1_16_4'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"inter_knowledge_file\": \"./data/tencent/THUOCL_FN_medical.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"inter_max_scan_num\": 20000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_v1_16_4\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 286MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 311MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 319MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 100kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 6697.49L/s]\n",
      "build line mapper: 4L [00:00, 22280.50L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 673.11it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 26159.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_word_vocab\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/inter_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:18<00:00, 306.33it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:02<00:00, 320.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing ZLEBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ZLEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ZLEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ZLEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.word_word_weight.bias', 'word_embeddings.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'inter_word_embeddings.weight', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_transform.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [03:48<00:00,  1.52it/s, F1=0.325, train_acc=0.91, train_loss=14, train_precision=0.368, train_recall=0.314]        \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.26it/s, F1=0.542, eval_acc=0.932, eval_loss=6.63, eval_precision=0.631, eval_recall=0.478]\n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [03:48<00:00,  1.53it/s, F1=0.612, train_acc=0.95, train_loss=3.74, train_precision=0.671, train_recall=0.589] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.551, eval_acc=0.934, eval_loss=6.15, eval_precision=0.705, eval_recall=0.456]\n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.60it/s, F1=0.674, train_acc=0.957, train_loss=2.69, train_precision=0.716, train_recall=0.656]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.33it/s, F1=0.515, eval_acc=0.929, eval_loss=7.32, eval_precision=0.79, eval_recall=0.384] \n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [03:01<00:00,  1.92it/s, F1=0.714, train_acc=0.963, train_loss=2.25, train_precision=0.746, train_recall=0.703]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.574, eval_acc=0.937, eval_loss=6.85, eval_precision=0.733, eval_recall=0.474]\n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.61it/s, F1=0.747, train_acc=0.968, train_loss=1.88, train_precision=0.769, train_recall=0.74] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.26it/s, F1=0.579, eval_acc=0.937, eval_loss=5.91, eval_precision=0.692, eval_recall=0.5]  \n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.55it/s, F1=0.78, train_acc=0.973, train_loss=1.63, train_precision=0.794, train_recall=0.776] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.592, eval_acc=0.939, eval_loss=7.56, eval_precision=0.731, eval_recall=0.5]  \n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.806, train_acc=0.976, train_loss=1.46, train_precision=0.818, train_recall=0.802]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.25it/s, F1=0.59, eval_acc=0.938, eval_loss=7.85, eval_precision=0.734, eval_recall=0.495] \n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.60it/s, F1=0.835, train_acc=0.98, train_loss=1.27, train_precision=0.845, train_recall=0.834] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s, F1=0.546, eval_acc=0.929, eval_loss=10.7, eval_precision=0.801, eval_recall=0.417]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.59it/s, F1=0.854, train_acc=0.982, train_loss=1.16, train_precision=0.861, train_recall=0.855]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.26it/s, F1=0.577, eval_acc=0.934, eval_loss=9.56, eval_precision=0.757, eval_recall=0.468]\n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.875, train_acc=0.985, train_loss=1.02, train_precision=0.877, train_recall=0.878] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.25it/s, F1=0.527, eval_acc=0.926, eval_loss=11.7, eval_precision=0.792, eval_recall=0.397]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.858, train_acc=0.982, train_loss=1.19, train_precision=0.871, train_recall=0.856]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s, F1=0.603, eval_acc=0.938, eval_loss=8.68, eval_precision=0.694, eval_recall=0.537]\n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.884, train_acc=0.986, train_loss=0.969, train_precision=0.891, train_recall=0.884]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.25it/s, F1=0.608, eval_acc=0.939, eval_loss=8.22, eval_precision=0.693, eval_recall=0.545]\n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.60it/s, F1=0.903, train_acc=0.988, train_loss=0.826, train_precision=0.907, train_recall=0.904]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.29it/s, F1=0.592, eval_acc=0.937, eval_loss=9.09, eval_precision=0.701, eval_recall=0.515]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.60it/s, F1=0.91, train_acc=0.989, train_loss=0.791, train_precision=0.911, train_recall=0.914] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.34it/s, F1=0.584, eval_acc=0.939, eval_loss=8.41, eval_precision=0.704, eval_recall=0.501]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [03:07<00:00,  1.86it/s, F1=0.928, train_acc=0.992, train_loss=0.61, train_precision=0.929, train_recall=0.93]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.55it/s, F1=0.591, eval_acc=0.937, eval_loss=10, eval_precision=0.709, eval_recall=0.509]  \n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:15<00:00,  1.78it/s, F1=0.929, train_acc=0.992, train_loss=0.615, train_precision=0.93, train_recall=0.93]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.29it/s, F1=0.588, eval_acc=0.937, eval_loss=10.5, eval_precision=0.726, eval_recall=0.497]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [03:36<00:00,  1.61it/s, F1=0.932, train_acc=0.992, train_loss=0.6, train_precision=0.933, train_recall=0.934]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.27it/s, F1=0.573, eval_acc=0.935, eval_loss=12.2, eval_precision=0.713, eval_recall=0.482]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [03:36<00:00,  1.61it/s, F1=0.936, train_acc=0.993, train_loss=0.551, train_precision=0.938, train_recall=0.936]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s, F1=0.6, eval_acc=0.939, eval_loss=11, eval_precision=0.69, eval_recall=0.533]     \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.939, train_acc=0.993, train_loss=0.554, train_precision=0.942, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.29it/s, F1=0.578, eval_acc=0.937, eval_loss=11.7, eval_precision=0.702, eval_recall=0.494]\n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:41<00:00,  1.58it/s, F1=0.941, train_acc=0.993, train_loss=0.523, train_precision=0.944, train_recall=0.94] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.27it/s, F1=0.595, eval_acc=0.938, eval_loss=11.6, eval_precision=0.685, eval_recall=0.529]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.938, train_acc=0.993, train_loss=0.517, train_precision=0.94, train_recall=0.938] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.601, eval_acc=0.937, eval_loss=10.3, eval_precision=0.65, eval_recall=0.562] \n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.59it/s, F1=0.941, train_acc=0.993, train_loss=0.53, train_precision=0.943, train_recall=0.941] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.25it/s, F1=0.608, eval_acc=0.939, eval_loss=10.2, eval_precision=0.69, eval_recall=0.546] \n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.95, train_acc=0.995, train_loss=0.453, train_precision=0.952, train_recall=0.949] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.598, eval_acc=0.938, eval_loss=11.4, eval_precision=0.658, eval_recall=0.55] \n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.949, train_acc=0.994, train_loss=0.435, train_precision=0.949, train_recall=0.951]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.26it/s, F1=0.602, eval_acc=0.939, eval_loss=12.6, eval_precision=0.669, eval_recall=0.551]\n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.945, train_acc=0.993, train_loss=0.507, train_precision=0.947, train_recall=0.946]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.33it/s, F1=0.612, eval_acc=0.942, eval_loss=11.9, eval_precision=0.682, eval_recall=0.559]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:25<00:00,  1.70it/s, F1=0.939, train_acc=0.994, train_loss=0.536, train_precision=0.942, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.59it/s, F1=0.6, eval_acc=0.938, eval_loss=11.3, eval_precision=0.635, eval_recall=0.571]  \n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [02:53<00:00,  2.01it/s, F1=0.947, train_acc=0.994, train_loss=0.468, train_precision=0.95, train_recall=0.946] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.34it/s, F1=0.585, eval_acc=0.938, eval_loss=10.5, eval_precision=0.646, eval_recall=0.537]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.946, train_acc=0.994, train_loss=0.471, train_precision=0.949, train_recall=0.944]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.32it/s, F1=0.6, eval_acc=0.939, eval_loss=14.4, eval_precision=0.692, eval_recall=0.532]  \n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.952, train_acc=0.995, train_loss=0.392, train_precision=0.954, train_recall=0.952]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.28it/s, F1=0.582, eval_acc=0.938, eval_loss=15.3, eval_precision=0.733, eval_recall=0.485]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.959, train_acc=0.995, train_loss=0.354, train_precision=0.96, train_recall=0.959] \n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.26it/s, F1=0.568, eval_acc=0.936, eval_loss=14.3, eval_precision=0.7, eval_recall=0.48]   \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_v1_16_4'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9392d1f0914889243d058bb73f0d89e61311fd6d751bbc8fa50e38d7d4ff811"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('NER': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
