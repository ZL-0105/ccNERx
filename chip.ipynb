{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_tx_1\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 244MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 192MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 177MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 197kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 83446.89L/s]\n",
      "build line mapper: 19L [00:00, 29287.68L/s]9 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 4107.82it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 100115.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1643: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n",
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:15<00:00, 949.05it/s] \n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:06<00:00, 787.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train:   4%|▍         | 9/235 [00:10<04:23,  1.16s/it, F1=0.000568, train_acc=0.123, train_loss=140, train_precision=0.000306, train_recall=0.00394] /home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [05:07<00:00,  1.31s/it, F1=0.377, train_acc=0.757, train_loss=33.5, train_precision=0.357, train_recall=0.401]       \n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.30it/s, F1=0.545, eval_acc=0.785, eval_loss=14.5, eval_precision=0.537, eval_recall=0.555]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.37s/it, F1=0.644, train_acc=0.841, train_loss=10.8, train_precision=0.643, train_recall=0.646]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.599, eval_acc=0.798, eval_loss=9.67, eval_precision=0.602, eval_recall=0.598]\n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.686, train_acc=0.857, train_loss=7.36, train_precision=0.687, train_recall=0.686]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.28it/s, F1=0.639, eval_acc=0.832, eval_loss=7.9, eval_precision=0.638, eval_recall=0.643] \n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.715, train_acc=0.872, train_loss=5.99, train_precision=0.715, train_recall=0.715]\n",
      "Eval Result: 100%|██████████| 79/79 [00:48<00:00,  1.64it/s, F1=0.648, eval_acc=0.842, eval_loss=7.53, eval_precision=0.641, eval_recall=0.658]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [05:12<00:00,  1.33s/it, F1=0.74, train_acc=0.885, train_loss=5.09, train_precision=0.739, train_recall=0.742] \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.647, eval_acc=0.838, eval_loss=7.47, eval_precision=0.639, eval_recall=0.66] \n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [05:20<00:00,  1.36s/it, F1=0.764, train_acc=0.897, train_loss=4.51, train_precision=0.762, train_recall=0.767]\n",
      "Eval Result: 100%|██████████| 79/79 [00:59<00:00,  1.32it/s, F1=0.616, eval_acc=0.79, eval_loss=7.98, eval_precision=0.604, eval_recall=0.631] \n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [05:17<00:00,  1.35s/it, F1=0.781, train_acc=0.905, train_loss=4.15, train_precision=0.778, train_recall=0.784]\n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.30it/s, F1=0.577, eval_acc=0.749, eval_loss=8.94, eval_precision=0.577, eval_recall=0.58] \n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [05:17<00:00,  1.35s/it, F1=0.797, train_acc=0.913, train_loss=3.89, train_precision=0.794, train_recall=0.801]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.624, eval_acc=0.816, eval_loss=7.97, eval_precision=0.62, eval_recall=0.629] \n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [05:29<00:00,  1.40s/it, F1=0.815, train_acc=0.922, train_loss=3.55, train_precision=0.812, train_recall=0.819]\n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.24it/s, F1=0.626, eval_acc=0.823, eval_loss=8.33, eval_precision=0.637, eval_recall=0.618]\n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [05:26<00:00,  1.39s/it, F1=0.828, train_acc=0.928, train_loss=3.33, train_precision=0.825, train_recall=0.832]\n",
      "Eval Result: 100%|██████████| 79/79 [01:05<00:00,  1.21it/s, F1=0.609, eval_acc=0.808, eval_loss=8.39, eval_precision=0.626, eval_recall=0.596]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [05:26<00:00,  1.39s/it, F1=0.846, train_acc=0.937, train_loss=3.01, train_precision=0.842, train_recall=0.85] \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.57it/s, F1=0.605, eval_acc=0.799, eval_loss=8.64, eval_precision=0.608, eval_recall=0.604]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.38s/it, F1=0.862, train_acc=0.944, train_loss=2.75, train_precision=0.859, train_recall=0.865]\n",
      "Eval Result: 100%|██████████| 79/79 [00:58<00:00,  1.34it/s, F1=0.633, eval_acc=0.828, eval_loss=8.97, eval_precision=0.619, eval_recall=0.652]\n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:58<00:00,  1.27s/it, F1=0.874, train_acc=0.95, train_loss=2.55, train_precision=0.872, train_recall=0.878] \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.90it/s, F1=0.637, eval_acc=0.838, eval_loss=9.52, eval_precision=0.633, eval_recall=0.645]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.38s/it, F1=0.883, train_acc=0.953, train_loss=2.4, train_precision=0.88, train_recall=0.888]  \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.639, eval_acc=0.838, eval_loss=10.8, eval_precision=0.645, eval_recall=0.637]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.897, train_acc=0.959, train_loss=2.22, train_precision=0.894, train_recall=0.901]\n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.25it/s, F1=0.63, eval_acc=0.836, eval_loss=11.3, eval_precision=0.62, eval_recall=0.643]  \n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [05:17<00:00,  1.35s/it, F1=0.905, train_acc=0.964, train_loss=2.05, train_precision=0.902, train_recall=0.908]\n",
      "Eval Result: 100%|██████████| 79/79 [00:56<00:00,  1.41it/s, F1=0.627, eval_acc=0.835, eval_loss=12.7, eval_precision=0.614, eval_recall=0.643]\n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [04:39<00:00,  1.19s/it, F1=0.908, train_acc=0.964, train_loss=2.01, train_precision=0.906, train_recall=0.911]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, F1=0.631, eval_acc=0.836, eval_loss=12.1, eval_precision=0.617, eval_recall=0.648]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [05:02<00:00,  1.29s/it, F1=0.916, train_acc=0.967, train_loss=1.9, train_precision=0.914, train_recall=0.919] \n",
      "Eval Result: 100%|██████████| 79/79 [00:58<00:00,  1.34it/s, F1=0.622, eval_acc=0.83, eval_loss=11.9, eval_precision=0.63, eval_recall=0.619]  \n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [05:03<00:00,  1.29s/it, F1=0.924, train_acc=0.971, train_loss=1.73, train_precision=0.922, train_recall=0.926]\n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.37it/s, F1=0.612, eval_acc=0.821, eval_loss=11.8, eval_precision=0.611, eval_recall=0.616]\n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:44<00:00,  1.21s/it, F1=0.928, train_acc=0.973, train_loss=1.67, train_precision=0.926, train_recall=0.93] \n",
      "Eval Result: 100%|██████████| 79/79 [01:00<00:00,  1.31it/s, F1=0.609, eval_acc=0.819, eval_loss=12, eval_precision=0.625, eval_recall=0.597]  \n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:53<00:00,  1.25s/it, F1=0.934, train_acc=0.975, train_loss=1.56, train_precision=0.932, train_recall=0.936]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.616, eval_acc=0.823, eval_loss=12.5, eval_precision=0.634, eval_recall=0.602]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:10<00:00,  1.07s/it, F1=0.94, train_acc=0.978, train_loss=1.42, train_precision=0.938, train_recall=0.942] \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.628, eval_acc=0.832, eval_loss=12.9, eval_precision=0.652, eval_recall=0.609]\n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.945, train_acc=0.98, train_loss=1.33, train_precision=0.943, train_recall=0.947] \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.79it/s, F1=0.622, eval_acc=0.831, eval_loss=13.9, eval_precision=0.641, eval_recall=0.606]\n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:05<00:00,  1.05s/it, F1=0.948, train_acc=0.98, train_loss=1.32, train_precision=0.946, train_recall=0.95]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.63, eval_acc=0.835, eval_loss=13.7, eval_precision=0.639, eval_recall=0.624] \n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:06<00:00,  1.05s/it, F1=0.95, train_acc=0.981, train_loss=1.27, train_precision=0.949, train_recall=0.952] \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.625, eval_acc=0.832, eval_loss=13.5, eval_precision=0.634, eval_recall=0.619]\n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [04:05<00:00,  1.04s/it, F1=0.953, train_acc=0.983, train_loss=1.19, train_precision=0.952, train_recall=0.954]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.631, eval_acc=0.834, eval_loss=13.5, eval_precision=0.622, eval_recall=0.643]\n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [04:05<00:00,  1.04s/it, F1=0.956, train_acc=0.983, train_loss=1.14, train_precision=0.955, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.629, eval_acc=0.832, eval_loss=14.4, eval_precision=0.624, eval_recall=0.636]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [04:06<00:00,  1.05s/it, F1=0.957, train_acc=0.983, train_loss=1.14, train_precision=0.957, train_recall=0.958]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.626, eval_acc=0.834, eval_loss=14.9, eval_precision=0.633, eval_recall=0.622]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [04:13<00:00,  1.08s/it, F1=0.958, train_acc=0.984, train_loss=1.1, train_precision=0.957, train_recall=0.958] \n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.82it/s, F1=0.627, eval_acc=0.832, eval_loss=15.6, eval_precision=0.631, eval_recall=0.625]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [04:03<00:00,  1.03s/it, F1=0.959, train_acc=0.984, train_loss=1.12, train_precision=0.958, train_recall=0.96] \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.63, eval_acc=0.832, eval_loss=14.8, eval_precision=0.619, eval_recall=0.643] \n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'max_scan_num': 1000000,\n",
    "    # 'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/chip/train_data.json',\n",
    "    'eval_file': './data/chip/val_data.json',\n",
    "    'test_file': './data/chip/val_data.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/chip/chip_tags_list.txt',\n",
    "    # 'loader_name': 'le_loader_zl',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/tencent_medicine_vocab.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/fn_thu_chn.txt\",\n",
    "    # \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 64,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'task_name': 'chip_tx_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_tx_2\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 312MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 356MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 383MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 338kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 45382.56L/s]\n",
      "build line mapper: 19L [00:00, 167068.71L/s] [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 4700.47it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 168481.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:11<00:00, 1346.70it/s]\n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:03<00:00, 1367.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [04:10<00:00,  1.07s/it, F1=0.327, train_acc=0.752, train_loss=37.8, train_precision=0.297, train_recall=0.368]        \n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.558, eval_acc=0.823, eval_loss=16.9, eval_precision=0.551, eval_recall=0.569]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.643, train_acc=0.843, train_loss=11.6, train_precision=0.643, train_recall=0.644]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.606, eval_acc=0.799, eval_loss=10.3, eval_precision=0.611, eval_recall=0.605]\n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [04:05<00:00,  1.05s/it, F1=0.688, train_acc=0.859, train_loss=7.59, train_precision=0.691, train_recall=0.686]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.623, eval_acc=0.815, eval_loss=8.4, eval_precision=0.627, eval_recall=0.622] \n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [04:07<00:00,  1.05s/it, F1=0.713, train_acc=0.873, train_loss=6.1, train_precision=0.715, train_recall=0.712] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.615, eval_acc=0.794, eval_loss=8.07, eval_precision=0.623, eval_recall=0.609]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.736, train_acc=0.884, train_loss=5.24, train_precision=0.736, train_recall=0.738]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.88it/s, F1=0.643, eval_acc=0.838, eval_loss=7.49, eval_precision=0.639, eval_recall=0.649]\n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [04:04<00:00,  1.04s/it, F1=0.755, train_acc=0.893, train_loss=4.69, train_precision=0.754, train_recall=0.757]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.6, eval_acc=0.779, eval_loss=8.17, eval_precision=0.605, eval_recall=0.597]  \n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.775, train_acc=0.902, train_loss=4.32, train_precision=0.772, train_recall=0.778]\n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.77it/s, F1=0.636, eval_acc=0.837, eval_loss=7.96, eval_precision=0.655, eval_recall=0.621]\n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [04:03<00:00,  1.04s/it, F1=0.792, train_acc=0.911, train_loss=3.9, train_precision=0.789, train_recall=0.797] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.638, eval_acc=0.834, eval_loss=8, eval_precision=0.644, eval_recall=0.636]   \n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [04:06<00:00,  1.05s/it, F1=0.815, train_acc=0.922, train_loss=3.53, train_precision=0.812, train_recall=0.819]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.636, eval_acc=0.829, eval_loss=8.21, eval_precision=0.631, eval_recall=0.642]\n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [04:07<00:00,  1.05s/it, F1=0.829, train_acc=0.928, train_loss=3.33, train_precision=0.825, train_recall=0.833]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.631, eval_acc=0.829, eval_loss=8.74, eval_precision=0.628, eval_recall=0.637]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.844, train_acc=0.936, train_loss=3.04, train_precision=0.84, train_recall=0.848] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.84it/s, F1=0.625, eval_acc=0.827, eval_loss=8.87, eval_precision=0.628, eval_recall=0.626]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [04:03<00:00,  1.04s/it, F1=0.861, train_acc=0.944, train_loss=2.76, train_precision=0.857, train_recall=0.865]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.63, eval_acc=0.828, eval_loss=9.2, eval_precision=0.615, eval_recall=0.648]  \n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.868, train_acc=0.947, train_loss=2.63, train_precision=0.865, train_recall=0.872]\n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.83it/s, F1=0.588, eval_acc=0.787, eval_loss=10.5, eval_precision=0.588, eval_recall=0.591]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.877, train_acc=0.95, train_loss=2.51, train_precision=0.874, train_recall=0.88]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:44<00:00,  1.78it/s, F1=0.575, eval_acc=0.771, eval_loss=10.8, eval_precision=0.568, eval_recall=0.584]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [04:21<00:00,  1.11s/it, F1=0.88, train_acc=0.95, train_loss=2.5, train_precision=0.878, train_recall=0.883]   \n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.70it/s, F1=0.64, eval_acc=0.831, eval_loss=9.92, eval_precision=0.618, eval_recall=0.666] \n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.887, train_acc=0.953, train_loss=2.41, train_precision=0.885, train_recall=0.89] \n",
      "Eval Result: 100%|██████████| 79/79 [00:49<00:00,  1.60it/s, F1=0.639, eval_acc=0.838, eval_loss=10.9, eval_precision=0.639, eval_recall=0.641]\n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [04:25<00:00,  1.13s/it, F1=0.899, train_acc=0.96, train_loss=2.11, train_precision=0.896, train_recall=0.903] \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, F1=0.64, eval_acc=0.838, eval_loss=11.4, eval_precision=0.646, eval_recall=0.637] \n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [04:38<00:00,  1.19s/it, F1=0.913, train_acc=0.966, train_loss=1.84, train_precision=0.91, train_recall=0.916] \n",
      "Eval Result: 100%|██████████| 79/79 [00:56<00:00,  1.39it/s, F1=0.624, eval_acc=0.825, eval_loss=11.6, eval_precision=0.611, eval_recall=0.64] \n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [04:51<00:00,  1.24s/it, F1=0.922, train_acc=0.971, train_loss=1.71, train_precision=0.92, train_recall=0.925] \n",
      "Eval Result: 100%|██████████| 79/79 [00:56<00:00,  1.40it/s, F1=0.622, eval_acc=0.824, eval_loss=12.2, eval_precision=0.604, eval_recall=0.643]\n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:55<00:00,  1.26s/it, F1=0.931, train_acc=0.975, train_loss=1.58, train_precision=0.929, train_recall=0.933]\n",
      "Eval Result: 100%|██████████| 79/79 [00:56<00:00,  1.39it/s, F1=0.628, eval_acc=0.828, eval_loss=12.6, eval_precision=0.597, eval_recall=0.664]\n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:54<00:00,  1.25s/it, F1=0.934, train_acc=0.975, train_loss=1.53, train_precision=0.932, train_recall=0.937]\n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.44it/s, F1=0.635, eval_acc=0.835, eval_loss=12.9, eval_precision=0.604, eval_recall=0.672]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:53<00:00,  1.25s/it, F1=0.935, train_acc=0.976, train_loss=1.5, train_precision=0.934, train_recall=0.937] \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.52it/s, F1=0.644, eval_acc=0.84, eval_loss=13.6, eval_precision=0.612, eval_recall=0.681] \n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:48<00:00,  1.23s/it, F1=0.936, train_acc=0.975, train_loss=1.49, train_precision=0.934, train_recall=0.939]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.52it/s, F1=0.635, eval_acc=0.838, eval_loss=13.7, eval_precision=0.62, eval_recall=0.653] \n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:50<00:00,  1.24s/it, F1=0.941, train_acc=0.978, train_loss=1.42, train_precision=0.939, train_recall=0.943]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.56it/s, F1=0.633, eval_acc=0.834, eval_loss=13.8, eval_precision=0.639, eval_recall=0.63] \n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:48<00:00,  1.23s/it, F1=0.941, train_acc=0.978, train_loss=1.41, train_precision=0.94, train_recall=0.944] \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, F1=0.629, eval_acc=0.833, eval_loss=13.3, eval_precision=0.633, eval_recall=0.629]\n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [04:47<00:00,  1.22s/it, F1=0.946, train_acc=0.98, train_loss=1.28, train_precision=0.945, train_recall=0.947] \n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.51it/s, F1=0.641, eval_acc=0.838, eval_loss=13.9, eval_precision=0.638, eval_recall=0.646]\n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [04:47<00:00,  1.22s/it, F1=0.95, train_acc=0.981, train_loss=1.19, train_precision=0.949, train_recall=0.951] \n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.45it/s, F1=0.636, eval_acc=0.836, eval_loss=13.7, eval_precision=0.624, eval_recall=0.651]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [04:48<00:00,  1.23s/it, F1=0.952, train_acc=0.983, train_loss=1.14, train_precision=0.951, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, F1=0.633, eval_acc=0.834, eval_loss=14.6, eval_precision=0.612, eval_recall=0.659]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [04:50<00:00,  1.24s/it, F1=0.957, train_acc=0.985, train_loss=1.03, train_precision=0.956, train_recall=0.959]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, F1=0.627, eval_acc=0.829, eval_loss=14.1, eval_precision=0.61, eval_recall=0.647] \n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [04:47<00:00,  1.22s/it, F1=0.961, train_acc=0.986, train_loss=0.981, train_precision=0.96, train_recall=0.962] \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.55it/s, F1=0.621, eval_acc=0.823, eval_loss=14.4, eval_precision=0.611, eval_recall=0.633]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_tx_2'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_tx_3\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 252MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 363MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 366MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 262kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 107837.32L/s]\n",
      "build line mapper: 19L [00:00, 142053.08L/s] [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 5225.69it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 187952.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:16<00:00, 892.52it/s] \n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:07<00:00, 628.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [04:49<00:00,  1.23s/it, F1=0.392, train_acc=0.742, train_loss=37.2, train_precision=0.374, train_recall=0.414]        \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.55it/s, F1=0.598, eval_acc=0.833, eval_loss=14.1, eval_precision=0.59, eval_recall=0.609] \n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [04:47<00:00,  1.22s/it, F1=0.637, train_acc=0.84, train_loss=10.9, train_precision=0.635, train_recall=0.642] \n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.56it/s, F1=0.631, eval_acc=0.832, eval_loss=8.97, eval_precision=0.634, eval_recall=0.632]\n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [04:45<00:00,  1.21s/it, F1=0.679, train_acc=0.854, train_loss=7.4, train_precision=0.678, train_recall=0.68]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:49<00:00,  1.60it/s, F1=0.637, eval_acc=0.831, eval_loss=7.78, eval_precision=0.634, eval_recall=0.644]\n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [04:47<00:00,  1.22s/it, F1=0.704, train_acc=0.867, train_loss=6.1, train_precision=0.702, train_recall=0.706] \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, F1=0.648, eval_acc=0.841, eval_loss=7.46, eval_precision=0.638, eval_recall=0.661]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [04:47<00:00,  1.22s/it, F1=0.725, train_acc=0.877, train_loss=5.28, train_precision=0.723, train_recall=0.728]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, F1=0.655, eval_acc=0.844, eval_loss=7.81, eval_precision=0.651, eval_recall=0.661]\n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [04:46<00:00,  1.22s/it, F1=0.741, train_acc=0.884, train_loss=4.85, train_precision=0.739, train_recall=0.745]\n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, F1=0.646, eval_acc=0.839, eval_loss=8.29, eval_precision=0.639, eval_recall=0.656]\n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [04:49<00:00,  1.23s/it, F1=0.758, train_acc=0.893, train_loss=4.46, train_precision=0.756, train_recall=0.762]\n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.46it/s, F1=0.63, eval_acc=0.832, eval_loss=9, eval_precision=0.613, eval_recall=0.651]    \n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [04:50<00:00,  1.23s/it, F1=0.772, train_acc=0.899, train_loss=4.22, train_precision=0.769, train_recall=0.777]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.55it/s, F1=0.606, eval_acc=0.792, eval_loss=9.91, eval_precision=0.568, eval_recall=0.651]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [04:52<00:00,  1.25s/it, F1=0.793, train_acc=0.91, train_loss=3.78, train_precision=0.789, train_recall=0.797] \n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, F1=0.615, eval_acc=0.811, eval_loss=9.13, eval_precision=0.571, eval_recall=0.669]\n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [04:45<00:00,  1.22s/it, F1=0.812, train_acc=0.92, train_loss=3.33, train_precision=0.809, train_recall=0.817] \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, F1=0.626, eval_acc=0.827, eval_loss=9.35, eval_precision=0.586, eval_recall=0.676]\n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:46<00:00,  1.22s/it, F1=0.825, train_acc=0.925, train_loss=3.15, train_precision=0.822, train_recall=0.83] \n",
      "Eval Result: 100%|██████████| 79/79 [00:49<00:00,  1.60it/s, F1=0.644, eval_acc=0.84, eval_loss=9.37, eval_precision=0.621, eval_recall=0.672] \n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [04:12<00:00,  1.07s/it, F1=0.842, train_acc=0.933, train_loss=2.92, train_precision=0.838, train_recall=0.847]\n",
      "Eval Result: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s, F1=0.638, eval_acc=0.84, eval_loss=9.35, eval_precision=0.63, eval_recall=0.649]  \n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:04<00:00,  1.04s/it, F1=0.852, train_acc=0.936, train_loss=2.78, train_precision=0.848, train_recall=0.856]\n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.81it/s, F1=0.625, eval_acc=0.822, eval_loss=9.13, eval_precision=0.619, eval_recall=0.634]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [04:04<00:00,  1.04s/it, F1=0.862, train_acc=0.942, train_loss=2.54, train_precision=0.859, train_recall=0.866]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s, F1=0.622, eval_acc=0.825, eval_loss=9.48, eval_precision=0.639, eval_recall=0.609]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.874, train_acc=0.947, train_loss=2.35, train_precision=0.872, train_recall=0.878]\n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.80it/s, F1=0.626, eval_acc=0.828, eval_loss=9.97, eval_precision=0.622, eval_recall=0.632]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [04:10<00:00,  1.07s/it, F1=0.891, train_acc=0.956, train_loss=2.04, train_precision=0.888, train_recall=0.894]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.629, eval_acc=0.83, eval_loss=10.9, eval_precision=0.607, eval_recall=0.654] \n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [04:06<00:00,  1.05s/it, F1=0.901, train_acc=0.961, train_loss=1.87, train_precision=0.898, train_recall=0.904]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.624, eval_acc=0.826, eval_loss=11.9, eval_precision=0.608, eval_recall=0.642]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.912, train_acc=0.966, train_loss=1.7, train_precision=0.91, train_recall=0.915]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.629, eval_acc=0.833, eval_loss=11.6, eval_precision=0.638, eval_recall=0.624]\n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [04:07<00:00,  1.05s/it, F1=0.921, train_acc=0.97, train_loss=1.54, train_precision=0.919, train_recall=0.924] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.636, eval_acc=0.837, eval_loss=12.4, eval_precision=0.636, eval_recall=0.638]\n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.928, train_acc=0.973, train_loss=1.46, train_precision=0.926, train_recall=0.931]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.63, eval_acc=0.834, eval_loss=14, eval_precision=0.627, eval_recall=0.634]   \n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:06<00:00,  1.05s/it, F1=0.93, train_acc=0.973, train_loss=1.45, train_precision=0.928, train_recall=0.932] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.636, eval_acc=0.832, eval_loss=14.3, eval_precision=0.632, eval_recall=0.642]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:06<00:00,  1.05s/it, F1=0.932, train_acc=0.973, train_loss=1.43, train_precision=0.93, train_recall=0.934] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.623, eval_acc=0.831, eval_loss=15.8, eval_precision=0.641, eval_recall=0.609]\n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:07<00:00,  1.05s/it, F1=0.928, train_acc=0.97, train_loss=1.54, train_precision=0.926, train_recall=0.929] \n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.80it/s, F1=0.623, eval_acc=0.832, eval_loss=14.2, eval_precision=0.64, eval_recall=0.61]  \n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:10<00:00,  1.07s/it, F1=0.929, train_acc=0.971, train_loss=1.52, train_precision=0.927, train_recall=0.93] \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.63, eval_acc=0.834, eval_loss=13.1, eval_precision=0.637, eval_recall=0.625] \n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:07<00:00,  1.05s/it, F1=0.939, train_acc=0.976, train_loss=1.28, train_precision=0.938, train_recall=0.941]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.609, eval_acc=0.819, eval_loss=13.7, eval_precision=0.627, eval_recall=0.595]\n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [04:04<00:00,  1.04s/it, F1=0.948, train_acc=0.98, train_loss=1.09, train_precision=0.947, train_recall=0.95]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.68it/s, F1=0.619, eval_acc=0.825, eval_loss=14.1, eval_precision=0.622, eval_recall=0.618]\n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [04:07<00:00,  1.05s/it, F1=0.955, train_acc=0.983, train_loss=0.963, train_precision=0.954, train_recall=0.956]\n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.80it/s, F1=0.62, eval_acc=0.825, eval_loss=14.3, eval_precision=0.627, eval_recall=0.616] \n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.958, train_acc=0.985, train_loss=0.914, train_precision=0.957, train_recall=0.959]\n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.70it/s, F1=0.625, eval_acc=0.829, eval_loss=15.5, eval_precision=0.625, eval_recall=0.629]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [04:15<00:00,  1.09s/it, F1=0.962, train_acc=0.986, train_loss=0.867, train_precision=0.961, train_recall=0.962]\n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, F1=0.634, eval_acc=0.835, eval_loss=16.3, eval_precision=0.627, eval_recall=0.643]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [04:07<00:00,  1.05s/it, F1=0.964, train_acc=0.987, train_loss=0.816, train_precision=0.964, train_recall=0.964]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.628, eval_acc=0.835, eval_loss=16.5, eval_precision=0.626, eval_recall=0.632]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_tx_3'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_tx_4\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 288MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 359MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 296MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 231kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 107112.60L/s]\n",
      "build line mapper: 19L [00:00, 151217.79L/s] [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 5138.09it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 146492.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:11<00:00, 1303.11it/s]\n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:03<00:00, 1351.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.377, train_acc=0.754, train_loss=33, train_precision=0.363, train_recall=0.393]          \n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.591, eval_acc=0.827, eval_loss=13.4, eval_precision=0.563, eval_recall=0.624]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [04:12<00:00,  1.07s/it, F1=0.645, train_acc=0.842, train_loss=10.4, train_precision=0.648, train_recall=0.643]\n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.81it/s, F1=0.642, eval_acc=0.839, eval_loss=8.97, eval_precision=0.628, eval_recall=0.66] \n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [04:09<00:00,  1.06s/it, F1=0.689, train_acc=0.859, train_loss=7.15, train_precision=0.692, train_recall=0.688]\n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.82it/s, F1=0.641, eval_acc=0.836, eval_loss=7.76, eval_precision=0.629, eval_recall=0.657]\n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [04:08<00:00,  1.06s/it, F1=0.717, train_acc=0.873, train_loss=5.83, train_precision=0.717, train_recall=0.718]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.85it/s, F1=0.633, eval_acc=0.833, eval_loss=7.72, eval_precision=0.621, eval_recall=0.649]\n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [04:06<00:00,  1.05s/it, F1=0.738, train_acc=0.883, train_loss=5.09, train_precision=0.737, train_recall=0.739]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, F1=0.624, eval_acc=0.826, eval_loss=7.79, eval_precision=0.615, eval_recall=0.636]\n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [04:35<00:00,  1.17s/it, F1=0.759, train_acc=0.894, train_loss=4.6, train_precision=0.757, train_recall=0.761] \n",
      "Eval Result: 100%|██████████| 79/79 [00:54<00:00,  1.45it/s, F1=0.622, eval_acc=0.826, eval_loss=7.88, eval_precision=0.609, eval_recall=0.636]\n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [04:54<00:00,  1.25s/it, F1=0.779, train_acc=0.905, train_loss=4.15, train_precision=0.776, train_recall=0.783]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, F1=0.632, eval_acc=0.821, eval_loss=8.1, eval_precision=0.623, eval_recall=0.643] \n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [04:45<00:00,  1.22s/it, F1=0.797, train_acc=0.913, train_loss=3.84, train_precision=0.794, train_recall=0.801]\n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.80it/s, F1=0.643, eval_acc=0.832, eval_loss=8.43, eval_precision=0.623, eval_recall=0.665]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [04:40<00:00,  1.19s/it, F1=0.814, train_acc=0.92, train_loss=3.53, train_precision=0.811, train_recall=0.818] \n",
      "Eval Result: 100%|██████████| 79/79 [00:53<00:00,  1.49it/s, F1=0.641, eval_acc=0.836, eval_loss=9.2, eval_precision=0.622, eval_recall=0.664] \n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [04:48<00:00,  1.23s/it, F1=0.832, train_acc=0.93, train_loss=3.21, train_precision=0.829, train_recall=0.836] \n",
      "Eval Result: 100%|██████████| 79/79 [00:48<00:00,  1.63it/s, F1=0.642, eval_acc=0.837, eval_loss=9.2, eval_precision=0.638, eval_recall=0.648] \n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:27<00:00,  1.14s/it, F1=0.85, train_acc=0.939, train_loss=2.93, train_precision=0.847, train_recall=0.854] \n",
      "Eval Result: 100%|██████████| 79/79 [00:48<00:00,  1.62it/s, F1=0.636, eval_acc=0.833, eval_loss=9.59, eval_precision=0.647, eval_recall=0.627]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [04:24<00:00,  1.12s/it, F1=0.863, train_acc=0.944, train_loss=2.74, train_precision=0.859, train_recall=0.867]\n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.69it/s, F1=0.625, eval_acc=0.823, eval_loss=9.99, eval_precision=0.616, eval_recall=0.637]\n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [04:25<00:00,  1.13s/it, F1=0.869, train_acc=0.947, train_loss=2.64, train_precision=0.866, train_recall=0.872]\n",
      "Eval Result: 100%|██████████| 79/79 [00:49<00:00,  1.58it/s, F1=0.61, eval_acc=0.804, eval_loss=10.5, eval_precision=0.58, eval_recall=0.646]  \n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.883, train_acc=0.953, train_loss=2.4, train_precision=0.88, train_recall=0.887]  \n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.66it/s, F1=0.618, eval_acc=0.813, eval_loss=9.73, eval_precision=0.612, eval_recall=0.626]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [04:20<00:00,  1.11s/it, F1=0.893, train_acc=0.957, train_loss=2.22, train_precision=0.89, train_recall=0.896] \n",
      "Eval Result: 100%|██████████| 79/79 [00:47<00:00,  1.66it/s, F1=0.602, eval_acc=0.801, eval_loss=10.3, eval_precision=0.609, eval_recall=0.597]\n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [04:24<00:00,  1.12s/it, F1=0.898, train_acc=0.959, train_loss=2.15, train_precision=0.894, train_recall=0.901]\n",
      "Eval Result: 100%|██████████| 79/79 [00:50<00:00,  1.57it/s, F1=0.617, eval_acc=0.821, eval_loss=9.83, eval_precision=0.634, eval_recall=0.602]\n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [04:24<00:00,  1.13s/it, F1=0.905, train_acc=0.962, train_loss=2.05, train_precision=0.903, train_recall=0.908]\n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.70it/s, F1=0.627, eval_acc=0.827, eval_loss=10.5, eval_precision=0.612, eval_recall=0.646]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.914, train_acc=0.967, train_loss=1.83, train_precision=0.912, train_recall=0.917]\n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.70it/s, F1=0.628, eval_acc=0.828, eval_loss=11.1, eval_precision=0.609, eval_recall=0.65] \n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.922, train_acc=0.97, train_loss=1.7, train_precision=0.92, train_recall=0.925]   \n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.72it/s, F1=0.63, eval_acc=0.83, eval_loss=11.4, eval_precision=0.613, eval_recall=0.65]   \n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [04:22<00:00,  1.12s/it, F1=0.929, train_acc=0.973, train_loss=1.59, train_precision=0.928, train_recall=0.932]\n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.69it/s, F1=0.632, eval_acc=0.833, eval_loss=11.6, eval_precision=0.618, eval_recall=0.65] \n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [04:21<00:00,  1.11s/it, F1=0.935, train_acc=0.975, train_loss=1.5, train_precision=0.934, train_recall=0.936] \n",
      "Eval Result: 100%|██████████| 79/79 [00:46<00:00,  1.70it/s, F1=0.629, eval_acc=0.83, eval_loss=11.6, eval_precision=0.62, eval_recall=0.64]   \n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [04:23<00:00,  1.12s/it, F1=0.937, train_acc=0.976, train_loss=1.45, train_precision=0.936, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 79/79 [00:49<00:00,  1.61it/s, F1=0.627, eval_acc=0.83, eval_loss=12.3, eval_precision=0.616, eval_recall=0.64]  \n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [04:21<00:00,  1.11s/it, F1=0.944, train_acc=0.979, train_loss=1.33, train_precision=0.943, train_recall=0.946]\n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.72it/s, F1=0.633, eval_acc=0.834, eval_loss=12.2, eval_precision=0.63, eval_recall=0.638] \n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [04:19<00:00,  1.11s/it, F1=0.947, train_acc=0.98, train_loss=1.29, train_precision=0.946, train_recall=0.949] \n",
      "Eval Result: 100%|██████████| 79/79 [00:43<00:00,  1.80it/s, F1=0.629, eval_acc=0.831, eval_loss=12.9, eval_precision=0.623, eval_recall=0.638]\n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [04:56<00:00,  1.26s/it, F1=0.949, train_acc=0.981, train_loss=1.24, train_precision=0.948, train_recall=0.951]\n",
      "Eval Result: 100%|██████████| 79/79 [00:45<00:00,  1.74it/s, F1=0.628, eval_acc=0.827, eval_loss=12.8, eval_precision=0.613, eval_recall=0.646]\n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [05:16<00:00,  1.35s/it, F1=0.937, train_acc=0.976, train_loss=1.5, train_precision=0.936, train_recall=0.938] \n",
      "Eval Result: 100%|██████████| 79/79 [01:08<00:00,  1.15it/s, F1=0.615, eval_acc=0.818, eval_loss=12.7, eval_precision=0.604, eval_recall=0.628]\n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.38s/it, F1=0.936, train_acc=0.977, train_loss=1.42, train_precision=0.936, train_recall=0.937]\n",
      "Eval Result: 100%|██████████| 79/79 [01:05<00:00,  1.20it/s, F1=0.63, eval_acc=0.828, eval_loss=13.1, eval_precision=0.63, eval_recall=0.632]  \n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [05:31<00:00,  1.41s/it, F1=0.946, train_acc=0.98, train_loss=1.22, train_precision=0.945, train_recall=0.947] \n",
      "Eval Result: 100%|██████████| 79/79 [01:04<00:00,  1.22it/s, F1=0.63, eval_acc=0.833, eval_loss=13.4, eval_precision=0.627, eval_recall=0.634] \n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [05:26<00:00,  1.39s/it, F1=0.956, train_acc=0.984, train_loss=1.05, train_precision=0.955, train_recall=0.957] \n",
      "Eval Result: 100%|██████████| 79/79 [01:05<00:00,  1.20it/s, F1=0.623, eval_acc=0.828, eval_loss=14, eval_precision=0.628, eval_recall=0.62]   \n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.38s/it, F1=0.957, train_acc=0.984, train_loss=1.02, train_precision=0.957, train_recall=0.958]\n",
      "Eval Result: 100%|██████████| 79/79 [01:04<00:00,  1.22it/s, F1=0.632, eval_acc=0.835, eval_loss=14.6, eval_precision=0.627, eval_recall=0.638]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_tx_4'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 64,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/chip/train_data.json\",\n",
      "    \"eval_file\": \"./data/chip/val_data.json\",\n",
      "    \"test_file\": \"./data/chip/val_data.json\",\n",
      "    \"tag_file\": \"data/chip/chip_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 128,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chip_tx_5\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/chip/train_data.json etag: 100%|██████████| 10.4M/10.4M [00:00<00:00, 197MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 249MB/s]\n",
      "calculate ./data/chip/val_data.json etag: 100%|██████████| 3.47M/3.47M [00:00<00:00, 301MB/s]\n",
      "calculate data/chip/chip_tags_list.txt etag: 100%|██████████| 109/109 [00:00<00:00, 423kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/matched_words\n",
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/chip/chip_tags_list.txt: 19L [00:00, 55806.57L/s]\n",
      "build line mapper: 19L [00:00, 170281.57L/s] [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 19/19 [00:00<00:00, 5296.54it/s]\n",
      "load vocab from list: 100%|██████████| 19/19 [00:00<00:00, 58726.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/48e17aade5e4d463fd71425011d5b491-3_8da604b8f72e97426416dc5021a1064c_8da604b8f72e97426416dc5021a1064c_3f65f4fa3d5578b528de9e2e2452728f/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "load dataset from ./data/chip/train_data.json: 100%|██████████| 15000/15000 [00:24<00:00, 611.81it/s] \n",
      "load dataset from ./data/chip/val_data.json: 100%|██████████| 5000/5000 [00:08<00:00, 569.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.417, train_acc=0.755, train_loss=29.9, train_precision=0.409, train_recall=0.429]        \n",
      "Eval Result: 100%|██████████| 79/79 [01:04<00:00,  1.23it/s, F1=0.614, eval_acc=0.835, eval_loss=12.7, eval_precision=0.597, eval_recall=0.634]\n",
      "Epoch: 2/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.652, train_acc=0.843, train_loss=9.88, train_precision=0.653, train_recall=0.652]\n",
      "Eval Result: 100%|██████████| 79/79 [01:07<00:00,  1.17it/s, F1=0.641, eval_acc=0.837, eval_loss=8.6, eval_precision=0.648, eval_recall=0.636] \n",
      "Epoch: 3/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.39s/it, F1=0.689, train_acc=0.856, train_loss=7.04, train_precision=0.69, train_recall=0.689] \n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.24it/s, F1=0.638, eval_acc=0.833, eval_loss=7.52, eval_precision=0.651, eval_recall=0.628]\n",
      "Epoch: 4/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.38s/it, F1=0.715, train_acc=0.87, train_loss=5.79, train_precision=0.715, train_recall=0.716] \n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.24it/s, F1=0.639, eval_acc=0.832, eval_loss=7.2, eval_precision=0.647, eval_recall=0.635] \n",
      "Epoch: 5/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.739, train_acc=0.884, train_loss=5.02, train_precision=0.737, train_recall=0.741]\n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.37it/s, F1=0.642, eval_acc=0.837, eval_loss=7.29, eval_precision=0.65, eval_recall=0.637] \n",
      "Epoch: 6/30 Train: 100%|██████████| 235/235 [05:08<00:00,  1.31s/it, F1=0.758, train_acc=0.893, train_loss=4.51, train_precision=0.756, train_recall=0.761]\n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.36it/s, F1=0.648, eval_acc=0.841, eval_loss=7.38, eval_precision=0.653, eval_recall=0.646]\n",
      "Epoch: 7/30 Train: 100%|██████████| 235/235 [05:22<00:00,  1.37s/it, F1=0.781, train_acc=0.905, train_loss=4.08, train_precision=0.778, train_recall=0.785]\n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, F1=0.635, eval_acc=0.829, eval_loss=7.67, eval_precision=0.634, eval_recall=0.64] \n",
      "Epoch: 8/30 Train: 100%|██████████| 235/235 [05:18<00:00,  1.35s/it, F1=0.801, train_acc=0.915, train_loss=3.71, train_precision=0.797, train_recall=0.806]\n",
      "Eval Result: 100%|██████████| 79/79 [01:06<00:00,  1.19it/s, F1=0.633, eval_acc=0.828, eval_loss=7.66, eval_precision=0.623, eval_recall=0.646]\n",
      "Epoch: 9/30 Train: 100%|██████████| 235/235 [05:14<00:00,  1.34s/it, F1=0.817, train_acc=0.921, train_loss=3.5, train_precision=0.812, train_recall=0.823] \n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.38it/s, F1=0.626, eval_acc=0.824, eval_loss=8.02, eval_precision=0.629, eval_recall=0.627]\n",
      "Epoch: 10/30 Train: 100%|██████████| 235/235 [05:05<00:00,  1.30s/it, F1=0.84, train_acc=0.933, train_loss=3.09, train_precision=0.835, train_recall=0.845] \n",
      "Eval Result: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, F1=0.612, eval_acc=0.81, eval_loss=8.73, eval_precision=0.596, eval_recall=0.631] \n",
      "Epoch: 11/30 Train: 100%|██████████| 235/235 [04:38<00:00,  1.18s/it, F1=0.849, train_acc=0.936, train_loss=2.95, train_precision=0.845, train_recall=0.853]\n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.24it/s, F1=0.612, eval_acc=0.813, eval_loss=9.08, eval_precision=0.593, eval_recall=0.635]\n",
      "Epoch: 12/30 Train: 100%|██████████| 235/235 [05:19<00:00,  1.36s/it, F1=0.862, train_acc=0.942, train_loss=2.74, train_precision=0.859, train_recall=0.867]\n",
      "Eval Result: 100%|██████████| 79/79 [01:05<00:00,  1.20it/s, F1=0.627, eval_acc=0.827, eval_loss=9.07, eval_precision=0.614, eval_recall=0.642]\n",
      "Epoch: 13/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.38s/it, F1=0.875, train_acc=0.949, train_loss=2.52, train_precision=0.871, train_recall=0.879]\n",
      "Eval Result: 100%|██████████| 79/79 [01:01<00:00,  1.29it/s, F1=0.635, eval_acc=0.831, eval_loss=9.65, eval_precision=0.618, eval_recall=0.655]\n",
      "Epoch: 14/30 Train: 100%|██████████| 235/235 [05:28<00:00,  1.40s/it, F1=0.885, train_acc=0.953, train_loss=2.35, train_precision=0.881, train_recall=0.89] \n",
      "Eval Result: 100%|██████████| 79/79 [00:57<00:00,  1.37it/s, F1=0.637, eval_acc=0.837, eval_loss=9.96, eval_precision=0.625, eval_recall=0.653]\n",
      "Epoch: 15/30 Train: 100%|██████████| 235/235 [05:25<00:00,  1.39s/it, F1=0.896, train_acc=0.958, train_loss=2.18, train_precision=0.892, train_recall=0.9]  \n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.25it/s, F1=0.634, eval_acc=0.831, eval_loss=9.87, eval_precision=0.621, eval_recall=0.65] \n",
      "Epoch: 16/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.907, train_acc=0.963, train_loss=2, train_precision=0.904, train_recall=0.911]   \n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.25it/s, F1=0.629, eval_acc=0.832, eval_loss=10.1, eval_precision=0.616, eval_recall=0.646]\n",
      "Epoch: 17/30 Train: 100%|██████████| 235/235 [05:14<00:00,  1.34s/it, F1=0.911, train_acc=0.966, train_loss=1.91, train_precision=0.908, train_recall=0.914]\n",
      "Eval Result: 100%|██████████| 79/79 [01:04<00:00,  1.23it/s, F1=0.633, eval_acc=0.831, eval_loss=10.7, eval_precision=0.615, eval_recall=0.653]\n",
      "Epoch: 18/30 Train: 100%|██████████| 235/235 [05:27<00:00,  1.39s/it, F1=0.918, train_acc=0.968, train_loss=1.8, train_precision=0.915, train_recall=0.921] \n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.24it/s, F1=0.639, eval_acc=0.838, eval_loss=11.2, eval_precision=0.63, eval_recall=0.649] \n",
      "Epoch: 19/30 Train: 100%|██████████| 235/235 [05:20<00:00,  1.36s/it, F1=0.926, train_acc=0.972, train_loss=1.69, train_precision=0.923, train_recall=0.929]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.26it/s, F1=0.63, eval_acc=0.835, eval_loss=12, eval_precision=0.64, eval_recall=0.623]    \n",
      "Epoch: 20/30 Train: 100%|██████████| 235/235 [05:29<00:00,  1.40s/it, F1=0.932, train_acc=0.974, train_loss=1.54, train_precision=0.929, train_recall=0.935]\n",
      "Eval Result: 100%|██████████| 79/79 [00:49<00:00,  1.60it/s, F1=0.632, eval_acc=0.836, eval_loss=13.3, eval_precision=0.638, eval_recall=0.628]\n",
      "Epoch: 21/30 Train: 100%|██████████| 235/235 [05:34<00:00,  1.42s/it, F1=0.938, train_acc=0.976, train_loss=1.44, train_precision=0.936, train_recall=0.941]\n",
      "Eval Result: 100%|██████████| 79/79 [01:03<00:00,  1.25it/s, F1=0.619, eval_acc=0.828, eval_loss=14.8, eval_precision=0.647, eval_recall=0.596]\n",
      "Epoch: 22/30 Train: 100%|██████████| 235/235 [05:28<00:00,  1.40s/it, F1=0.938, train_acc=0.976, train_loss=1.44, train_precision=0.936, train_recall=0.941]\n",
      "Eval Result: 100%|██████████| 79/79 [01:06<00:00,  1.19it/s, F1=0.621, eval_acc=0.831, eval_loss=14.4, eval_precision=0.639, eval_recall=0.606]\n",
      "Epoch: 23/30 Train: 100%|██████████| 235/235 [05:00<00:00,  1.28s/it, F1=0.945, train_acc=0.979, train_loss=1.33, train_precision=0.943, train_recall=0.947]\n",
      "Eval Result: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s, F1=0.622, eval_acc=0.829, eval_loss=14.2, eval_precision=0.624, eval_recall=0.623]\n",
      "Epoch: 24/30 Train: 100%|██████████| 235/235 [05:23<00:00,  1.38s/it, F1=0.946, train_acc=0.979, train_loss=1.33, train_precision=0.944, train_recall=0.948]\n",
      "Eval Result: 100%|██████████| 79/79 [00:58<00:00,  1.35it/s, F1=0.62, eval_acc=0.827, eval_loss=14.4, eval_precision=0.618, eval_recall=0.624] \n",
      "Epoch: 25/30 Train: 100%|██████████| 235/235 [05:17<00:00,  1.35s/it, F1=0.951, train_acc=0.982, train_loss=1.23, train_precision=0.949, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 79/79 [01:12<00:00,  1.09it/s, F1=0.626, eval_acc=0.831, eval_loss=14.3, eval_precision=0.622, eval_recall=0.633]\n",
      "Epoch: 26/30 Train: 100%|██████████| 235/235 [05:22<00:00,  1.37s/it, F1=0.951, train_acc=0.982, train_loss=1.18, train_precision=0.95, train_recall=0.952] \n",
      "Eval Result: 100%|██████████| 79/79 [00:55<00:00,  1.43it/s, F1=0.621, eval_acc=0.826, eval_loss=15.2, eval_precision=0.614, eval_recall=0.63] \n",
      "Epoch: 27/30 Train: 100%|██████████| 235/235 [05:21<00:00,  1.37s/it, F1=0.955, train_acc=0.983, train_loss=1.11, train_precision=0.953, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 79/79 [00:59<00:00,  1.32it/s, F1=0.637, eval_acc=0.834, eval_loss=14.2, eval_precision=0.626, eval_recall=0.651]\n",
      "Epoch: 28/30 Train: 100%|██████████| 235/235 [05:02<00:00,  1.29s/it, F1=0.956, train_acc=0.983, train_loss=1.1, train_precision=0.956, train_recall=0.957] \n",
      "Eval Result: 100%|██████████| 79/79 [01:11<00:00,  1.10it/s, F1=0.625, eval_acc=0.826, eval_loss=14.5, eval_precision=0.612, eval_recall=0.641]\n",
      "Epoch: 29/30 Train: 100%|██████████| 235/235 [05:15<00:00,  1.34s/it, F1=0.962, train_acc=0.986, train_loss=1, train_precision=0.961, train_recall=0.963]   \n",
      "Eval Result: 100%|██████████| 79/79 [00:52<00:00,  1.51it/s, F1=0.604, eval_acc=0.814, eval_loss=15.3, eval_precision=0.606, eval_recall=0.604]\n",
      "Epoch: 30/30 Train: 100%|██████████| 235/235 [05:09<00:00,  1.32s/it, F1=0.962, train_acc=0.986, train_loss=0.986, train_precision=0.961, train_recall=0.964]\n",
      "Eval Result: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, F1=0.621, eval_acc=0.828, eval_loss=16.2, eval_precision=0.622, eval_recall=0.623]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'chip_tx_5'\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_tx_1\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 321MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 329MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 346MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 54.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 17050.02L/s]\n",
      "build line mapper: 4L [00:00, 14652.59L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 504.11it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 12735.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:14<00:00, 387.79it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:02<00:00, 415.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [03:26<00:00,  1.69it/s, F1=0.363, train_acc=0.936, train_loss=12.3, train_precision=0.386, train_recall=0.366]       \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s, F1=0.578, eval_acc=0.938, eval_loss=6.99, eval_precision=0.657, eval_recall=0.52] \n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.646, train_acc=0.954, train_loss=3.86, train_precision=0.702, train_recall=0.619]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.604, eval_acc=0.941, eval_loss=5.24, eval_precision=0.71, eval_recall=0.529] \n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [03:34<00:00,  1.62it/s, F1=0.717, train_acc=0.964, train_loss=2.56, train_precision=0.748, train_recall=0.702]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.44it/s, F1=0.603, eval_acc=0.941, eval_loss=5.21, eval_precision=0.69, eval_recall=0.539] \n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.759, train_acc=0.97, train_loss=2.07, train_precision=0.782, train_recall=0.749] \n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, F1=0.604, eval_acc=0.937, eval_loss=5.12, eval_precision=0.671, eval_recall=0.552]\n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.55it/s, F1=0.793, train_acc=0.974, train_loss=1.81, train_precision=0.812, train_recall=0.785]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.602, eval_acc=0.933, eval_loss=6.3, eval_precision=0.675, eval_recall=0.546] \n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.56it/s, F1=0.818, train_acc=0.978, train_loss=1.55, train_precision=0.831, train_recall=0.813]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, F1=0.587, eval_acc=0.938, eval_loss=7.15, eval_precision=0.696, eval_recall=0.511]\n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:41<00:00,  1.58it/s, F1=0.84, train_acc=0.981, train_loss=1.4, train_precision=0.847, train_recall=0.839]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.567, eval_acc=0.936, eval_loss=10, eval_precision=0.759, eval_recall=0.454]  \n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [03:48<00:00,  1.53it/s, F1=0.858, train_acc=0.983, train_loss=1.27, train_precision=0.865, train_recall=0.858]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, F1=0.611, eval_acc=0.941, eval_loss=6.69, eval_precision=0.696, eval_recall=0.548]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.55it/s, F1=0.872, train_acc=0.985, train_loss=1.16, train_precision=0.876, train_recall=0.873]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.598, eval_acc=0.94, eval_loss=7.5, eval_precision=0.733, eval_recall=0.508]  \n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [03:50<00:00,  1.51it/s, F1=0.884, train_acc=0.986, train_loss=1.03, train_precision=0.889, train_recall=0.885]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.585, eval_acc=0.933, eval_loss=7.08, eval_precision=0.667, eval_recall=0.524]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [03:16<00:00,  1.78it/s, F1=0.888, train_acc=0.987, train_loss=0.981, train_precision=0.893, train_recall=0.888]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.585, eval_acc=0.931, eval_loss=7.43, eval_precision=0.648, eval_recall=0.536]\n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.904, train_acc=0.989, train_loss=0.827, train_precision=0.906, train_recall=0.906]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, F1=0.591, eval_acc=0.934, eval_loss=8.23, eval_precision=0.628, eval_recall=0.56] \n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.912, train_acc=0.99, train_loss=0.787, train_precision=0.914, train_recall=0.914] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s, F1=0.605, eval_acc=0.938, eval_loss=8.09, eval_precision=0.68, eval_recall=0.547] \n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.55it/s, F1=0.916, train_acc=0.99, train_loss=0.759, train_precision=0.918, train_recall=0.916] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, F1=0.598, eval_acc=0.942, eval_loss=10.9, eval_precision=0.732, eval_recall=0.508]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.928, train_acc=0.992, train_loss=0.659, train_precision=0.926, train_recall=0.932]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.596, eval_acc=0.939, eval_loss=11.7, eval_precision=0.72, eval_recall=0.511] \n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.931, train_acc=0.992, train_loss=0.643, train_precision=0.931, train_recall=0.934]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s, F1=0.581, eval_acc=0.937, eval_loss=9.04, eval_precision=0.686, eval_recall=0.508]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [03:41<00:00,  1.58it/s, F1=0.936, train_acc=0.993, train_loss=0.59, train_precision=0.937, train_recall=0.937] \n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, F1=0.589, eval_acc=0.938, eval_loss=11.8, eval_precision=0.689, eval_recall=0.518]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [03:33<00:00,  1.63it/s, F1=0.935, train_acc=0.992, train_loss=0.595, train_precision=0.937, train_recall=0.937]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.597, eval_acc=0.939, eval_loss=12.7, eval_precision=0.703, eval_recall=0.522]\n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.936, train_acc=0.992, train_loss=0.574, train_precision=0.936, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.29it/s, F1=0.599, eval_acc=0.941, eval_loss=12.7, eval_precision=0.725, eval_recall=0.513]\n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:01<00:00,  1.92it/s, F1=0.939, train_acc=0.993, train_loss=0.537, train_precision=0.942, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.44it/s, F1=0.582, eval_acc=0.937, eval_loss=12.7, eval_precision=0.725, eval_recall=0.489]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.21it/s, F1=0.948, train_acc=0.994, train_loss=0.474, train_precision=0.95, train_recall=0.948] \n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.43it/s, F1=0.598, eval_acc=0.938, eval_loss=11.4, eval_precision=0.7, eval_recall=0.525]  \n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [03:09<00:00,  1.84it/s, F1=0.952, train_acc=0.995, train_loss=0.425, train_precision=0.953, train_recall=0.952]\n",
      "Eval Result: 100%|██████████| 15/15 [00:11<00:00,  1.25it/s, F1=0.602, eval_acc=0.939, eval_loss=11.8, eval_precision=0.689, eval_recall=0.537]\n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [03:06<00:00,  1.87it/s, F1=0.952, train_acc=0.995, train_loss=0.439, train_precision=0.953, train_recall=0.952]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.586, eval_acc=0.937, eval_loss=13.7, eval_precision=0.74, eval_recall=0.487] \n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:47<00:00,  1.53it/s, F1=0.951, train_acc=0.994, train_loss=0.44, train_precision=0.953, train_recall=0.95]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.596, eval_acc=0.94, eval_loss=13, eval_precision=0.731, eval_recall=0.505]   \n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.948, train_acc=0.994, train_loss=0.462, train_precision=0.95, train_recall=0.947] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.591, eval_acc=0.939, eval_loss=11.1, eval_precision=0.735, eval_recall=0.496]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:57<00:00,  1.47it/s, F1=0.956, train_acc=0.995, train_loss=0.399, train_precision=0.957, train_recall=0.956]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, F1=0.577, eval_acc=0.938, eval_loss=16.2, eval_precision=0.738, eval_recall=0.476]\n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.952, train_acc=0.994, train_loss=0.448, train_precision=0.954, train_recall=0.951]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.572, eval_acc=0.937, eval_loss=16.8, eval_precision=0.749, eval_recall=0.465]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.954, train_acc=0.994, train_loss=0.43, train_precision=0.956, train_recall=0.953] \n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, F1=0.602, eval_acc=0.941, eval_loss=12.6, eval_precision=0.693, eval_recall=0.535]\n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [04:03<00:00,  1.43it/s, F1=0.953, train_acc=0.994, train_loss=0.438, train_precision=0.956, train_recall=0.951]\n",
      "Eval Result: 100%|██████████| 15/15 [00:15<00:00,  1.02s/it, F1=0.612, eval_acc=0.941, eval_loss=11.9, eval_precision=0.7, eval_recall=0.546]  \n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.956, train_acc=0.995, train_loss=0.38, train_precision=0.959, train_recall=0.956] \n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.02it/s, F1=0.608, eval_acc=0.941, eval_loss=13.3, eval_precision=0.702, eval_recall=0.54] \n"
     ]
    }
   ],
   "source": [
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 150,\n",
    "    'max_scan_num': 1000000,\n",
    "    # 'inter_max_scan_num': 3000,\n",
    "    'train_file': './data/CDD/train.json',\n",
    "    'eval_file': './data/CDD/dev.json',\n",
    "    'test_file': './data/CDD/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    # 'loader_name': 'le_loader_zl',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/tencent_medicine_vocab.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'task_name': 'cdd_tx_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_tx_2\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 289MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 281MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 246MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 54.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 8101.02L/s]\n",
      "build line mapper: 4L [00:00, 8572.93L/s]/4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 491.60it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 21998.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:13<00:00, 407.21it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:02<00:00, 418.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.156, train_acc=0.908, train_loss=25.9, train_precision=0.131, train_recall=0.207]        \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.528, eval_acc=0.933, eval_loss=10.1, eval_precision=0.493, eval_recall=0.57] \n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [03:57<00:00,  1.47it/s, F1=0.606, train_acc=0.952, train_loss=5.57, train_precision=0.634, train_recall=0.601]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.586, eval_acc=0.936, eval_loss=6.37, eval_precision=0.619, eval_recall=0.56] \n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.688, train_acc=0.961, train_loss=3.11, train_precision=0.714, train_recall=0.678]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.603, eval_acc=0.94, eval_loss=5.65, eval_precision=0.69, eval_recall=0.538]  \n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.55it/s, F1=0.726, train_acc=0.966, train_loss=2.37, train_precision=0.75, train_recall=0.717] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.57it/s, F1=0.609, eval_acc=0.939, eval_loss=6.5, eval_precision=0.708, eval_recall=0.538] \n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [04:05<00:00,  1.42it/s, F1=0.746, train_acc=0.969, train_loss=2.09, train_precision=0.764, train_recall=0.742]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.566, eval_acc=0.934, eval_loss=8.14, eval_precision=0.748, eval_recall=0.458]\n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [03:45<00:00,  1.55it/s, F1=0.77, train_acc=0.971, train_loss=1.88, train_precision=0.786, train_recall=0.772] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.57, eval_acc=0.936, eval_loss=8.84, eval_precision=0.737, eval_recall=0.467] \n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:53<00:00,  1.50it/s, F1=0.803, train_acc=0.975, train_loss=1.6, train_precision=0.815, train_recall=0.802] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.602, eval_acc=0.939, eval_loss=6.64, eval_precision=0.679, eval_recall=0.543]\n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [03:54<00:00,  1.49it/s, F1=0.824, train_acc=0.979, train_loss=1.38, train_precision=0.832, train_recall=0.827]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.578, eval_acc=0.936, eval_loss=8.49, eval_precision=0.738, eval_recall=0.478]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.838, train_acc=0.98, train_loss=1.27, train_precision=0.846, train_recall=0.839] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s, F1=0.603, eval_acc=0.941, eval_loss=8.55, eval_precision=0.68, eval_recall=0.544] \n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [03:17<00:00,  1.77it/s, F1=0.85, train_acc=0.981, train_loss=1.2, train_precision=0.857, train_recall=0.853]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.601, eval_acc=0.941, eval_loss=7.93, eval_precision=0.701, eval_recall=0.528]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.872, train_acc=0.985, train_loss=0.966, train_precision=0.876, train_recall=0.874]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.603, eval_acc=0.94, eval_loss=7.78, eval_precision=0.673, eval_recall=0.549] \n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [03:56<00:00,  1.48it/s, F1=0.892, train_acc=0.987, train_loss=0.893, train_precision=0.895, train_recall=0.895]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, F1=0.569, eval_acc=0.937, eval_loss=10.3, eval_precision=0.722, eval_recall=0.471]\n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [03:55<00:00,  1.48it/s, F1=0.892, train_acc=0.987, train_loss=0.903, train_precision=0.897, train_recall=0.894]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, F1=0.574, eval_acc=0.936, eval_loss=9.37, eval_precision=0.738, eval_recall=0.471]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [03:32<00:00,  1.64it/s, F1=0.901, train_acc=0.988, train_loss=0.798, train_precision=0.904, train_recall=0.902]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.606, eval_acc=0.941, eval_loss=9.18, eval_precision=0.713, eval_recall=0.529]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [03:57<00:00,  1.47it/s, F1=0.911, train_acc=0.99, train_loss=0.693, train_precision=0.914, train_recall=0.912] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.608, eval_acc=0.939, eval_loss=8.43, eval_precision=0.679, eval_recall=0.552]\n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:53<00:00,  1.49it/s, F1=0.923, train_acc=0.991, train_loss=0.644, train_precision=0.924, train_recall=0.925]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.599, eval_acc=0.936, eval_loss=9.53, eval_precision=0.667, eval_recall=0.546]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.60it/s, F1=0.925, train_acc=0.991, train_loss=0.661, train_precision=0.927, train_recall=0.926]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.602, eval_acc=0.939, eval_loss=9.84, eval_precision=0.666, eval_recall=0.552]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [03:54<00:00,  1.49it/s, F1=0.93, train_acc=0.992, train_loss=0.583, train_precision=0.93, train_recall=0.932]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.6, eval_acc=0.94, eval_loss=9.01, eval_precision=0.687, eval_recall=0.534]   \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:55<00:00,  1.48it/s, F1=0.929, train_acc=0.992, train_loss=0.593, train_precision=0.928, train_recall=0.931]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s, F1=0.603, eval_acc=0.941, eval_loss=8.37, eval_precision=0.693, eval_recall=0.535]\n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.94, train_acc=0.993, train_loss=0.496, train_precision=0.942, train_recall=0.941] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.599, eval_acc=0.938, eval_loss=9.11, eval_precision=0.662, eval_recall=0.551]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [03:57<00:00,  1.47it/s, F1=0.934, train_acc=0.993, train_loss=0.541, train_precision=0.935, train_recall=0.936]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.601, eval_acc=0.938, eval_loss=8.28, eval_precision=0.666, eval_recall=0.55] \n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [03:46<00:00,  1.54it/s, F1=0.942, train_acc=0.993, train_loss=0.487, train_precision=0.943, train_recall=0.944]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.598, eval_acc=0.94, eval_loss=9.61, eval_precision=0.686, eval_recall=0.533] \n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [03:49<00:00,  1.52it/s, F1=0.947, train_acc=0.994, train_loss=0.471, train_precision=0.948, train_recall=0.947]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.601, eval_acc=0.941, eval_loss=10.1, eval_precision=0.707, eval_recall=0.526]\n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:53<00:00,  1.49it/s, F1=0.946, train_acc=0.994, train_loss=0.474, train_precision=0.947, train_recall=0.946]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.603, eval_acc=0.941, eval_loss=10.6, eval_precision=0.72, eval_recall=0.521] \n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.944, train_acc=0.994, train_loss=0.533, train_precision=0.944, train_recall=0.946]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.597, eval_acc=0.941, eval_loss=10.8, eval_precision=0.705, eval_recall=0.52] \n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:56<00:00,  1.48it/s, F1=0.944, train_acc=0.994, train_loss=0.487, train_precision=0.944, train_recall=0.946]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.6, eval_acc=0.941, eval_loss=11.5, eval_precision=0.691, eval_recall=0.533]  \n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [03:58<00:00,  1.46it/s, F1=0.945, train_acc=0.993, train_loss=0.514, train_precision=0.947, train_recall=0.947]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.594, eval_acc=0.94, eval_loss=12.5, eval_precision=0.698, eval_recall=0.519] \n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [03:37<00:00,  1.60it/s, F1=0.949, train_acc=0.994, train_loss=0.442, train_precision=0.95, train_recall=0.949] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.599, eval_acc=0.94, eval_loss=11.5, eval_precision=0.708, eval_recall=0.522] \n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [03:57<00:00,  1.47it/s, F1=0.957, train_acc=0.995, train_loss=0.352, train_precision=0.957, train_recall=0.96] \n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, F1=0.587, eval_acc=0.939, eval_loss=10.5, eval_precision=0.696, eval_recall=0.509]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [04:01<00:00,  1.44it/s, F1=0.96, train_acc=0.995, train_loss=0.33, train_precision=0.96, train_recall=0.96]    \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.59, eval_acc=0.941, eval_loss=9.3, eval_precision=0.712, eval_recall=0.507]  \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_tx_2'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_tx_3\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 208MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 232MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 243MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 57.9kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 11898.73L/s]\n",
      "build line mapper: 4L [00:00, 36711.63L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 1206.82it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 47482.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:05<00:00, 948.53it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:00<00:00, 967.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [03:52<00:00,  1.50it/s, F1=0.455, train_acc=0.938, train_loss=7.28, train_precision=0.529, train_recall=0.425]     \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.521, eval_acc=0.93, eval_loss=6.07, eval_precision=0.73, eval_recall=0.407]  \n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [03:51<00:00,  1.51it/s, F1=0.664, train_acc=0.957, train_loss=3.02, train_precision=0.715, train_recall=0.638]\n",
      "Eval Result: 100%|██████████| 15/15 [00:15<00:00,  1.02s/it, F1=0.552, eval_acc=0.933, eval_loss=5.46, eval_precision=0.739, eval_recall=0.442]\n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [03:44<00:00,  1.56it/s, F1=0.732, train_acc=0.966, train_loss=2.27, train_precision=0.766, train_recall=0.713]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.557, eval_acc=0.933, eval_loss=5.98, eval_precision=0.765, eval_recall=0.44] \n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [04:04<00:00,  1.42it/s, F1=0.777, train_acc=0.971, train_loss=1.93, train_precision=0.8, train_recall=0.766]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.583, eval_acc=0.939, eval_loss=5.48, eval_precision=0.719, eval_recall=0.492]\n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [03:51<00:00,  1.51it/s, F1=0.817, train_acc=0.977, train_loss=1.62, train_precision=0.832, train_recall=0.811]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, F1=0.595, eval_acc=0.938, eval_loss=5.84, eval_precision=0.733, eval_recall=0.503]\n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [03:36<00:00,  1.61it/s, F1=0.835, train_acc=0.98, train_loss=1.49, train_precision=0.849, train_recall=0.83]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, F1=0.529, eval_acc=0.93, eval_loss=6.84, eval_precision=0.748, eval_recall=0.411] \n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:57<00:00,  1.47it/s, F1=0.846, train_acc=0.981, train_loss=1.36, train_precision=0.854, train_recall=0.844]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.587, eval_acc=0.938, eval_loss=7, eval_precision=0.742, eval_recall=0.488]   \n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [04:09<00:00,  1.40it/s, F1=0.856, train_acc=0.982, train_loss=1.26, train_precision=0.865, train_recall=0.856]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.577, eval_acc=0.938, eval_loss=7.64, eval_precision=0.738, eval_recall=0.475]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:18<00:00,  1.76it/s, F1=0.876, train_acc=0.985, train_loss=1.14, train_precision=0.883, train_recall=0.876]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s, F1=0.581, eval_acc=0.938, eval_loss=7.08, eval_precision=0.732, eval_recall=0.483]\n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.888, train_acc=0.986, train_loss=1.04, train_precision=0.895, train_recall=0.886]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.42it/s, F1=0.595, eval_acc=0.94, eval_loss=7.2, eval_precision=0.711, eval_recall=0.515]  \n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [02:38<00:00,  2.21it/s, F1=0.902, train_acc=0.989, train_loss=0.895, train_precision=0.904, train_recall=0.904]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.53it/s, F1=0.577, eval_acc=0.939, eval_loss=7.55, eval_precision=0.743, eval_recall=0.474]\n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [03:14<00:00,  1.79it/s, F1=0.921, train_acc=0.991, train_loss=0.749, train_precision=0.925, train_recall=0.919]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.63it/s, F1=0.594, eval_acc=0.938, eval_loss=7.26, eval_precision=0.716, eval_recall=0.51] \n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.935, train_acc=0.992, train_loss=0.675, train_precision=0.937, train_recall=0.934]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.598, eval_acc=0.94, eval_loss=8.68, eval_precision=0.726, eval_recall=0.511] \n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [03:00<00:00,  1.93it/s, F1=0.925, train_acc=0.992, train_loss=0.696, train_precision=0.928, train_recall=0.924]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s, F1=0.571, eval_acc=0.937, eval_loss=7.82, eval_precision=0.694, eval_recall=0.487]\n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [03:13<00:00,  1.80it/s, F1=0.929, train_acc=0.992, train_loss=0.675, train_precision=0.929, train_recall=0.93] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.598, eval_acc=0.94, eval_loss=7.29, eval_precision=0.698, eval_recall=0.526] \n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.938, train_acc=0.993, train_loss=0.594, train_precision=0.939, train_recall=0.94] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.09it/s, F1=0.582, eval_acc=0.939, eval_loss=8.22, eval_precision=0.702, eval_recall=0.499]\n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [03:48<00:00,  1.52it/s, F1=0.942, train_acc=0.993, train_loss=0.566, train_precision=0.944, train_recall=0.942]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.00it/s, F1=0.588, eval_acc=0.937, eval_loss=7.98, eval_precision=0.715, eval_recall=0.502]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [03:36<00:00,  1.61it/s, F1=0.942, train_acc=0.994, train_loss=0.514, train_precision=0.941, train_recall=0.945]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.584, eval_acc=0.938, eval_loss=9.32, eval_precision=0.73, eval_recall=0.489] \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:43<00:00,  1.56it/s, F1=0.95, train_acc=0.994, train_loss=0.461, train_precision=0.952, train_recall=0.95]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.588, eval_acc=0.938, eval_loss=8.98, eval_precision=0.716, eval_recall=0.502]\n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:49<00:00,  1.52it/s, F1=0.948, train_acc=0.994, train_loss=0.483, train_precision=0.948, train_recall=0.948]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, F1=0.598, eval_acc=0.941, eval_loss=10.1, eval_precision=0.724, eval_recall=0.511]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [03:33<00:00,  1.63it/s, F1=0.951, train_acc=0.994, train_loss=0.457, train_precision=0.952, train_recall=0.952]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, F1=0.584, eval_acc=0.939, eval_loss=9.65, eval_precision=0.718, eval_recall=0.495]\n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [03:48<00:00,  1.53it/s, F1=0.954, train_acc=0.995, train_loss=0.404, train_precision=0.956, train_recall=0.955]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, F1=0.592, eval_acc=0.94, eval_loss=9.45, eval_precision=0.684, eval_recall=0.523]\n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [03:29<00:00,  1.66it/s, F1=0.956, train_acc=0.995, train_loss=0.458, train_precision=0.959, train_recall=0.954]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s, F1=0.59, eval_acc=0.939, eval_loss=9.52, eval_precision=0.707, eval_recall=0.508] \n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [03:24<00:00,  1.70it/s, F1=0.949, train_acc=0.994, train_loss=0.451, train_precision=0.951, train_recall=0.949]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, F1=0.598, eval_acc=0.938, eval_loss=8.85, eval_precision=0.676, eval_recall=0.538]\n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.96, train_acc=0.995, train_loss=0.405, train_precision=0.962, train_recall=0.959] \n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, F1=0.597, eval_acc=0.94, eval_loss=9.97, eval_precision=0.703, eval_recall=0.521] \n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.957, train_acc=0.995, train_loss=0.396, train_precision=0.958, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 15/15 [00:15<00:00,  1.01s/it, F1=0.595, eval_acc=0.94, eval_loss=11.2, eval_precision=0.717, eval_recall=0.51]  \n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.954, train_acc=0.994, train_loss=0.437, train_precision=0.956, train_recall=0.954]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s, F1=0.587, eval_acc=0.938, eval_loss=11.1, eval_precision=0.748, eval_recall=0.485]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.957, train_acc=0.995, train_loss=0.392, train_precision=0.96, train_recall=0.956] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s, F1=0.585, eval_acc=0.939, eval_loss=11.6, eval_precision=0.724, eval_recall=0.493]\n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [03:31<00:00,  1.65it/s, F1=0.961, train_acc=0.995, train_loss=0.334, train_precision=0.962, train_recall=0.961]\n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, F1=0.59, eval_acc=0.938, eval_loss=12.5, eval_precision=0.72, eval_recall=0.503]  \n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [03:07<00:00,  1.86it/s, F1=0.966, train_acc=0.996, train_loss=0.294, train_precision=0.967, train_recall=0.967]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.69it/s, F1=0.6, eval_acc=0.94, eval_loss=12.4, eval_precision=0.739, eval_recall=0.508]   \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_tx_3'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_tx_4\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 352MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 325MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 357MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 53.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 9805.50L/s]\n",
      "build line mapper: 4L [00:00, 35172.36L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 1192.07it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 44938.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:06<00:00, 872.65it/s]\n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:00<00:00, 946.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [02:57<00:00,  1.97it/s, F1=0.33, train_acc=0.922, train_loss=13.4, train_precision=0.351, train_recall=0.334]       \n",
      "Eval Result: 100%|██████████| 15/15 [00:14<00:00,  1.02it/s, F1=0.557, eval_acc=0.937, eval_loss=6.86, eval_precision=0.629, eval_recall=0.503]\n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [04:00<00:00,  1.45it/s, F1=0.637, train_acc=0.952, train_loss=3.94, train_precision=0.69, train_recall=0.616] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.603, eval_acc=0.938, eval_loss=5.87, eval_precision=0.633, eval_recall=0.579]\n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [04:00<00:00,  1.45it/s, F1=0.706, train_acc=0.961, train_loss=2.72, train_precision=0.746, train_recall=0.692]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.611, eval_acc=0.939, eval_loss=5.73, eval_precision=0.668, eval_recall=0.565]\n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [03:35<00:00,  1.62it/s, F1=0.75, train_acc=0.966, train_loss=2.14, train_precision=0.779, train_recall=0.74]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.09it/s, F1=0.608, eval_acc=0.94, eval_loss=6.07, eval_precision=0.713, eval_recall=0.533] \n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [03:57<00:00,  1.47it/s, F1=0.787, train_acc=0.972, train_loss=1.79, train_precision=0.806, train_recall=0.783]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.601, eval_acc=0.94, eval_loss=6.97, eval_precision=0.724, eval_recall=0.517] \n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [03:56<00:00,  1.48it/s, F1=0.827, train_acc=0.978, train_loss=1.47, train_precision=0.834, train_recall=0.828]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.569, eval_acc=0.934, eval_loss=7.21, eval_precision=0.76, eval_recall=0.457] \n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [03:42<00:00,  1.57it/s, F1=0.846, train_acc=0.981, train_loss=1.32, train_precision=0.852, train_recall=0.846]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.14it/s, F1=0.572, eval_acc=0.932, eval_loss=8.89, eval_precision=0.768, eval_recall=0.458]\n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [03:59<00:00,  1.46it/s, F1=0.864, train_acc=0.983, train_loss=1.21, train_precision=0.87, train_recall=0.863] \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.563, eval_acc=0.934, eval_loss=8.06, eval_precision=0.738, eval_recall=0.456]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [03:54<00:00,  1.49it/s, F1=0.884, train_acc=0.986, train_loss=1.06, train_precision=0.887, train_recall=0.886]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.594, eval_acc=0.94, eval_loss=8.38, eval_precision=0.684, eval_recall=0.526] \n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [03:32<00:00,  1.64it/s, F1=0.883, train_acc=0.985, train_loss=1.07, train_precision=0.892, train_recall=0.881]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s, F1=0.609, eval_acc=0.939, eval_loss=9.05, eval_precision=0.66, eval_recall=0.569] \n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [03:55<00:00,  1.48it/s, F1=0.902, train_acc=0.987, train_loss=0.9, train_precision=0.904, train_recall=0.904]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.17it/s, F1=0.605, eval_acc=0.936, eval_loss=8.46, eval_precision=0.635, eval_recall=0.582]\n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [04:00<00:00,  1.45it/s, F1=0.911, train_acc=0.989, train_loss=0.841, train_precision=0.913, train_recall=0.913]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.15it/s, F1=0.594, eval_acc=0.937, eval_loss=8.77, eval_precision=0.633, eval_recall=0.562]\n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [03:38<00:00,  1.60it/s, F1=0.908, train_acc=0.988, train_loss=0.861, train_precision=0.913, train_recall=0.908]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s, F1=0.604, eval_acc=0.941, eval_loss=8.99, eval_precision=0.697, eval_recall=0.535]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [03:58<00:00,  1.46it/s, F1=0.921, train_acc=0.989, train_loss=0.771, train_precision=0.923, train_recall=0.922]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.18it/s, F1=0.593, eval_acc=0.94, eval_loss=9.75, eval_precision=0.735, eval_recall=0.499] \n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [04:00<00:00,  1.45it/s, F1=0.925, train_acc=0.991, train_loss=0.658, train_precision=0.928, train_recall=0.925]\n",
      "Eval Result: 100%|██████████| 15/15 [00:15<00:00,  1.05s/it, F1=0.605, eval_acc=0.945, eval_loss=9.81, eval_precision=0.724, eval_recall=0.522]\n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [03:39<00:00,  1.59it/s, F1=0.939, train_acc=0.993, train_loss=0.595, train_precision=0.939, train_recall=0.94] \n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.13it/s, F1=0.611, eval_acc=0.94, eval_loss=9.43, eval_precision=0.69, eval_recall=0.552]  \n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [03:51<00:00,  1.50it/s, F1=0.946, train_acc=0.993, train_loss=0.523, train_precision=0.946, train_recall=0.947]\n",
      "Eval Result: 100%|██████████| 15/15 [00:16<00:00,  1.07s/it, F1=0.588, eval_acc=0.94, eval_loss=11.9, eval_precision=0.715, eval_recall=0.502] \n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [03:52<00:00,  1.50it/s, F1=0.951, train_acc=0.994, train_loss=0.467, train_precision=0.951, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s, F1=0.593, eval_acc=0.941, eval_loss=12.5, eval_precision=0.71, eval_recall=0.512] \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [03:40<00:00,  1.58it/s, F1=0.952, train_acc=0.994, train_loss=0.456, train_precision=0.953, train_recall=0.952]\n",
      "Eval Result: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s, F1=0.601, eval_acc=0.94, eval_loss=12.7, eval_precision=0.662, eval_recall=0.554] \n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [03:26<00:00,  1.69it/s, F1=0.949, train_acc=0.994, train_loss=0.481, train_precision=0.949, train_recall=0.95] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.596, eval_acc=0.941, eval_loss=13.6, eval_precision=0.712, eval_recall=0.516]\n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [02:35<00:00,  2.24it/s, F1=0.958, train_acc=0.995, train_loss=0.409, train_precision=0.96, train_recall=0.958] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.601, eval_acc=0.941, eval_loss=13.5, eval_precision=0.728, eval_recall=0.514]\n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.958, train_acc=0.995, train_loss=0.387, train_precision=0.959, train_recall=0.958]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.596, eval_acc=0.941, eval_loss=12.6, eval_precision=0.709, eval_recall=0.518]\n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [02:38<00:00,  2.21it/s, F1=0.96, train_acc=0.995, train_loss=0.386, train_precision=0.963, train_recall=0.958] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.586, eval_acc=0.94, eval_loss=15.1, eval_precision=0.729, eval_recall=0.492] \n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [02:45<00:00,  2.11it/s, F1=0.958, train_acc=0.995, train_loss=0.404, train_precision=0.961, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.588, eval_acc=0.938, eval_loss=18.9, eval_precision=0.718, eval_recall=0.501]\n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.958, train_acc=0.995, train_loss=0.4, train_precision=0.958, train_recall=0.959]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.595, eval_acc=0.94, eval_loss=15.6, eval_precision=0.714, eval_recall=0.512] \n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [02:33<00:00,  2.27it/s, F1=0.958, train_acc=0.995, train_loss=0.392, train_precision=0.959, train_recall=0.958]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.44it/s, F1=0.578, eval_acc=0.937, eval_loss=15.1, eval_precision=0.749, eval_recall=0.472]\n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.96, train_acc=0.995, train_loss=0.382, train_precision=0.961, train_recall=0.959] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.594, eval_acc=0.94, eval_loss=14.7, eval_precision=0.726, eval_recall=0.505]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [02:35<00:00,  2.24it/s, F1=0.964, train_acc=0.996, train_loss=0.352, train_precision=0.964, train_recall=0.964]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.584, eval_acc=0.937, eval_loss=19.2, eval_precision=0.749, eval_recall=0.481]\n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [02:35<00:00,  2.24it/s, F1=0.966, train_acc=0.996, train_loss=0.322, train_precision=0.967, train_recall=0.966]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.562, eval_acc=0.937, eval_loss=17.2, eval_precision=0.766, eval_recall=0.445]\n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.18it/s, F1=0.966, train_acc=0.996, train_loss=0.311, train_precision=0.968, train_recall=0.965]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.585, eval_acc=0.939, eval_loss=15.6, eval_precision=0.738, eval_recall=0.486]\n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_tx_4'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CDD/train.json\",\n",
      "    \"eval_file\": \"./data/CDD/dev.json\",\n",
      "    \"test_file\": \"./data/CDD/test.json\",\n",
      "    \"tag_file\": \"data/CDD/cdd_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 150,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"cdd_tx_5\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CDD/train.json etag: 100%|██████████| 6.29M/6.29M [00:00<00:00, 350MB/s]\n",
      "calculate ./data/CDD/dev.json etag: 100%|██████████| 1.00M/1.00M [00:00<00:00, 356MB/s]\n",
      "calculate ./data/CDD/test.json etag: 100%|██████████| 1.09M/1.09M [00:00<00:00, 363MB/s]\n",
      "calculate data/CDD/cdd_tags_list.txt etag: 100%|██████████| 18.0/18.0 [00:00<00:00, 53.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/lexicon_tree\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/matched_words\n",
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/CDD/cdd_tags_list.txt: 4L [00:00, 11001.45L/s]\n",
      "build line mapper: 4L [00:00, 36235.89L/s]4 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 4/4 [00:00<00:00, 1117.29it/s]\n",
      "load vocab from list: 100%|██████████| 3/3 [00:00<00:00, 36261.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/71ed97929533356ed21b571a9fa456ae-2_349f7211c68e3ec4a8d14d462f359739_4bdeb826cacfa5eec1e7ad6c99dabacf_aae8c811d19923238e7599e515cbdb51/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CDD/train.json: 100%|██████████| 5574/5574 [00:05<00:00, 966.42it/s] \n",
      "load dataset from ./data/CDD/dev.json: 100%|██████████| 929/929 [00:00<00:00, 986.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.embeddings.position_ids', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.attn_W', 'bert.encoder.layer.0.fuse_layernorm.bias', 'bert.encoder.layer.0.word_transform.bias', 'word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 349/349 [02:35<00:00,  2.24it/s, F1=0.318, train_acc=0.921, train_loss=13.7, train_precision=0.358, train_recall=0.317]     \n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.44it/s, F1=0.565, eval_acc=0.937, eval_loss=7.27, eval_precision=0.654, eval_recall=0.5]  \n",
      "Epoch: 2/30 Train: 100%|██████████| 349/349 [02:35<00:00,  2.24it/s, F1=0.631, train_acc=0.954, train_loss=3.87, train_precision=0.681, train_recall=0.608]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.591, eval_acc=0.94, eval_loss=5.63, eval_precision=0.697, eval_recall=0.516] \n",
      "Epoch: 3/30 Train: 100%|██████████| 349/349 [02:38<00:00,  2.20it/s, F1=0.701, train_acc=0.962, train_loss=2.65, train_precision=0.741, train_recall=0.685]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.579, eval_acc=0.939, eval_loss=6.1, eval_precision=0.747, eval_recall=0.476] \n",
      "Epoch: 4/30 Train: 100%|██████████| 349/349 [02:35<00:00,  2.24it/s, F1=0.752, train_acc=0.969, train_loss=2.09, train_precision=0.774, train_recall=0.744]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.44it/s, F1=0.595, eval_acc=0.939, eval_loss=6.2, eval_precision=0.7, eval_recall=0.521]   \n",
      "Epoch: 5/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.18it/s, F1=0.784, train_acc=0.974, train_loss=1.75, train_precision=0.8, train_recall=0.779]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.608, eval_acc=0.94, eval_loss=5.91, eval_precision=0.662, eval_recall=0.564] \n",
      "Epoch: 6/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.805, train_acc=0.975, train_loss=1.66, train_precision=0.823, train_recall=0.8]  \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.593, eval_acc=0.942, eval_loss=6.46, eval_precision=0.689, eval_recall=0.522]\n",
      "Epoch: 7/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.821, train_acc=0.977, train_loss=1.47, train_precision=0.838, train_recall=0.817]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.593, eval_acc=0.939, eval_loss=7.3, eval_precision=0.716, eval_recall=0.508] \n",
      "Epoch: 8/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.856, train_acc=0.982, train_loss=1.23, train_precision=0.86, train_recall=0.859] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.577, eval_acc=0.939, eval_loss=7.98, eval_precision=0.742, eval_recall=0.473]\n",
      "Epoch: 9/30 Train: 100%|██████████| 349/349 [02:34<00:00,  2.25it/s, F1=0.874, train_acc=0.985, train_loss=1.09, train_precision=0.879, train_recall=0.876]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.58it/s, F1=0.569, eval_acc=0.939, eval_loss=7.96, eval_precision=0.709, eval_recall=0.476]\n",
      "Epoch: 10/30 Train: 100%|██████████| 349/349 [02:38<00:00,  2.20it/s, F1=0.89, train_acc=0.987, train_loss=0.957, train_precision=0.891, train_recall=0.894] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.582, eval_acc=0.939, eval_loss=7.64, eval_precision=0.727, eval_recall=0.486]\n",
      "Epoch: 11/30 Train: 100%|██████████| 349/349 [02:44<00:00,  2.12it/s, F1=0.89, train_acc=0.987, train_loss=0.954, train_precision=0.892, train_recall=0.893] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.592, eval_acc=0.94, eval_loss=7.77, eval_precision=0.695, eval_recall=0.518] \n",
      "Epoch: 12/30 Train: 100%|██████████| 349/349 [02:34<00:00,  2.26it/s, F1=0.905, train_acc=0.989, train_loss=0.854, train_precision=0.907, train_recall=0.906]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.55it/s, F1=0.575, eval_acc=0.937, eval_loss=9.54, eval_precision=0.723, eval_recall=0.479]\n",
      "Epoch: 13/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.22it/s, F1=0.917, train_acc=0.99, train_loss=0.761, train_precision=0.917, train_recall=0.919] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.568, eval_acc=0.937, eval_loss=9.86, eval_precision=0.731, eval_recall=0.466]\n",
      "Epoch: 14/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.22it/s, F1=0.921, train_acc=0.991, train_loss=0.715, train_precision=0.921, train_recall=0.923]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.56it/s, F1=0.572, eval_acc=0.934, eval_loss=9.61, eval_precision=0.75, eval_recall=0.464] \n",
      "Epoch: 15/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.21it/s, F1=0.924, train_acc=0.991, train_loss=0.656, train_precision=0.927, train_recall=0.925]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.567, eval_acc=0.936, eval_loss=9.16, eval_precision=0.729, eval_recall=0.465]\n",
      "Epoch: 16/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.18it/s, F1=0.934, train_acc=0.993, train_loss=0.584, train_precision=0.934, train_recall=0.935]\n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.44it/s, F1=0.57, eval_acc=0.937, eval_loss=9.8, eval_precision=0.716, eval_recall=0.476]  \n",
      "Epoch: 17/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.22it/s, F1=0.937, train_acc=0.993, train_loss=0.555, train_precision=0.94, train_recall=0.936] \n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.573, eval_acc=0.936, eval_loss=10.3, eval_precision=0.723, eval_recall=0.477]\n",
      "Epoch: 18/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.21it/s, F1=0.946, train_acc=0.994, train_loss=0.515, train_precision=0.946, train_recall=0.947]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.587, eval_acc=0.937, eval_loss=9.31, eval_precision=0.7, eval_recall=0.508]  \n",
      "Epoch: 19/30 Train: 100%|██████████| 349/349 [02:40<00:00,  2.17it/s, F1=0.901, train_acc=0.988, train_loss=1.04, train_precision=0.909, train_recall=0.899]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.578, eval_acc=0.936, eval_loss=8.35, eval_precision=0.688, eval_recall=0.5]  \n",
      "Epoch: 20/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.936, train_acc=0.993, train_loss=0.536, train_precision=0.937, train_recall=0.936]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.582, eval_acc=0.937, eval_loss=9.73, eval_precision=0.72, eval_recall=0.49]  \n",
      "Epoch: 21/30 Train: 100%|██████████| 349/349 [02:37<00:00,  2.22it/s, F1=0.952, train_acc=0.995, train_loss=0.437, train_precision=0.952, train_recall=0.952]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.593, eval_acc=0.938, eval_loss=9.98, eval_precision=0.699, eval_recall=0.518]\n",
      "Epoch: 22/30 Train: 100%|██████████| 349/349 [02:35<00:00,  2.24it/s, F1=0.948, train_acc=0.994, train_loss=0.433, train_precision=0.949, train_recall=0.949]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, F1=0.591, eval_acc=0.939, eval_loss=9.61, eval_precision=0.684, eval_recall=0.522]\n",
      "Epoch: 23/30 Train: 100%|██████████| 349/349 [02:36<00:00,  2.22it/s, F1=0.953, train_acc=0.995, train_loss=0.402, train_precision=0.955, train_recall=0.952]\n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.60it/s, F1=0.587, eval_acc=0.939, eval_loss=9.89, eval_precision=0.693, eval_recall=0.512]\n",
      "Epoch: 24/30 Train: 100%|██████████| 349/349 [02:33<00:00,  2.27it/s, F1=0.955, train_acc=0.995, train_loss=0.368, train_precision=0.954, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.581, eval_acc=0.937, eval_loss=11.4, eval_precision=0.715, eval_recall=0.492]\n",
      "Epoch: 25/30 Train: 100%|██████████| 349/349 [02:38<00:00,  2.20it/s, F1=0.959, train_acc=0.995, train_loss=0.364, train_precision=0.959, train_recall=0.96] \n",
      "Eval Result: 100%|██████████| 15/15 [00:10<00:00,  1.44it/s, F1=0.609, eval_acc=0.942, eval_loss=9.82, eval_precision=0.709, eval_recall=0.535]\n",
      "Epoch: 26/30 Train: 100%|██████████| 349/349 [02:41<00:00,  2.16it/s, F1=0.956, train_acc=0.995, train_loss=0.395, train_precision=0.956, train_recall=0.957]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.608, eval_acc=0.943, eval_loss=9.37, eval_precision=0.719, eval_recall=0.528]\n",
      "Epoch: 27/30 Train: 100%|██████████| 349/349 [02:34<00:00,  2.26it/s, F1=0.962, train_acc=0.996, train_loss=0.367, train_precision=0.962, train_recall=0.962]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.596, eval_acc=0.938, eval_loss=11.5, eval_precision=0.686, eval_recall=0.529]\n",
      "Epoch: 28/30 Train: 100%|██████████| 349/349 [02:35<00:00,  2.24it/s, F1=0.956, train_acc=0.995, train_loss=0.421, train_precision=0.957, train_recall=0.956]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.598, eval_acc=0.94, eval_loss=8.84, eval_precision=0.695, eval_recall=0.526] \n",
      "Epoch: 29/30 Train: 100%|██████████| 349/349 [02:33<00:00,  2.27it/s, F1=0.96, train_acc=0.995, train_loss=0.357, train_precision=0.963, train_recall=0.959] \n",
      "Eval Result: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s, F1=0.588, eval_acc=0.94, eval_loss=10.2, eval_precision=0.706, eval_recall=0.506] \n",
      "Epoch: 30/30 Train: 100%|██████████| 349/349 [02:33<00:00,  2.27it/s, F1=0.968, train_acc=0.996, train_loss=0.309, train_precision=0.969, train_recall=0.969]\n",
      "Eval Result: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s, F1=0.598, eval_acc=0.94, eval_loss=9.7, eval_precision=0.701, eval_recall=0.524]  \n"
     ]
    }
   ],
   "source": [
    "args['task_name'] = 'cdd_tx_5'\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9392d1f0914889243d058bb73f0d89e61311fd6d751bbc8fa50e38d7d4ff811"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('NER': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
