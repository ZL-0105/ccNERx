{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 8,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CHN_NER/train.json\",\n",
      "    \"eval_file\": \"./data/CHN_NER/dev.json\",\n",
      "    \"test_file\": \"./data/CHN_NER/test.json\",\n",
      "    \"tag_file\": \"data/ccks/ccks_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 64,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chn_tx_1\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CHN_NER/train.json etag: 100%|██████████| 2.50M/2.50M [00:00<00:00, 310MB/s]\n",
      "calculate ./data/CHN_NER/dev.json etag: 100%|██████████| 320k/320k [00:00<00:00, 261MB/s]\n",
      "calculate ./data/CHN_NER/test.json etag: 100%|██████████| 321k/321k [00:00<00:00, 274MB/s]\n",
      "calculate data/ccks/ccks_tags_list.txt etag: 100%|██████████| 85.0/85.0 [00:00<00:00, 376kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/lexicon_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/matched_words\n",
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/ccks/ccks_tags_list.txt: 13L [00:00, 83118.83L/s]\n",
      "build line mapper: 13L [00:00, 33888.10L/s]3 [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 13/13 [00:00<00:00, 3542.26it/s]\n",
      "load vocab from list: 100%|██████████| 13/13 [00:00<00:00, 118792.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1643: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n",
      "load dataset from ./data/CHN_NER/train.json: 100%|██████████| 5657/5657 [00:02<00:00, 2051.68it/s]\n",
      "load dataset from ./data/CHN_NER/dev.json: 100%|██████████| 723/723 [00:00<00:00, 2109.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.attn_W', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.fuse_layernorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train:   2%|▏         | 12/708 [00:03<02:47,  4.16it/s, F1=0.00154, train_acc=0.152, train_loss=74.9, train_precision=0.000859, train_recall=0.00758] /home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch: 1/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.96it/s, F1=0.38, train_acc=0.882, train_loss=9.26, train_precision=0.406, train_recall=0.368]        \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.454, eval_acc=0.882, eval_loss=4.79, eval_precision=0.55, eval_recall=0.389] \n",
      "Epoch: 2/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.97it/s, F1=0.534, train_acc=0.919, train_loss=3.98, train_precision=0.565, train_recall=0.513]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.15it/s, F1=0.461, eval_acc=0.896, eval_loss=4.51, eval_precision=0.514, eval_recall=0.42] \n",
      "Epoch: 3/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.96it/s, F1=0.575, train_acc=0.928, train_loss=3.37, train_precision=0.6, train_recall=0.557]  \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, F1=0.531, eval_acc=0.912, eval_loss=3.63, eval_precision=0.526, eval_recall=0.537]\n",
      "Epoch: 4/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.98it/s, F1=0.61, train_acc=0.937, train_loss=2.95, train_precision=0.629, train_recall=0.596] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.23it/s, F1=0.482, eval_acc=0.904, eval_loss=4.02, eval_precision=0.456, eval_recall=0.513]\n",
      "Epoch: 5/30 Train: 100%|██████████| 708/708 [03:00<00:00,  3.93it/s, F1=0.625, train_acc=0.939, train_loss=2.87, train_precision=0.649, train_recall=0.608]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.25it/s, F1=0.497, eval_acc=0.896, eval_loss=4.13, eval_precision=0.467, eval_recall=0.532]\n",
      "Epoch: 6/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.97it/s, F1=0.666, train_acc=0.949, train_loss=2.42, train_precision=0.681, train_recall=0.656]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.26it/s, F1=0.541, eval_acc=0.917, eval_loss=3.85, eval_precision=0.51, eval_recall=0.577] \n",
      "Epoch: 7/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.97it/s, F1=0.673, train_acc=0.951, train_loss=2.34, train_precision=0.687, train_recall=0.662]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.29it/s, F1=0.505, eval_acc=0.903, eval_loss=4.07, eval_precision=0.485, eval_recall=0.528]\n",
      "Epoch: 8/30 Train: 100%|██████████| 708/708 [02:59<00:00,  3.95it/s, F1=0.597, train_acc=0.934, train_loss=3.39, train_precision=0.616, train_recall=0.586]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.35it/s, F1=0.00165, eval_acc=0.83, eval_loss=14.1, eval_precision=0.0833, eval_recall=0.000833]\n",
      "Epoch: 9/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.98it/s, F1=0.587, train_acc=0.932, train_loss=3.39, train_precision=0.624, train_recall=0.57]     \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.28it/s, F1=0.543, eval_acc=0.92, eval_loss=3.77, eval_precision=0.527, eval_recall=0.561]\n",
      "Epoch: 10/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.691, train_acc=0.954, train_loss=2.04, train_precision=0.705, train_recall=0.682]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.32it/s, F1=0.581, eval_acc=0.923, eval_loss=3.72, eval_precision=0.582, eval_recall=0.581]\n",
      "Epoch: 11/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.705, train_acc=0.958, train_loss=1.94, train_precision=0.717, train_recall=0.697]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, F1=0.583, eval_acc=0.924, eval_loss=4.02, eval_precision=0.559, eval_recall=0.61] \n",
      "Epoch: 12/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.04it/s, F1=0.715, train_acc=0.959, train_loss=1.92, train_precision=0.727, train_recall=0.706]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.586, eval_acc=0.924, eval_loss=3.52, eval_precision=0.589, eval_recall=0.584]\n",
      "Epoch: 13/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.00it/s, F1=0.737, train_acc=0.964, train_loss=1.69, train_precision=0.746, train_recall=0.732]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, F1=0.594, eval_acc=0.93, eval_loss=3.83, eval_precision=0.594, eval_recall=0.596] \n",
      "Epoch: 14/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.03it/s, F1=0.752, train_acc=0.966, train_loss=1.6, train_precision=0.761, train_recall=0.747] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.599, eval_acc=0.93, eval_loss=4.06, eval_precision=0.588, eval_recall=0.61] \n",
      "Epoch: 15/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.97it/s, F1=0.769, train_acc=0.97, train_loss=1.47, train_precision=0.774, train_recall=0.766] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.27it/s, F1=0.566, eval_acc=0.925, eval_loss=4.09, eval_precision=0.553, eval_recall=0.581]\n",
      "Epoch: 16/30 Train: 100%|██████████| 708/708 [02:54<00:00,  4.05it/s, F1=0.769, train_acc=0.968, train_loss=1.5, train_precision=0.775, train_recall=0.765] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.576, eval_acc=0.923, eval_loss=4.53, eval_precision=0.59, eval_recall=0.563] \n",
      "Epoch: 17/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.786, train_acc=0.972, train_loss=1.37, train_precision=0.793, train_recall=0.781]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, F1=0.591, eval_acc=0.928, eval_loss=4.2, eval_precision=0.598, eval_recall=0.585]\n",
      "Epoch: 18/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.796, train_acc=0.974, train_loss=1.29, train_precision=0.802, train_recall=0.792]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.596, eval_acc=0.927, eval_loss=4.89, eval_precision=0.597, eval_recall=0.595]\n",
      "Epoch: 19/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.98it/s, F1=0.822, train_acc=0.978, train_loss=1.16, train_precision=0.827, train_recall=0.819]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.28it/s, F1=0.591, eval_acc=0.927, eval_loss=4.32, eval_precision=0.59, eval_recall=0.592]\n",
      "Epoch: 20/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.97it/s, F1=0.839, train_acc=0.98, train_loss=1.02, train_precision=0.844, train_recall=0.836] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.18it/s, F1=0.587, eval_acc=0.929, eval_loss=4.91, eval_precision=0.607, eval_recall=0.568]\n",
      "Epoch: 21/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.851, train_acc=0.981, train_loss=0.957, train_precision=0.855, train_recall=0.848]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, F1=0.548, eval_acc=0.92, eval_loss=4.73, eval_precision=0.539, eval_recall=0.559] \n",
      "Epoch: 22/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.03it/s, F1=0.86, train_acc=0.982, train_loss=0.887, train_precision=0.863, train_recall=0.858] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.28it/s, F1=0.593, eval_acc=0.93, eval_loss=4.81, eval_precision=0.584, eval_recall=0.604] \n",
      "Epoch: 23/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.862, train_acc=0.982, train_loss=0.887, train_precision=0.867, train_recall=0.86] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.29it/s, F1=0.571, eval_acc=0.925, eval_loss=4.74, eval_precision=0.563, eval_recall=0.581]\n",
      "Epoch: 24/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.00it/s, F1=0.879, train_acc=0.986, train_loss=0.762, train_precision=0.882, train_recall=0.878]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.594, eval_acc=0.927, eval_loss=4.87, eval_precision=0.583, eval_recall=0.606]\n",
      "Epoch: 25/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.97it/s, F1=0.888, train_acc=0.986, train_loss=0.746, train_precision=0.892, train_recall=0.885]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.32it/s, F1=0.584, eval_acc=0.925, eval_loss=5.85, eval_precision=0.579, eval_recall=0.59] \n",
      "Epoch: 26/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.03it/s, F1=0.883, train_acc=0.985, train_loss=0.78, train_precision=0.887, train_recall=0.88]  \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, F1=0.595, eval_acc=0.932, eval_loss=5.28, eval_precision=0.593, eval_recall=0.598]\n",
      "Epoch: 27/30 Train: 100%|██████████| 708/708 [02:59<00:00,  3.95it/s, F1=0.895, train_acc=0.987, train_loss=0.671, train_precision=0.898, train_recall=0.894]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.23it/s, F1=0.616, eval_acc=0.929, eval_loss=5.39, eval_precision=0.603, eval_recall=0.63] \n",
      "Epoch: 28/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.96it/s, F1=0.909, train_acc=0.989, train_loss=0.616, train_precision=0.913, train_recall=0.907]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.607, eval_acc=0.93, eval_loss=5.69, eval_precision=0.589, eval_recall=0.627]\n",
      "Epoch: 29/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.98it/s, F1=0.908, train_acc=0.988, train_loss=0.599, train_precision=0.911, train_recall=0.906]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.36it/s, F1=0.627, eval_acc=0.932, eval_loss=5.86, eval_precision=0.616, eval_recall=0.64]\n",
      "Epoch: 30/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.96it/s, F1=0.923, train_acc=0.99, train_loss=0.532, train_precision=0.926, train_recall=0.92]  \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.62, eval_acc=0.928, eval_loss=6.08, eval_precision=0.604, eval_recall=0.638] \n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 64,\n",
    "    'max_scan_num': 1000000,\n",
    "    # 'inter_max_scan_num': 3000,\n",
    "    'train_file': './data/CHN_NER/train.json',\n",
    "    'eval_file': './data/CHN_NER/dev.json',\n",
    "    'test_file': './data/CHN_NER/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/ccks/ccks_tags_list.txt',\n",
    "    # 'loader_name': 'le_loader_zl',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/tencent_medicine_vocab.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'task_name': 'chn_tx_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 8,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CHN_NER/train.json\",\n",
      "    \"eval_file\": \"./data/CHN_NER/dev.json\",\n",
      "    \"test_file\": \"./data/CHN_NER/test.json\",\n",
      "    \"tag_file\": \"data/ccks/ccks_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 64,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chn_tx_2\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CHN_NER/train.json etag: 100%|██████████| 2.50M/2.50M [00:00<00:00, 353MB/s]\n",
      "calculate ./data/CHN_NER/dev.json etag: 100%|██████████| 320k/320k [00:00<00:00, 290MB/s]\n",
      "calculate ./data/CHN_NER/test.json etag: 100%|██████████| 321k/321k [00:00<00:00, 298MB/s]\n",
      "calculate data/ccks/ccks_tags_list.txt etag: 100%|██████████| 85.0/85.0 [00:00<00:00, 199kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/lexicon_tree\n",
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/matched_words\n",
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/ccks/ccks_tags_list.txt: 13L [00:00, 65932.23L/s]\n",
      "build line mapper: 13L [00:00, 125925.99L/s] [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 13/13 [00:00<00:00, 2242.39it/s]\n",
      "load vocab from list: 100%|██████████| 13/13 [00:00<00:00, 161798.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CHN_NER/train.json: 100%|██████████| 5657/5657 [00:02<00:00, 2067.13it/s]\n",
      "load dataset from ./data/CHN_NER/dev.json: 100%|██████████| 723/723 [00:00<00:00, 2017.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.attn_W', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.fuse_layernorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.4, train_acc=0.885, train_loss=9.23, train_precision=0.435, train_recall=0.379]       \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.534, eval_acc=0.911, eval_loss=4.14, eval_precision=0.564, eval_recall=0.508]\n",
      "Epoch: 2/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.549, train_acc=0.921, train_loss=3.87, train_precision=0.579, train_recall=0.529]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.32it/s, F1=0.551, eval_acc=0.92, eval_loss=3.44, eval_precision=0.554, eval_recall=0.549] \n",
      "Epoch: 3/30 Train: 100%|██████████| 708/708 [02:57<00:00,  4.00it/s, F1=0.594, train_acc=0.933, train_loss=3.2, train_precision=0.617, train_recall=0.579] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.57, eval_acc=0.921, eval_loss=3.23, eval_precision=0.59, eval_recall=0.552] \n",
      "Epoch: 4/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.629, train_acc=0.94, train_loss=2.85, train_precision=0.647, train_recall=0.617] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.555, eval_acc=0.92, eval_loss=3.25, eval_precision=0.584, eval_recall=0.529]\n",
      "Epoch: 5/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.02it/s, F1=0.661, train_acc=0.948, train_loss=2.44, train_precision=0.675, train_recall=0.652]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, F1=0.553, eval_acc=0.922, eval_loss=3.32, eval_precision=0.547, eval_recall=0.561]\n",
      "Epoch: 6/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.692, train_acc=0.955, train_loss=2.17, train_precision=0.702, train_recall=0.686]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.552, eval_acc=0.921, eval_loss=3.74, eval_precision=0.548, eval_recall=0.557]\n",
      "Epoch: 7/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.98it/s, F1=0.718, train_acc=0.96, train_loss=2.02, train_precision=0.727, train_recall=0.712] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.576, eval_acc=0.929, eval_loss=3.68, eval_precision=0.561, eval_recall=0.594]\n",
      "Epoch: 8/30 Train: 100%|██████████| 708/708 [02:59<00:00,  3.94it/s, F1=0.735, train_acc=0.964, train_loss=1.8, train_precision=0.745, train_recall=0.728] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.32it/s, F1=0.564, eval_acc=0.922, eval_loss=3.57, eval_precision=0.56, eval_recall=0.569]\n",
      "Epoch: 9/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.98it/s, F1=0.753, train_acc=0.967, train_loss=1.64, train_precision=0.762, train_recall=0.747]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.603, eval_acc=0.93, eval_loss=3.87, eval_precision=0.594, eval_recall=0.614]\n",
      "Epoch: 10/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.98it/s, F1=0.778, train_acc=0.972, train_loss=1.45, train_precision=0.785, train_recall=0.774]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.36it/s, F1=0.584, eval_acc=0.927, eval_loss=4.14, eval_precision=0.572, eval_recall=0.598]\n",
      "Epoch: 11/30 Train: 100%|██████████| 708/708 [02:59<00:00,  3.95it/s, F1=0.789, train_acc=0.974, train_loss=1.38, train_precision=0.797, train_recall=0.784]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.26it/s, F1=0.604, eval_acc=0.931, eval_loss=4.04, eval_precision=0.597, eval_recall=0.611]\n",
      "Epoch: 12/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.98it/s, F1=0.815, train_acc=0.977, train_loss=1.24, train_precision=0.82, train_recall=0.812] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.26it/s, F1=0.576, eval_acc=0.923, eval_loss=4.65, eval_precision=0.553, eval_recall=0.603]\n",
      "Epoch: 13/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.02it/s, F1=0.829, train_acc=0.98, train_loss=1.1, train_precision=0.834, train_recall=0.825]  \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.29it/s, F1=0.612, eval_acc=0.933, eval_loss=4.54, eval_precision=0.605, eval_recall=0.619]\n",
      "Epoch: 14/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.851, train_acc=0.982, train_loss=0.997, train_precision=0.856, train_recall=0.848]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, F1=0.607, eval_acc=0.925, eval_loss=5.07, eval_precision=0.583, eval_recall=0.635]\n",
      "Epoch: 15/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.97it/s, F1=0.869, train_acc=0.984, train_loss=0.885, train_precision=0.872, train_recall=0.867]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.13it/s, F1=0.614, eval_acc=0.928, eval_loss=5.25, eval_precision=0.594, eval_recall=0.636]\n",
      "Epoch: 16/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.886, train_acc=0.986, train_loss=0.813, train_precision=0.89, train_recall=0.884] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.29it/s, F1=0.605, eval_acc=0.923, eval_loss=5.87, eval_precision=0.585, eval_recall=0.629]\n",
      "Epoch: 17/30 Train: 100%|██████████| 708/708 [02:34<00:00,  4.59it/s, F1=0.875, train_acc=0.984, train_loss=0.92, train_precision=0.878, train_recall=0.873] \n",
      "Eval Result: 100%|██████████| 12/12 [00:02<00:00,  4.06it/s, F1=0.603, eval_acc=0.929, eval_loss=4.8, eval_precision=0.588, eval_recall=0.619] \n",
      "Epoch: 18/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.04it/s, F1=0.901, train_acc=0.988, train_loss=0.69, train_precision=0.904, train_recall=0.9]   \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.24it/s, F1=0.639, eval_acc=0.933, eval_loss=5.85, eval_precision=0.613, eval_recall=0.667]\n",
      "Epoch: 19/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.907, train_acc=0.988, train_loss=0.683, train_precision=0.911, train_recall=0.905]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.35it/s, F1=0.608, eval_acc=0.927, eval_loss=5.43, eval_precision=0.581, eval_recall=0.638]\n",
      "Epoch: 20/30 Train: 100%|██████████| 708/708 [02:57<00:00,  4.00it/s, F1=0.922, train_acc=0.991, train_loss=0.544, train_precision=0.924, train_recall=0.921]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.645, eval_acc=0.933, eval_loss=6.06, eval_precision=0.617, eval_recall=0.677]\n",
      "Epoch: 21/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.02it/s, F1=0.927, train_acc=0.991, train_loss=0.562, train_precision=0.927, train_recall=0.927]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.32it/s, F1=0.651, eval_acc=0.938, eval_loss=6.19, eval_precision=0.645, eval_recall=0.658]\n",
      "Epoch: 22/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.03it/s, F1=0.927, train_acc=0.991, train_loss=0.563, train_precision=0.93, train_recall=0.926] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.23it/s, F1=0.64, eval_acc=0.932, eval_loss=6.28, eval_precision=0.624, eval_recall=0.657]\n",
      "Epoch: 23/30 Train: 100%|██████████| 708/708 [02:57<00:00,  4.00it/s, F1=0.929, train_acc=0.991, train_loss=0.544, train_precision=0.931, train_recall=0.928]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.643, eval_acc=0.935, eval_loss=6.1, eval_precision=0.639, eval_recall=0.648] \n",
      "Epoch: 24/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.96it/s, F1=0.938, train_acc=0.992, train_loss=0.465, train_precision=0.94, train_recall=0.936] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.36it/s, F1=0.635, eval_acc=0.934, eval_loss=6.72, eval_precision=0.622, eval_recall=0.649]\n",
      "Epoch: 25/30 Train: 100%|██████████| 708/708 [02:59<00:00,  3.94it/s, F1=0.939, train_acc=0.992, train_loss=0.457, train_precision=0.941, train_recall=0.938]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.16it/s, F1=0.64, eval_acc=0.935, eval_loss=6.73, eval_precision=0.625, eval_recall=0.656] \n",
      "Epoch: 26/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.02it/s, F1=0.945, train_acc=0.992, train_loss=0.431, train_precision=0.945, train_recall=0.945]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.637, eval_acc=0.934, eval_loss=6.3, eval_precision=0.62, eval_recall=0.657] \n",
      "Epoch: 27/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.97it/s, F1=0.942, train_acc=0.992, train_loss=0.464, train_precision=0.944, train_recall=0.941]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.26it/s, F1=0.658, eval_acc=0.936, eval_loss=6.56, eval_precision=0.636, eval_recall=0.682]\n",
      "Epoch: 28/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.03it/s, F1=0.941, train_acc=0.993, train_loss=0.439, train_precision=0.943, train_recall=0.94] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.27it/s, F1=0.652, eval_acc=0.934, eval_loss=7.09, eval_precision=0.638, eval_recall=0.668]\n",
      "Epoch: 29/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.02it/s, F1=0.953, train_acc=0.994, train_loss=0.391, train_precision=0.954, train_recall=0.953]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.35it/s, F1=0.64, eval_acc=0.932, eval_loss=6.71, eval_precision=0.62, eval_recall=0.662]  \n",
      "Epoch: 30/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.943, train_acc=0.993, train_loss=0.44, train_precision=0.944, train_recall=0.943] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.29it/s, F1=0.623, eval_acc=0.932, eval_loss=6.03, eval_precision=0.614, eval_recall=0.633]\n"
     ]
    }
   ],
   "source": [
    "args[\"task_name\"] = \"chn_tx_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 8,\n",
      "    \"eval_batch_size\": 64,\n",
      "    \"test_batch_size\": 16,\n",
      "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
      "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
      "    \"train_file\": \"./data/CHN_NER/train.json\",\n",
      "    \"eval_file\": \"./data/CHN_NER/dev.json\",\n",
      "    \"test_file\": \"./data/CHN_NER/test.json\",\n",
      "    \"tag_file\": \"data/ccks/ccks_tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"output_eval\": true,\n",
      "    \"max_scan_num\": 1000000,\n",
      "    \"add_seq_vocab\": false,\n",
      "    \"max_seq_length\": 64,\n",
      "    \"max_word_num\": 5,\n",
      "    \"default_tag\": \"O\",\n",
      "    \"use_test\": false,\n",
      "    \"do_shuffle\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"task_name\": \"chn_tx_3\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate ./data/CHN_NER/train.json etag: 100%|██████████| 2.50M/2.50M [00:00<00:00, 363MB/s]\n",
      "calculate ./data/CHN_NER/dev.json etag: 100%|██████████| 320k/320k [00:00<00:00, 294MB/s]\n",
      "calculate ./data/CHN_NER/test.json etag: 100%|██████████| 321k/321k [00:00<00:00, 298MB/s]\n",
      "calculate data/ccks/ccks_tags_list.txt etag: 100%|██████████| 85.0/85.0 [00:00<00:00, 537kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/lexicon_tree\n",
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/matched_words\n",
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/word_vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count line size data/ccks/ccks_tags_list.txt: 13L [00:00, 102685.41L/s]\n",
      "build line mapper: 13L [00:00, 110825.11L/s] [00:00<?, ?it/s]\n",
      "load vocab from files: 100%|██████████| 13/13 [00:00<00:00, 3742.60it/s]\n",
      "load vocab from list: 100%|██████████| 13/13 [00:00<00:00, 161319.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached ./temp/cc78cd055ec1e1aceea9e0d47d19c450_c417566c1204052a82c6905730a07e30_3a0cb918f2fd9cba35f0603ba26028e4_9c02c6b5f9f31c0f8b66d34ba80dcf4e/1000000/vocab_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/CHN_NER/train.json: 100%|██████████| 5657/5657 [00:02<00:00, 2100.89it/s]\n",
      "load dataset from ./data/CHN_NER/dev.json: 100%|██████████| 723/723 [00:00<00:00, 2053.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained embedding from file.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing LEBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing LEBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LEBertModel were not initialized from the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin and are newly initialized: ['bert.encoder.layer.0.attn_W', 'word_embeddings.weight', 'bert.encoder.layer.0.word_transform.weight', 'bert.embeddings.position_ids', 'bert.encoder.layer.0.word_word_weight.bias', 'bert.encoder.layer.0.word_transform.bias', 'bert.encoder.layer.0.fuse_layernorm.weight', 'bert.encoder.layer.0.word_word_weight.weight', 'bert.encoder.layer.0.fuse_layernorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 1/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.395, train_acc=0.884, train_loss=8.64, train_precision=0.432, train_recall=0.375]    \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.513, eval_acc=0.905, eval_loss=4.34, eval_precision=0.496, eval_recall=0.533]\n",
      "Epoch: 2/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.556, train_acc=0.924, train_loss=3.8, train_precision=0.586, train_recall=0.536] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, F1=0.489, eval_acc=0.886, eval_loss=4.33, eval_precision=0.467, eval_recall=0.514]\n",
      "Epoch: 3/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.606, train_acc=0.935, train_loss=3.12, train_precision=0.63, train_recall=0.589] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.35it/s, F1=0.539, eval_acc=0.911, eval_loss=3.61, eval_precision=0.546, eval_recall=0.533]\n",
      "Epoch: 4/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.00it/s, F1=0.629, train_acc=0.941, train_loss=2.77, train_precision=0.648, train_recall=0.617]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, F1=0.527, eval_acc=0.908, eval_loss=3.57, eval_precision=0.513, eval_recall=0.543]\n",
      "Epoch: 5/30 Train: 100%|██████████| 708/708 [02:57<00:00,  4.00it/s, F1=0.671, train_acc=0.951, train_loss=2.41, train_precision=0.687, train_recall=0.66] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, F1=0.545, eval_acc=0.914, eval_loss=3.6, eval_precision=0.524, eval_recall=0.569] \n",
      "Epoch: 6/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.691, train_acc=0.955, train_loss=2.22, train_precision=0.705, train_recall=0.682]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.547, eval_acc=0.924, eval_loss=3.47, eval_precision=0.53, eval_recall=0.566] \n",
      "Epoch: 7/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.72, train_acc=0.962, train_loss=1.93, train_precision=0.731, train_recall=0.713] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.553, eval_acc=0.915, eval_loss=3.74, eval_precision=0.529, eval_recall=0.581]\n",
      "Epoch: 8/30 Train: 100%|██████████| 708/708 [02:58<00:00,  3.97it/s, F1=0.74, train_acc=0.966, train_loss=1.75, train_precision=0.748, train_recall=0.734] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.555, eval_acc=0.92, eval_loss=3.76, eval_precision=0.545, eval_recall=0.566]\n",
      "Epoch: 9/30 Train: 100%|██████████| 708/708 [02:57<00:00,  4.00it/s, F1=0.758, train_acc=0.969, train_loss=1.63, train_precision=0.765, train_recall=0.754]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.23it/s, F1=0.516, eval_acc=0.912, eval_loss=4.4, eval_precision=0.488, eval_recall=0.548]\n",
      "Epoch: 10/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.785, train_acc=0.974, train_loss=1.44, train_precision=0.792, train_recall=0.78] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, F1=0.549, eval_acc=0.918, eval_loss=4.48, eval_precision=0.532, eval_recall=0.568]\n",
      "Epoch: 11/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.03it/s, F1=0.801, train_acc=0.975, train_loss=1.32, train_precision=0.807, train_recall=0.798]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, F1=0.561, eval_acc=0.924, eval_loss=3.99, eval_precision=0.548, eval_recall=0.574]\n",
      "Epoch: 12/30 Train: 100%|██████████| 708/708 [02:55<00:00,  4.03it/s, F1=0.829, train_acc=0.98, train_loss=1.14, train_precision=0.833, train_recall=0.827] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.35it/s, F1=0.573, eval_acc=0.923, eval_loss=4.02, eval_precision=0.575, eval_recall=0.571]\n",
      "Epoch: 13/30 Train: 100%|██████████| 708/708 [02:59<00:00,  3.95it/s, F1=0.836, train_acc=0.98, train_loss=1.09, train_precision=0.841, train_recall=0.833] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, F1=0.567, eval_acc=0.928, eval_loss=4.94, eval_precision=0.559, eval_recall=0.575]\n",
      "Epoch: 14/30 Train: 100%|██████████| 708/708 [02:57<00:00,  4.00it/s, F1=0.865, train_acc=0.984, train_loss=0.948, train_precision=0.868, train_recall=0.864]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.35it/s, F1=0.595, eval_acc=0.931, eval_loss=4.77, eval_precision=0.59, eval_recall=0.602]\n",
      "Epoch: 15/30 Train: 100%|██████████| 708/708 [02:57<00:00,  3.99it/s, F1=0.877, train_acc=0.986, train_loss=0.876, train_precision=0.882, train_recall=0.875]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.608, eval_acc=0.932, eval_loss=5.35, eval_precision=0.608, eval_recall=0.609]\n",
      "Epoch: 16/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.01it/s, F1=0.884, train_acc=0.986, train_loss=0.79, train_precision=0.888, train_recall=0.883] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.35it/s, F1=0.594, eval_acc=0.926, eval_loss=5.34, eval_precision=0.607, eval_recall=0.583]\n",
      "Epoch: 17/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.00it/s, F1=0.895, train_acc=0.987, train_loss=0.762, train_precision=0.899, train_recall=0.893]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, F1=0.543, eval_acc=0.92, eval_loss=5.9, eval_precision=0.569, eval_recall=0.52]  \n",
      "Epoch: 18/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.02it/s, F1=0.895, train_acc=0.987, train_loss=0.763, train_precision=0.899, train_recall=0.893]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.28it/s, F1=0.604, eval_acc=0.93, eval_loss=5.73, eval_precision=0.609, eval_recall=0.599] \n",
      "Epoch: 19/30 Train: 100%|██████████| 708/708 [02:54<00:00,  4.05it/s, F1=0.912, train_acc=0.99, train_loss=0.622, train_precision=0.914, train_recall=0.912] \n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, F1=0.569, eval_acc=0.929, eval_loss=6.95, eval_precision=0.572, eval_recall=0.568]\n",
      "Epoch: 20/30 Train: 100%|██████████| 708/708 [02:56<00:00,  4.02it/s, F1=0.915, train_acc=0.991, train_loss=0.599, train_precision=0.917, train_recall=0.914]\n",
      "Eval Result: 100%|██████████| 12/12 [00:05<00:00,  2.37it/s, F1=0.59, eval_acc=0.927, eval_loss=6.46, eval_precision=0.579, eval_recall=0.601] \n",
      "Epoch: 21/30 Train:  90%|████████▉ | 634/708 [02:39<00:18,  4.02it/s, F1=0.923, train_acc=0.991, train_loss=0.559, train_precision=0.926, train_recall=0.923]"
     ]
    }
   ],
   "source": [
    "args[\"task_name\"] = \"chn_tx_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_tx_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_tx_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 64,\n",
    "    'max_scan_num': 1000000,\n",
    "    'inter_max_scan_num': 20000,\n",
    "    'train_file': './data/CHN_NER/train.json',\n",
    "    'eval_file': './data/CHN_NER/dev.json',\n",
    "    'test_file': './data/CHN_NER/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/ccks/ccks_tags_list.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    # 'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    # \"word_vocab_file\":\"./data/tencent/tencent_medicine_vocab.txt\",\n",
    "    # \"inter_knowledge_file\":\"./data/tencent/FN_medicine_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    # \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'task_name': 'chn_v1_tx_FN_TH_20000_1'\n",
    "}\n",
    "\n",
    "# Trainer\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v1_tx_FN_TH_20000_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v1_tx_FN_TH_20000_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v1_tx_FN_TH_20000_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v1_tx_FN_TH_20000_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"model_name\"] = \"ZLEBert_v2\"\n",
    "args[\"task_name\"] = \"chn_v2_tx_FN_TH_20000_1\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v2_tx_FN_TH_20000_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v2_tx_FN_TH_20000_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v2_tx_FN_TH_20000_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v2_tx_FN_TH_20000_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"model_name\"] = \"ZLEBert_v3\"\n",
    "args[\"task_name\"] = \"chn_v3_tx_FN_TH_20000_1\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v3_tx_FN_TH_20000_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v3_tx_FN_TH_20000_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v3_tx_FN_TH_20000_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v3_tx_FN_TH_20000_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"model_name\"] = \"ZLEBert_v4\"\n",
    "args[\"task_name\"] = \"chn_v4_tx_FN_TH_20000_1\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v4_tx_FN_TH_20000_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v4_tx_FN_TH_20000_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v4_tx_FN_TH_20000_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"task_name\"] = \"chn_v4_tx_FN_TH_20000_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9392d1f0914889243d058bb73f0d89e61311fd6d751bbc8fa50e38d7d4ff811"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('NER')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
