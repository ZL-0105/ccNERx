{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert预训练\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/FN_multiple_pretrained_2/Bert_8960/pytorch_model.bin',\n",
    "    'max_seq_length': 256,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/CDD/train.json',\n",
    "    'eval_file': './data/CDD/dev.json',\n",
    "    'test_file': './data/CDD/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/CDD/cdd_tags_list.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'cdd_pre_3',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        # \"KEYWORD\": \"关键词\",\n",
    "        # \"DIS\": \"疾病或诊断\",\n",
    "        # \"ANA\": \"解剖部位\",\n",
    "        # \"LAB\": \"实验室检验\",\n",
    "        # \"MED\": \"药物\",\n",
    "        # \"OPE\": \"手术\",\n",
    "        # \"IMA\": \"影像检查\",\n",
    "        \"CHECK\":\"检查\",\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert预训练\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/ccks_pre_2_512/Bert_4375/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/ccks/before/subtask1_train.json',\n",
    "    'eval_file': './data/ccks/subtask1_test.json',\n",
    "    'test_file': './data/ccks/subtask1_test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/ccks/ccks_tags_list.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'ccks_pre_3',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        # \"KEYWORD\": \"关键词\",\n",
    "        \"DIS\": \"疾病或诊断\",\n",
    "        \"ANA\": \"解剖部位\",\n",
    "        \"LAB\": \"实验室检验\",\n",
    "        \"MED\": \"药物\",\n",
    "        \"OPE\": \"手术\",\n",
    "        \"IMA\": \"影像检查\",\n",
    "        # \"CHECK\":\"检查\",\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert预训练\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/FN_multiple_pretrained_2/Bert_8960/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/FN/sc_json_500/train.json',\n",
    "    'eval_file': './data/FN/sc_test100/test.json',\n",
    "    'test_file': './data/FN/sc_test100/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/FN/tags_list.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'sc_pre_3',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        \"KEYWORD\": \"关键词\",\n",
    "        # \"DIS\": \"疾病或诊断\",\n",
    "        # \"ANA\": \"解剖部位\",\n",
    "        # \"LAB\": \"实验室检验\",\n",
    "        # \"MED\": \"药物\",\n",
    "        # \"OPE\": \"手术\",\n",
    "        # \"IMA\": \"影像检查\",\n",
    "        # \"CHECK\":\"检查\",\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert预训练\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/ccks_pre_2_512/Bert_4375/pytorch_model.bin',\n",
    "    'max_seq_length': 256,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/ccks/cut/subtask1_train.json',\n",
    "    'eval_file': './data/ccks/subtask1_test.json',\n",
    "    'test_file': './data/ccks/subtask1_test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/ccks/ccks_tags_list.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'ccks_pre_4',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        # \"KEYWORD\": \"关键词\",\n",
    "        \"DIS\": \"疾病或诊断\",\n",
    "        \"ANA\": \"解剖部位\",\n",
    "        \"LAB\": \"实验室检验\",\n",
    "        \"MED\": \"药物\",\n",
    "        \"OPE\": \"手术\",\n",
    "        \"IMA\": \"影像检查\",\n",
    "        # \"CHECK\":\"检查\",\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert预训练\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/FN_multiple_pretrained_2/Bert_8960/pytorch_model.bin',\n",
    "    'max_seq_length': 256,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/FN/sc_cut_400/train.json',\n",
    "    'eval_file': './data/FN/sc_test100/test.json',\n",
    "    'test_file': './data/FN/sc_test100/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/FN/tags_list.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'sc_pre_5',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        \"KEYWORD\": \"关键词\",\n",
    "        # \"DIS\": \"疾病或诊断\",\n",
    "        # \"ANA\": \"解剖部位\",\n",
    "        # \"LAB\": \"实验室检验\",\n",
    "        # \"MED\": \"药物\",\n",
    "        # \"OPE\": \"手术\",\n",
    "        # \"IMA\": \"影像检查\",\n",
    "        # \"CHECK\":\"检查\",\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结论词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1643: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"train_file\": \"./data/prompt/pro_keyword.json\",\n",
      "    \"tag_file\": \"data/FN/tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"max_seq_length\": 128,\n",
      "    \"do_shuffle\": true,\n",
      "    \"task_name\": \"summary_pre_1\",\n",
      "    \"tag_rules\": {\n",
      "        \"O\": \"非实体\",\n",
      "        \"KEYWORD\": \"关键词\"\n",
      "    },\n",
      "    \"debug\": true,\n",
      "    \"pass_none_rule\": true\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/prompt/pro_keyword.json: 100%|██████████| 1607/1607 [00:00<00:00, 1761.05it/s]\n",
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch: 1/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.74it/s, train_loss=8.1] \n",
      "Epoch: 2/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.77it/s, train_loss=0.218]\n",
      "Epoch: 3/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.75it/s, train_loss=0.0121]\n",
      "Epoch: 4/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.74it/s, train_loss=0.00455]\n",
      "Epoch: 5/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.72it/s, train_loss=0.00306]\n",
      "Epoch: 6/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.71it/s, train_loss=0.00203]\n",
      "Epoch: 7/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.0014] \n",
      "Epoch: 8/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.000956]\n",
      "Epoch: 9/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.000733]\n",
      "Epoch: 10/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.000554]\n",
      "Epoch: 11/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000482]\n",
      "Epoch: 12/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000398]\n",
      "Epoch: 13/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000318]\n",
      "Epoch: 14/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000345]\n",
      "Epoch: 15/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000269]\n",
      "Epoch: 16/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.000204]\n",
      "Epoch: 17/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000163]\n",
      "Epoch: 18/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000107]\n",
      "Epoch: 19/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.67it/s, train_loss=0.000136]\n",
      "Epoch: 20/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000192]\n",
      "Epoch: 21/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.67it/s, train_loss=0.000106]\n",
      "Epoch: 22/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000176]\n",
      "Epoch: 23/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=7.25e-5]\n",
      "Epoch: 24/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000136]\n",
      "Epoch: 25/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=4.8e-5] \n",
      "Epoch: 26/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=5.24e-5]\n",
      "Epoch: 27/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=5.16e-5]\n",
      "Epoch: 28/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.67it/s, train_loss=5.52e-5]\n",
      "Epoch: 29/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=4.77e-5]\n",
      "Epoch: 30/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=0.000143]\n",
      "Epoch: 31/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, train_loss=7.73e-5]\n",
      "Epoch: 32/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.67it/s, train_loss=3.07e-5]\n",
      "Epoch: 33/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.67it/s, train_loss=7.28e-5]\n",
      "Epoch: 34/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.67it/s, train_loss=9.63e-5]\n",
      "Epoch: 35/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.67it/s, train_loss=4.32e-5]\n"
     ]
    }
   ],
   "source": [
    "# Bert预训练\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/FN_multiple_pretrained_2/Bert_8960/pytorch_model.bin',\n",
    "    'max_seq_length': 128,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/prompt/pro_keyword.json',\n",
    "    'eval_file': './data/FN/sc_test100/test.json',\n",
    "    'test_file': './data/FN/sc_test100/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/FN/tags_list.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'summary_pre_1',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        \"KEYWORD\": \"关键词\",\n",
    "        # \"DIS\": \"疾病或诊断\",\n",
    "        # \"ANA\": \"解剖部位\",\n",
    "        # \"LAB\": \"实验室检验\",\n",
    "        # \"MED\": \"药物\",\n",
    "        # \"OPE\": \"手术\",\n",
    "        # \"IMA\": \"影像检查\",\n",
    "        # \"CHECK\":\"检查\",\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1643: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"train_file\": \"./data/prompt/pro_thuocl_key.json\",\n",
      "    \"tag_file\": \"data/FN/tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"max_seq_length\": 128,\n",
      "    \"do_shuffle\": true,\n",
      "    \"task_name\": \"thuocl_key_pre_1\",\n",
      "    \"tag_rules\": {\n",
      "        \"O\": \"非实体\",\n",
      "        \"KEYWORD\": \"关键词\"\n",
      "    },\n",
      "    \"debug\": true,\n",
      "    \"pass_none_rule\": true\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/prompt/pro_thuocl_key.json: 100%|██████████| 22218/22218 [00:11<00:00, 1883.52it/s]\n",
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch: 1/35 Train: 100%|██████████| 1389/1389 [04:56<00:00,  4.68it/s, train_loss=0.655]\n",
      "Epoch: 2/35 Train: 100%|██████████| 1389/1389 [05:03<00:00,  4.57it/s, train_loss=0.000185]\n",
      "Epoch: 3/35 Train: 100%|██████████| 1389/1389 [05:05<00:00,  4.55it/s, train_loss=9.83e-5] \n",
      "Epoch: 4/35 Train: 100%|██████████| 1389/1389 [05:07<00:00,  4.52it/s, train_loss=4.07e-5]\n",
      "Epoch: 5/35 Train: 100%|██████████| 1389/1389 [05:06<00:00,  4.53it/s, train_loss=1.82e-5]\n",
      "Epoch: 6/35 Train: 100%|██████████| 1389/1389 [05:06<00:00,  4.53it/s, train_loss=2.03e-5]\n",
      "Epoch: 7/35 Train: 100%|██████████| 1389/1389 [05:07<00:00,  4.51it/s, train_loss=3.42e-6]\n",
      "Epoch: 8/35 Train: 100%|██████████| 1389/1389 [05:06<00:00,  4.53it/s, train_loss=7.02e-5]\n",
      "Epoch: 9/35 Train: 100%|██████████| 1389/1389 [05:07<00:00,  4.52it/s, train_loss=3.34e-6]\n",
      "Epoch: 10/35 Train: 100%|██████████| 1389/1389 [05:06<00:00,  4.53it/s, train_loss=5.56e-5]\n",
      "Epoch: 11/35 Train: 100%|██████████| 1389/1389 [05:05<00:00,  4.55it/s, train_loss=1.81e-5]\n",
      "Epoch: 12/35 Train: 100%|██████████| 1389/1389 [05:06<00:00,  4.53it/s, train_loss=2.81e-5]\n",
      "Epoch: 13/35 Train:  76%|███████▌  | 1055/1389 [03:53<01:17,  4.29it/s, train_loss=4.74e-5]"
     ]
    }
   ],
   "source": [
    "# Bert预训练\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/FN_multiple_pretrained_2/Bert_8960/pytorch_model.bin',\n",
    "    'max_seq_length': 128,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/prompt/pro_thuocl_key.json',\n",
    "    'eval_file': './data/FN/sc_test100/test.json',\n",
    "    'test_file': './data/FN/sc_test100/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/FN/tags_list.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'thuocl_key_pre_1',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        \"KEYWORD\": \"关键词\",\n",
    "        # \"DIS\": \"疾病或诊断\",\n",
    "        # \"ANA\": \"解剖部位\",\n",
    "        # \"LAB\": \"实验室检验\",\n",
    "        # \"MED\": \"药物\",\n",
    "        # \"OPE\": \"手术\",\n",
    "        # \"IMA\": \"影像检查\",\n",
    "        # \"CHECK\":\"检查\",\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zl/anaconda3/envs/NER/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1643: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs parser: {\n",
      "    \"batch_size\": 16,\n",
      "    \"train_file\": \"./data/prompt/pro_mul.json\",\n",
      "    \"tag_file\": \"data/FN/tags_list.txt\",\n",
      "    \"bert_vocab_file\": \"./model/chinese_wwm_ext/vocab.txt\",\n",
      "    \"max_seq_length\": 128,\n",
      "    \"do_shuffle\": true,\n",
      "    \"task_name\": \"tmul_pre_1\",\n",
      "    \"tag_rules\": {\n",
      "        \"O\": \"非实体\",\n",
      "        \"Surgery\": \"外科\",\n",
      "        \"Health\": \"健康管理\",\n",
      "        \"mouth\": \"口腔\",\n",
      "        \"gyn\": \"妇科\",\n",
      "        \"Oto\": \"耳鼻咽喉科\",\n",
      "        \"eye\": \"眼科\",\n",
      "        \"inter\": \"内科\"\n",
      "    },\n",
      "    \"debug\": true,\n",
      "    \"pass_none_rule\": true\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset from ./data/prompt/pro_mul.json: 100%|██████████| 1601/1601 [00:00<00:00, 1728.69it/s]\n",
      "Some weights of the model checkpoint at ./model/chinese_wwm_ext/pytorch_model.bin were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch: 1/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.76it/s, train_loss=7.95]\n",
      "Epoch: 2/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.80it/s, train_loss=0.285]\n",
      "Epoch: 3/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.77it/s, train_loss=0.0765]\n",
      "Epoch: 4/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.76it/s, train_loss=0.0473]\n",
      "Epoch: 5/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.75it/s, train_loss=0.0355]\n",
      "Epoch: 6/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.73it/s, train_loss=0.0274]\n",
      "Epoch: 7/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.72it/s, train_loss=0.0223]\n",
      "Epoch: 8/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.72it/s, train_loss=0.0183]\n",
      "Epoch: 9/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.72it/s, train_loss=0.0158]\n",
      "Epoch: 10/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.72it/s, train_loss=0.0129]\n",
      "Epoch: 11/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.71it/s, train_loss=0.0155]\n",
      "Epoch: 12/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.0109]\n",
      "Epoch: 13/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00817]\n",
      "Epoch: 14/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.71it/s, train_loss=0.00715]\n",
      "Epoch: 15/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.71it/s, train_loss=0.00643]\n",
      "Epoch: 16/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.71it/s, train_loss=0.00555]\n",
      "Epoch: 17/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00546]\n",
      "Epoch: 18/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00482]\n",
      "Epoch: 19/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00378]\n",
      "Epoch: 20/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00321]\n",
      "Epoch: 21/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00307]\n",
      "Epoch: 22/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00319]\n",
      "Epoch: 23/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.00253]\n",
      "Epoch: 24/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00265]\n",
      "Epoch: 25/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.00242]\n",
      "Epoch: 26/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.00206]\n",
      "Epoch: 27/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.0022] \n",
      "Epoch: 28/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00192]\n",
      "Epoch: 29/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00147]\n",
      "Epoch: 30/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.70it/s, train_loss=0.00139]\n",
      "Epoch: 31/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.00157]\n",
      "Epoch: 32/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.00128]\n",
      "Epoch: 33/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.00134]\n",
      "Epoch: 34/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.0013] \n",
      "Epoch: 35/35 Train: 100%|██████████| 101/101 [00:21<00:00,  4.69it/s, train_loss=0.000981]\n"
     ]
    }
   ],
   "source": [
    "# Bert预训练\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "args = {\n",
    "    'num_epochs': 35,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/FN_multiple_pretrained_2/Bert_8960/pytorch_model.bin',\n",
    "    'max_seq_length': 128,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/prompt/pro_mul.json',\n",
    "    'eval_file': './data/FN/sc_test100/test.json',\n",
    "    'test_file': './data/FN/sc_test100/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': 'data/FN/tags_list.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 16,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'tmul_pre_1',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        # \"KEYWORD\": \"关键词\",\n",
    "        # \"DIS\": \"疾病或诊断\",\n",
    "        # \"ANA\": \"解剖部位\",\n",
    "        # \"LAB\": \"实验室检验\",\n",
    "        # \"MED\": \"药物\",\n",
    "        # \"OPE\": \"手术\",\n",
    "        # \"IMA\": \"影像检查\",\n",
    "        # \"CHECK\":\"检查\",\n",
    "        \"Surgery\":\"外科\",\n",
    "        \"Health\":\"健康管理\",\n",
    "        \"mouth\":\"口腔\",\n",
    "        \"gyn\":\"妇科\",\n",
    "        'Oto':'耳鼻咽喉科',\n",
    "        'eye':'眼科',\n",
    "        \"inter\":\"内科\",\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9392d1f0914889243d058bb73f0d89e61311fd6d751bbc8fa50e38d7d4ff811"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('NER': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
